{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fad462a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:29.004367Z",
     "iopub.status.busy": "2025-06-03T05:57:29.004122Z",
     "iopub.status.idle": "2025-06-03T05:57:30.642998Z",
     "shell.execute_reply": "2025-06-03T05:57:30.642342Z"
    },
    "papermill": {
     "duration": 1.648956,
     "end_time": "2025-06-03T05:57:30.644484",
     "exception": false,
     "start_time": "2025-06-03T05:57:28.995528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/eatvul/preserved_pool_attack.csv\n",
      "/kaggle/input/eatvul/cwe189_train.csv\n",
      "/kaggle/input/eatvul/cwe119_train.csv\n",
      "/kaggle/input/eatvul/cwe416_test.csv\n",
      "/kaggle/input/eatvul/cwe399_ast_test.json\n",
      "/kaggle/input/eatvul/asterisk_ast_test_ADV.json\n",
      "/kaggle/input/eatvul/predict_codet5_cwe119.txt\n",
      "/kaggle/input/eatvul/cwe399-huggingface.csv\n",
      "/kaggle/input/eatvul/cwe399_ast_test_ADV.json\n",
      "/kaggle/input/eatvul/cwe399_test.csv\n",
      "/kaggle/input/eatvul/openssl_ast_test_ADV.json\n",
      "/kaggle/input/eatvul/cwe119_test.csv\n",
      "/kaggle/input/eatvul/openssl_ast_test.json\n",
      "/kaggle/input/eatvul/cwe119-huggingface.csv\n",
      "/kaggle/input/eatvul/cwe20_train.csv\n",
      "/kaggle/input/eatvul/cwe399_ast_train.json\n",
      "/kaggle/input/eatvul/predict_codet5_cwe20.txt\n",
      "/kaggle/input/eatvul/cwe-399-v2.csv\n",
      "/kaggle/input/eatvul/predict_codebert_cwe189.txt\n",
      "/kaggle/input/eatvul/predict_codebert_cwe399.txt\n",
      "/kaggle/input/eatvul/openssl_ast_train.json\n",
      "/kaggle/input/eatvul/predict_codet5_cwe416.txt\n",
      "/kaggle/input/eatvul/cwe119_ast_test.json\n",
      "/kaggle/input/eatvul/predict_codebert_cwe20.txt\n",
      "/kaggle/input/eatvul/2005_009_001_52710.pdf\n",
      "/kaggle/input/eatvul/cwe119_ast_train.json\n",
      "/kaggle/input/eatvul/asterisk_ast_train.json\n",
      "/kaggle/input/eatvul/predict_codet5_cwe189.txt\n",
      "/kaggle/input/eatvul/cwe20_test.csv\n",
      "/kaggle/input/eatvul/cwe119_ast_test_ADV.json\n",
      "/kaggle/input/eatvul/predict_codebert_cwe119.txt\n",
      "/kaggle/input/eatvul/predict_codet5_cwe399.txt\n",
      "/kaggle/input/eatvul/gnu_c_language.pdf\n",
      "/kaggle/input/eatvul/cwe189_test.csv\n",
      "/kaggle/input/eatvul/cwe416_train.csv\n",
      "/kaggle/input/eatvul/asterisk_ast_test.json\n",
      "/kaggle/input/eatvul/SDP18011FU1.pdf\n",
      "/kaggle/input/eatvul/cwe399_train.csv\n",
      "/kaggle/input/eatvul/cwe399_attack_pool.csv\n",
      "/kaggle/input/eatvul/predict_codebert_cwe416.txt\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe399-codet5-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe189-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe189-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/tokenizer.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe189-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe416-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe416-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/tokenizer.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe416-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe399-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe399-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe399-model/model/tokenizer.json\n",
      "/kaggle/input/eatvul/cwe399-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe399-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe399-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe399-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe399-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe119-codet5-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe189-codet5-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe20-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe20-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/tokenizer.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe20-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe20-codet5-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe119-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe119-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe119-model/model/tokenizer.json\n",
      "/kaggle/input/eatvul/cwe119-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe119-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe119-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe119-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe119-model/model/best_model.pt\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/merges.txt\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/evaluation_results.json\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/model_config.json\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/vocab.json\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/tokenizer_config.json\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/training_history.json\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/special_tokens_map.json\n",
      "/kaggle/input/eatvul/cwe416-codet5-model/model/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56f4eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.659098Z",
     "iopub.status.busy": "2025-06-03T05:57:30.658802Z",
     "iopub.status.idle": "2025-06-03T05:57:30.662250Z",
     "shell.execute_reply": "2025-06-03T05:57:30.661598Z"
    },
    "papermill": {
     "duration": 0.011719,
     "end_time": "2025-06-03T05:57:30.663402",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.651683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # CWE-399\n",
    "# train_399 = pd.read_csv('/kaggle/input/eatvul/cwe399_train.csv')\n",
    "# test_399 = pd.read_csv('/kaggle/input/eatvul/cwe399_test.csv')\n",
    "\n",
    "# # CWE-119\n",
    "# train_119 = pd.read_csv('/kaggle/input/eatvul/cwe119_train.csv')\n",
    "# test_119 = pd.read_csv('/kaggle/input/eatvul/cwe119_test.csv')\n",
    "\n",
    "# # CWE-20\n",
    "# train_20 = pd.read_csv('/kaggle/input/eatvul/cwe20_train.csv')\n",
    "# test_20 = pd.read_csv('/kaggle/input/eatvul/cwe20_test.csv')\n",
    "\n",
    "# # CWE-416\n",
    "# train_416 = pd.read_csv('/kaggle/input/eatvul/cwe416_train.csv')\n",
    "# test_416 = pd.read_csv('/kaggle/input/eatvul/cwe416_test.csv')\n",
    "\n",
    "# # CWE-189\n",
    "# train_189 = pd.read_csv('/kaggle/input/eatvul/cwe189_train.csv')\n",
    "# test_189 = pd.read_csv('/kaggle/input/eatvul/cwe189_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d570e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.678687Z",
     "iopub.status.busy": "2025-06-03T05:57:30.678488Z",
     "iopub.status.idle": "2025-06-03T05:57:30.695823Z",
     "shell.execute_reply": "2025-06-03T05:57:30.695267Z"
    },
    "papermill": {
     "duration": 0.026798,
     "end_time": "2025-06-03T05:57:30.696862",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.670064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.nn import CrossEntropyLoss\n",
    "# from transformers import T5ForConditionalGeneration, RobertaTokenizer, get_linear_schedule_with_warmup\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# try:\n",
    "#     import seaborn as sns\n",
    "# except ImportError:\n",
    "#     print(\"Warning: Seaborn not installed. Some visualizations may not work.\")\n",
    "#     sns = None\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# import re\n",
    "# import gc\n",
    "# import json\n",
    "# import zipfile\n",
    "# from datetime import datetime\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "# # Set device (GPU if available, else CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# class CodePreprocessor:\n",
    "#     \"\"\"Preprocess code for CodeT5 model\"\"\"\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "#         self.max_length = 512  # Maximum sequence length for CodeT5\n",
    "    \n",
    "#     def preprocess_code(self, code_text):\n",
    "#         \"\"\"Basic preprocessing of code text\"\"\"\n",
    "#         # Remove extra whitespace\n",
    "#         code_text = re.sub(r'\\s+', ' ', code_text)\n",
    "#         code_text = code_text.strip()\n",
    "#         return code_text\n",
    "    \n",
    "#     def tokenize(self, code_text, truncation=True, padding='max_length', return_tensors=None):\n",
    "#         \"\"\"Tokenize code text using RobertaTokenizer\"\"\"\n",
    "#         processed_code = self.preprocess_code(code_text)\n",
    "#         return self.tokenizer(processed_code, \n",
    "#                              truncation=truncation, \n",
    "#                              max_length=self.max_length,\n",
    "#                              padding=padding,\n",
    "#                              return_tensors=return_tensors)\n",
    "\n",
    "# class CodeDataset(Dataset):\n",
    "#     \"\"\"Dataset for code vulnerability detection using CodeT5\"\"\"\n",
    "    \n",
    "#     def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts[idx])\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         encoding = self.tokenizer(text, \n",
    "#                                  truncation=True,\n",
    "#                                  max_length=self.max_length,\n",
    "#                                  padding='max_length',\n",
    "#                                  return_tensors='pt')\n",
    "        \n",
    "#         # Remove batch dimension added by tokenizer when return_tensors='pt'\n",
    "#         input_ids = encoding['input_ids'].squeeze()\n",
    "#         attention_mask = encoding['attention_mask'].squeeze()\n",
    "        \n",
    "#         return {\n",
    "#             'input_ids': input_ids,\n",
    "#             'attention_mask': attention_mask,\n",
    "#             'label': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# class CodeT5Classifier(nn.Module):\n",
    "#     \"\"\"CodeT5 model for code vulnerability detection\"\"\"\n",
    "    \n",
    "#     def __init__(self, freeze_base=False, dropout_rate=0.1):\n",
    "#         super(CodeT5Classifier, self).__init__()\n",
    "        \n",
    "#         # Load pre-trained CodeT5 model\n",
    "#         self.codet5 = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base\")\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "#         # For classification, we'll use the encoder's last hidden state\n",
    "#         # Get hidden size from the model config\n",
    "#         self.hidden_size = self.codet5.config.d_model\n",
    "        \n",
    "#         # Classification head\n",
    "#         self.classifier = nn.Linear(self.hidden_size, 2)  # Binary classification\n",
    "        \n",
    "#         # Freeze CodeT5 layers if specified\n",
    "#         if freeze_base:\n",
    "#             for param in self.codet5.parameters():\n",
    "#                 param.requires_grad = False\n",
    "    \n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get CodeT5 encoder outputs\n",
    "#         encoder_outputs = self.codet5.encoder(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             return_dict=True\n",
    "#         )\n",
    "        \n",
    "#         # Use the mean of the last hidden state for classification\n",
    "#         # Shape: (batch_size, sequence_length, hidden_size)\n",
    "#         last_hidden_state = encoder_outputs.last_hidden_state\n",
    "        \n",
    "#         # Create a mask to exclude padding tokens from the mean\n",
    "#         # Shape: (batch_size, sequence_length, 1)\n",
    "#         mask = attention_mask.unsqueeze(-1).float()\n",
    "        \n",
    "#         # Apply mask and compute mean over sequence length\n",
    "#         # Shape: (batch_size, hidden_size)\n",
    "#         pooled_output = torch.sum(last_hidden_state * mask, dim=1) / torch.sum(mask, dim=1)\n",
    "        \n",
    "#         # Apply dropout and classify\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "        \n",
    "#         return logits \n",
    "\n",
    "# class CodeT5Trainer:\n",
    "#     \"\"\"Trainer for CodeT5 model\"\"\"\n",
    "    \n",
    "#     def __init__(self, data_path=None, batch_size=8, epochs=4, learning_rate=2e-5):\n",
    "#         self.preprocessor = CodePreprocessor()\n",
    "#         self.batch_size = batch_size\n",
    "#         self.epochs = epochs\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.data = None\n",
    "#         self.model = None\n",
    "#         self.best_model_state = None\n",
    "#         self.best_val_accuracy = 0.0\n",
    "#         self.history = {\n",
    "#             'train_loss': [],\n",
    "#             'val_loss': [],\n",
    "#             'val_accuracy': [],\n",
    "#             'val_precision': [],\n",
    "#             'val_recall': [],\n",
    "#             'val_f1': []\n",
    "#         }\n",
    "#         self.output_dir = os.path.join(os.getcwd(), 'codet5_outputs')\n",
    "#         os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "#         if data_path:\n",
    "#             self.load_data(data_path)\n",
    "    \n",
    "#     def load_data(self, data_path):\n",
    "#         \"\"\"\n",
    "#         Load data from file or DataFrame\n",
    "        \n",
    "#         Args:\n",
    "#             data_path: Path to a data file (CSV, Excel, JSON) or a pandas DataFrame\n",
    "#         \"\"\"\n",
    "#         print(f\"DEBUG: Type of data_path in load_data: {type(data_path)}\")\n",
    "        \n",
    "#         # If data_path is already a DataFrame, use it directly\n",
    "#         if isinstance(data_path, pd.DataFrame):\n",
    "#             self.data = data_path\n",
    "#             print(f\"Using provided DataFrame with {len(self.data)} samples.\")\n",
    "            \n",
    "#         # If it's a string, try to load from file\n",
    "#         elif isinstance(data_path, str):\n",
    "#             print(f\"DEBUG: Trying to load from file path: '{data_path}'\")\n",
    "            \n",
    "#             # Check if the file exists\n",
    "#             if not os.path.exists(data_path):\n",
    "#                 raise FileNotFoundError(f\"File not found: '{data_path}'\")\n",
    "                \n",
    "#             file_ext = os.path.splitext(data_path.lower())[1]\n",
    "#             print(f\"DEBUG: File extension detected: '{file_ext}'\")\n",
    "            \n",
    "#             if file_ext == '.csv':\n",
    "#                 self.data = pd.read_csv(data_path)\n",
    "#             elif file_ext in ['.xls', '.xlsx']:\n",
    "#                 self.data = pd.read_excel(data_path)\n",
    "#             elif file_ext == '.json':\n",
    "#                 self.data = pd.read_json(data_path)\n",
    "#             elif file_ext == '.pkl' or file_ext == '.pickle':\n",
    "#                 self.data = pd.read_pickle(data_path)\n",
    "#             elif file_ext == '':\n",
    "#                 # Try to infer the format if no extension is given\n",
    "#                 try:\n",
    "#                     # First try CSV as it's most common\n",
    "#                     self.data = pd.read_csv(data_path)\n",
    "#                     print(f\"Inferred file format as CSV for: {data_path}\")\n",
    "#                 except:\n",
    "#                     try:\n",
    "#                         # Then try JSON\n",
    "#                         self.data = pd.read_json(data_path)\n",
    "#                         print(f\"Inferred file format as JSON for: {data_path}\")\n",
    "#                     except:\n",
    "#                         raise ValueError(f\"Could not determine file format for: '{data_path}'. Please specify a file with extension or provide a DataFrame.\")\n",
    "#             else:\n",
    "#                 raise ValueError(f\"Unsupported file format: '{file_ext}'. Supported formats: CSV, Excel, JSON, Pickle\")\n",
    "#         else:\n",
    "#             raise TypeError(f\"data_path must be either a string file path or a pandas DataFrame, got {type(data_path).__name__}\")\n",
    "        \n",
    "#         # Check if required columns exist\n",
    "#         if 'functionSource' not in self.data.columns or 'label' not in self.data.columns:\n",
    "#             raise ValueError(\"Data must contain 'functionSource' and 'label' columns.\")\n",
    "        \n",
    "#         print(f\"Loaded data with {len(self.data)} samples.\")\n",
    "#         print(f\"Label distribution: {self.data['label'].value_counts().to_dict()}\")\n",
    "    \n",
    "#     def set_data(self, dataframe):\n",
    "#         \"\"\"Set data directly from a pandas DataFrame\"\"\"\n",
    "#         if not isinstance(dataframe, pd.DataFrame):\n",
    "#             raise ValueError(\"Input must be a pandas DataFrame.\")\n",
    "        \n",
    "#         # Check if required columns exist\n",
    "#         if 'functionSource' not in dataframe.columns or 'label' not in dataframe.columns:\n",
    "#             raise ValueError(\"Data must contain 'functionSource' and 'label' columns.\")\n",
    "        \n",
    "#         self.data = dataframe\n",
    "#         print(f\"Set data with {len(self.data)} samples.\")\n",
    "#         print(f\"Label distribution: {self.data['label'].value_counts().to_dict()}\")\n",
    "    \n",
    "#     def prepare_data(self, train_data, test_data):\n",
    "#         \"\"\"Prepare data for model training using pre-split train and test data\"\"\"\n",
    "#         if self.data is None and (train_data is None or test_data is None):\n",
    "#             raise ValueError(\"No data provided. Provide train_data and test_data or call load_data/set_data first.\")\n",
    "        \n",
    "#         # Use provided train and test data\n",
    "#         train_texts = train_data['functionSource'].values\n",
    "#         train_labels = train_data['label'].values\n",
    "#         test_texts = test_data['functionSource'].values\n",
    "#         test_labels = test_data['label'].values\n",
    "        \n",
    "#         # Create datasets\n",
    "#         train_dataset = CodeDataset(\n",
    "#             train_texts, \n",
    "#             train_labels, \n",
    "#             self.preprocessor.tokenizer, \n",
    "#             self.preprocessor.max_length\n",
    "#         )\n",
    "        \n",
    "#         test_dataset = CodeDataset(\n",
    "#             test_texts, \n",
    "#             test_labels, \n",
    "#             self.preprocessor.tokenizer, \n",
    "#             self.preprocessor.max_length\n",
    "#         )\n",
    "        \n",
    "#         # Create data loaders\n",
    "#         train_loader = DataLoader(\n",
    "#             train_dataset,\n",
    "#             batch_size=self.batch_size,\n",
    "#             shuffle=True\n",
    "#         )\n",
    "        \n",
    "#         test_loader = DataLoader(\n",
    "#             test_dataset,\n",
    "#             batch_size=self.batch_size,\n",
    "#             shuffle=False\n",
    "#         )\n",
    "        \n",
    "#         print(f\"Train samples: {len(train_dataset)}\")\n",
    "#         print(f\"Test samples: {len(test_dataset)}\")\n",
    "        \n",
    "#         return {\n",
    "#             'train_loader': train_loader,\n",
    "#             'val_loader': test_loader,  # Use test loader for validation\n",
    "#             'test_loader': test_loader,\n",
    "#             'test_texts': test_texts,\n",
    "#             'test_labels': test_labels\n",
    "#         } \n",
    "\n",
    "#     def run_all(self, data_source=None, train_data=None, test_data=None, freeze_base=False, dataset_name=\"test\"):\n",
    "#         \"\"\"Run all steps: data preparation, training, evaluation, and saving\"\"\"\n",
    "#         # Load data if provided as a single source\n",
    "#         if data_source is not None:\n",
    "#             if isinstance(data_source, str):\n",
    "#                 self.load_data(data_source)\n",
    "#             elif isinstance(data_source, pd.DataFrame):\n",
    "#                 self.set_data(data_source)\n",
    "        \n",
    "#         # If train_data and test_data are provided, use them; otherwise, ensure data is loaded\n",
    "#         if train_data is not None and test_data is not None:\n",
    "#             if not isinstance(train_data, pd.DataFrame) or not isinstance(test_data, pd.DataFrame):\n",
    "#                 raise ValueError(\"train_data and test_data must be pandas DataFrames.\")\n",
    "#             if 'functionSource' not in train_data.columns or 'label' not in train_data.columns:\n",
    "#                 raise ValueError(\"train_data must contain 'functionSource' and 'label' columns.\")\n",
    "#             if 'functionSource' not in test_data.columns or 'label' not in test_data.columns:\n",
    "#                 raise ValueError(\"test_data must contain 'functionSource' and 'label' columns.\")\n",
    "#             print(f\"Using provided train_data with {len(train_data)} samples.\")\n",
    "#             print(f\"Using provided test_data with {len(test_data)} samples.\")\n",
    "#         elif self.data is None:\n",
    "#             raise ValueError(\"No data loaded. Provide data_source or train_data/test_data.\")\n",
    "        \n",
    "#         # Prepare data using provided train/test split or loaded data\n",
    "#         if train_data is not None and test_data is not None:\n",
    "#             data_loaders = self.prepare_data(train_data, test_data)\n",
    "#         else:\n",
    "#             data_loaders = self.prepare_data(self.data, self.data)  # Fallback (though not used in your case)\n",
    "        \n",
    "#         # Train model\n",
    "#         self.train_model(data_loaders, freeze_base=freeze_base)\n",
    "        \n",
    "#         # Plot training history\n",
    "#         self.plot_training_history()\n",
    "        \n",
    "#         # Evaluate model with dataset name for proper file naming\n",
    "#         results = self.evaluate_model(data_loaders['test_loader'], dataset_name=dataset_name)\n",
    "        \n",
    "#         # Save model\n",
    "#         model_dir = self.save_model()\n",
    "        \n",
    "#         # Save evaluation results\n",
    "#         with open(os.path.join(model_dir, 'evaluation_results.json'), 'w') as f:\n",
    "#             # Convert numpy values to Python types for JSON serialization\n",
    "#             serializable_results = {\n",
    "#                 k: v if not isinstance(v, np.ndarray) else v.tolist()\n",
    "#                 for k, v in results.items()\n",
    "#             }\n",
    "#             json.dump(serializable_results, f)\n",
    "        \n",
    "#         print(\"\\n=== Training and Evaluation Complete ===\")\n",
    "#         print(f\"All outputs saved to: {model_dir}\")\n",
    "        \n",
    "#         # Free up GPU memory\n",
    "#         if torch.cuda.is_available():\n",
    "#             torch.cuda.empty_cache()\n",
    "        \n",
    "#         return results\n",
    "    \n",
    "#     def train_model(self, data_loaders, freeze_base=False):\n",
    "#         \"\"\"Train the CodeT5 model\"\"\"\n",
    "#         # Initialize model\n",
    "#         self.model = CodeT5Classifier(freeze_base=freeze_base)\n",
    "#         self.model.to(device)\n",
    "        \n",
    "#         # Define optimizer and scheduler\n",
    "#         optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "#         # Calculate total training steps for learning rate scheduler\n",
    "#         total_steps = len(data_loaders['train_loader']) * self.epochs\n",
    "        \n",
    "#         # Create learning rate scheduler\n",
    "#         scheduler = get_linear_schedule_with_warmup(\n",
    "#             optimizer,\n",
    "#             num_warmup_steps=0,\n",
    "#             num_training_steps=total_steps\n",
    "#         )\n",
    "        \n",
    "#         # Define loss function\n",
    "#         criterion = CrossEntropyLoss()\n",
    "        \n",
    "#         # Training loop\n",
    "#         print(\"\\n=== Training CodeT5 Model ===\")\n",
    "        \n",
    "#         for epoch in range(self.epochs):\n",
    "#             print(f\"\\nEpoch {epoch+1}/{self.epochs}\")\n",
    "            \n",
    "#             # Training phase\n",
    "#             self.model.train()\n",
    "#             train_loss = 0.0\n",
    "            \n",
    "#             progress_bar = tqdm(data_loaders['train_loader'], desc=\"Training\")\n",
    "#             for batch in progress_bar:\n",
    "#                 # Move batch to device\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 labels = batch['label'].to(device)\n",
    "                \n",
    "#                 # Zero gradients\n",
    "#                 optimizer.zero_grad()\n",
    "                \n",
    "#                 # Forward pass\n",
    "#                 outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "#                 # Calculate loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "#                 # Backward pass\n",
    "#                 loss.backward()\n",
    "                \n",
    "#                 # Update parameters\n",
    "#                 optimizer.step()\n",
    "#                 scheduler.step()\n",
    "                \n",
    "#                 # Update training loss\n",
    "#                 train_loss += loss.item()\n",
    "#                 progress_bar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "#             # Calculate average training loss\n",
    "#             avg_train_loss = train_loss / len(data_loaders['train_loader'])\n",
    "#             self.history['train_loss'].append(avg_train_loss)\n",
    "            \n",
    "#             # Validation phase\n",
    "#             self.model.eval()\n",
    "#             val_loss = 0.0\n",
    "#             val_predictions = []\n",
    "#             val_true_labels = []\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "#                 for batch in tqdm(data_loaders['val_loader'], desc=\"Validation\"):\n",
    "#                     # Move batch to device\n",
    "#                     input_ids = batch['input_ids'].to(device)\n",
    "#                     attention_mask = batch['attention_mask'].to(device)\n",
    "#                     labels = batch['label'].to(device)\n",
    "                    \n",
    "#                     # Forward pass\n",
    "#                     outputs = self.model(input_ids, attention_mask)\n",
    "                    \n",
    "#                     # Calculate loss\n",
    "#                     loss = criterion(outputs, labels)\n",
    "                    \n",
    "#                     # Update validation loss\n",
    "#                     val_loss += loss.item()\n",
    "                    \n",
    "#                     # Get predictions\n",
    "#                     _, preds = torch.max(outputs, dim=1)\n",
    "                    \n",
    "#                     # Store predictions and true labels\n",
    "#                     val_predictions.extend(preds.cpu().tolist())\n",
    "#                     val_true_labels.extend(labels.cpu().tolist())\n",
    "            \n",
    "#             # Calculate average validation loss\n",
    "#             avg_val_loss = val_loss / len(data_loaders['val_loader'])\n",
    "#             self.history['val_loss'].append(avg_val_loss)\n",
    "            \n",
    "#             # Calculate validation metrics\n",
    "#             val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "#             val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
    "#                 val_true_labels, val_predictions, average='binary'\n",
    "#             )\n",
    "            \n",
    "#             self.history['val_accuracy'].append(val_accuracy)\n",
    "#             self.history['val_precision'].append(val_precision)\n",
    "#             self.history['val_recall'].append(val_recall)\n",
    "#             self.history['val_f1'].append(val_f1)\n",
    "            \n",
    "#             print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "#             print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "#             print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "#             print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "#             print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "#             print(f\"Validation F1: {val_f1:.4f}\")\n",
    "            \n",
    "#             # Save best model\n",
    "#             if val_accuracy > self.best_val_accuracy:\n",
    "#                 self.best_val_accuracy = val_accuracy\n",
    "#                 self.best_model_state = self.model.state_dict().copy()\n",
    "#                 print(f\"New best model with validation accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "#         # Load best model for testing\n",
    "#         if self.best_model_state is not None:\n",
    "#             self.model.load_state_dict(self.best_model_state)\n",
    "#             print(f\"Loaded best model with validation accuracy: {self.best_val_accuracy:.4f}\")\n",
    "        \n",
    "#         return self.model\n",
    "\n",
    "#     def plot_training_history(self):\n",
    "#         \"\"\"Plot training history\"\"\"\n",
    "#         plt.figure(figsize=(12, 4))\n",
    "        \n",
    "#         # Plot training loss\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.plot(self.history['train_loss'], label='Training Loss')\n",
    "#         plt.plot(self.history['val_loss'], label='Validation Loss')\n",
    "#         plt.title('Model Loss')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.legend()\n",
    "        \n",
    "#         # Plot validation metrics\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
    "#         plt.plot(self.history['val_precision'], label='Validation Precision')\n",
    "#         plt.plot(self.history['val_recall'], label='Validation Recall')\n",
    "#         plt.plot(self.history['val_f1'], label='Validation F1')\n",
    "#         plt.title('Model Validation Metrics')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         plt.ylabel('Metric Value')\n",
    "#         plt.legend()\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "#     def evaluate_model(self, test_loader, dataset_name=\"test\", export_predictions=True):\n",
    "#         \"\"\"Evaluate the model on test data\"\"\"\n",
    "#         if self.model is None:\n",
    "#             raise ValueError(\"No model trained. Call train_model first.\")\n",
    "        \n",
    "#         print(\"\\n=== Evaluating Model on Test Set ===\")\n",
    "        \n",
    "#         # Explicitly load the best model state for evaluation\n",
    "#         if self.best_model_state is not None:\n",
    "#             print(f\"Loading best model with validation accuracy: {self.best_val_accuracy:.4f}\")\n",
    "#             self.model.load_state_dict(self.best_model_state)\n",
    "#             self.model.eval()\n",
    "#         else:\n",
    "#             print(\"Warning: No best model state found, using current model state\")\n",
    "#             self.model.eval()\n",
    "        \n",
    "#         test_predictions = []\n",
    "#         test_true_labels = []\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "#                 # Move batch to device\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 labels = batch['label'].to(device)\n",
    "                \n",
    "#                 # Forward pass\n",
    "#                 outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "#                 # Get predictions\n",
    "#                 _, preds = torch.max(outputs, dim=1)\n",
    "                \n",
    "#                 # Store predictions and true labels\n",
    "#                 test_predictions.extend(preds.cpu().tolist())\n",
    "#                 test_true_labels.extend(labels.cpu().tolist())\n",
    "        \n",
    "#         # Calculate test metrics\n",
    "#         test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "#         test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(\n",
    "#             test_true_labels, test_predictions, average='binary'\n",
    "#         )\n",
    "        \n",
    "#         # Generate classification report\n",
    "#         class_report = classification_report(test_true_labels, test_predictions)\n",
    "        \n",
    "#         # Generate confusion matrix\n",
    "#         conf_matrix = confusion_matrix(test_true_labels, test_predictions)\n",
    "        \n",
    "#         print(f\"\\n=== BEST MODEL EVALUATION RESULTS ===\")\n",
    "#         if self.best_model_state is not None:\n",
    "#             print(f\"Using best model from training (Validation Accuracy: {self.best_val_accuracy:.4f})\")\n",
    "#         print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "#         print(f\"Test Precision: {test_precision:.4f}\")\n",
    "#         print(f\"Test Recall: {test_recall:.4f}\")\n",
    "#         print(f\"Test F1: {test_f1:.4f}\")\n",
    "#         print(\"\\n=== DETAILED CLASSIFICATION REPORT (BEST MODEL) ===\")\n",
    "#         print(class_report)\n",
    "#         print(\"=\"*60)\n",
    "        \n",
    "#         # Plot confusion matrix\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         if sns is not None:\n",
    "#             sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "#                        xticklabels=['Not Vulnerable', 'Vulnerable'],\n",
    "#                        yticklabels=['Not Vulnerable', 'Vulnerable'])\n",
    "#         else:\n",
    "#             # Fallback to matplotlib if seaborn is not available\n",
    "#             plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "#             plt.colorbar()\n",
    "#             # Add text annotations\n",
    "#             for i in range(conf_matrix.shape[0]):\n",
    "#                 for j in range(conf_matrix.shape[1]):\n",
    "#                     plt.text(j, i, str(conf_matrix[i, j]), \n",
    "#                             ha='center', va='center', color='black')\n",
    "#             plt.xticks([0, 1], ['Not Vulnerable', 'Vulnerable'])\n",
    "#             plt.yticks([0, 1], ['Not Vulnerable', 'Vulnerable'])\n",
    "        \n",
    "#         plt.title(f'Confusion Matrix - Best Model (Val Acc: {self.best_val_accuracy:.4f})')\n",
    "#         plt.ylabel('True Label')\n",
    "#         plt.xlabel('Predicted Label')\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(os.path.join(self.output_dir, 'confusion_matrix.png'))\n",
    "#         plt.close()\n",
    "        \n",
    "#         results = {\n",
    "#             'accuracy': test_accuracy,\n",
    "#             'precision': test_precision,\n",
    "#             'recall': test_recall,\n",
    "#             'f1': test_f1,\n",
    "#             'classification_report': class_report,\n",
    "#             'confusion_matrix': conf_matrix.tolist(),\n",
    "#             'predictions': test_predictions,\n",
    "#             'true_labels': test_true_labels,\n",
    "#             'best_val_accuracy': self.best_val_accuracy\n",
    "#         }\n",
    "        \n",
    "#         # Export predictions if requested\n",
    "#         if export_predictions:\n",
    "#             export_path = self.export_predictions(\n",
    "#                 test_predictions, \n",
    "#                 test_true_labels, \n",
    "#                 dataset_name\n",
    "#             )\n",
    "#             results['export_path'] = export_path\n",
    "        \n",
    "#         return results\n",
    "    \n",
    "#     def save_model(self):\n",
    "#         \"\"\"Save trained model and tokenizer, and create a zip archive\"\"\"\n",
    "#         if self.model is None:\n",
    "#             print(\"No model to save.\")\n",
    "#             return\n",
    "        \n",
    "#         # Create timestamp for unique folder\n",
    "#         timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#         model_dir = os.path.join(self.output_dir, f'model')\n",
    "#         os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "#         # Save model\n",
    "#         if self.best_model_state is not None:\n",
    "#             torch.save(self.best_model_state, os.path.join(model_dir, 'best_model.pt'))\n",
    "#         else:\n",
    "#             torch.save(self.model.state_dict(), os.path.join(model_dir, 'model.pt'))\n",
    "        \n",
    "#         # Save model configuration\n",
    "#         model_config = {\n",
    "#             'hidden_size': self.model.hidden_size,\n",
    "#             'vocab_size': self.preprocessor.tokenizer.vocab_size,\n",
    "#             'num_labels': 2,\n",
    "#             'max_length': self.preprocessor.max_length\n",
    "#         }\n",
    "        \n",
    "#         with open(os.path.join(model_dir, 'model_config.json'), 'w') as f:\n",
    "#             json.dump(model_config, f)\n",
    "        \n",
    "#         # Save tokenizer\n",
    "#         self.preprocessor.tokenizer.save_pretrained(model_dir)\n",
    "        \n",
    "#         # Save training history\n",
    "#         with open(os.path.join(model_dir, 'training_history.json'), 'w') as f:\n",
    "#             json.dump(self.history, f)\n",
    "        \n",
    "#         print(f\"Model saved to {model_dir}\")\n",
    "        \n",
    "#         # Create zip archive of the model directory\n",
    "#         zip_path = f\"{model_dir}_{timestamp}.zip\"\n",
    "#         try:\n",
    "#             print(f\"Creating zip archive: {zip_path}\")\n",
    "#             with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#                 # Walk through the model directory and add all files\n",
    "#                 for root, dirs, files in os.walk(model_dir):\n",
    "#                     for file in files:\n",
    "#                         file_path = os.path.join(root, file)\n",
    "#                         # Create archive path relative to the model directory\n",
    "#                         arcname = os.path.relpath(file_path, os.path.dirname(model_dir))\n",
    "#                         zipf.write(file_path, arcname)\n",
    "            \n",
    "#             # Get zip file size for user feedback\n",
    "#             zip_size = os.path.getsize(zip_path)\n",
    "#             zip_size_mb = zip_size / (1024 * 1024)\n",
    "#             print(f\"‚úÖ Model archive created successfully: {zip_path}\")\n",
    "#             print(f\"üì¶ Archive size: {zip_size_mb:.2f} MB\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ö†Ô∏è Warning: Could not create zip archive: {str(e)}\")\n",
    "#             print(f\"Model files are still available in: {model_dir}\")\n",
    "        \n",
    "#         return model_dir\n",
    "    \n",
    "#     def load_model(self, model_dir):\n",
    "#         \"\"\"\n",
    "#         Load a previously saved CodeT5 model from the specified directory\n",
    "        \n",
    "#         Args:\n",
    "#             model_dir: Path to the directory containing the saved model\n",
    "            \n",
    "#         Returns:\n",
    "#             The loaded CodeT5Classifier model\n",
    "#         \"\"\"\n",
    "#         if not os.path.exists(model_dir):\n",
    "#             raise ValueError(f\"Model directory {model_dir} does not exist\")\n",
    "            \n",
    "#         print(f\"Loading model from {model_dir}\")\n",
    "        \n",
    "#         # Check for model config file\n",
    "#         config_path = os.path.join(model_dir, 'model_config.json')\n",
    "#         if not os.path.exists(config_path):\n",
    "#             raise ValueError(f\"Model config file not found in {model_dir}\")\n",
    "            \n",
    "#         # Load model configuration\n",
    "#         with open(config_path, 'r') as f:\n",
    "#             model_config = json.load(f)\n",
    "            \n",
    "#         # Initialize model\n",
    "#         self.model = CodeT5Classifier()\n",
    "#         self.model.to(device)\n",
    "        \n",
    "#         # Check for model state file (either best_model.pt or model.pt)\n",
    "#         best_model_path = os.path.join(model_dir, 'best_model.pt')\n",
    "#         model_path = os.path.join(model_dir, 'model.pt')\n",
    "        \n",
    "#         if os.path.exists(best_model_path):\n",
    "#             state_dict = torch.load(best_model_path, map_location=device)\n",
    "#             print(\"Loading best model checkpoint\")\n",
    "#         elif os.path.exists(model_path):\n",
    "#             state_dict = torch.load(model_path, map_location=device)\n",
    "#             print(\"Loading regular model checkpoint\")\n",
    "#         else:\n",
    "#             raise ValueError(f\"No model checkpoint found in {model_dir}\")\n",
    "            \n",
    "#         # Load model state\n",
    "#         self.model.load_state_dict(state_dict)\n",
    "#         self.best_model_state = state_dict\n",
    "        \n",
    "#         # Load tokenizer if available\n",
    "#         tokenizer_path = os.path.join(model_dir, 'special_tokens_map.json')\n",
    "#         if os.path.exists(tokenizer_path):\n",
    "#             self.preprocessor.tokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "#             print(\"Loaded tokenizer from saved model\")\n",
    "            \n",
    "#         # Load training history if available\n",
    "#         history_path = os.path.join(model_dir, 'training_history.json')\n",
    "#         if os.path.exists(history_path):\n",
    "#             with open(history_path, 'r') as f:\n",
    "#                 self.history = json.load(f)\n",
    "            \n",
    "#             # Set best accuracy from history if available\n",
    "#             if self.history.get('val_accuracy'):\n",
    "#                 self.best_val_accuracy = max(self.history['val_accuracy'])\n",
    "#                 print(f\"Loaded training history. Best validation accuracy: {self.best_val_accuracy:.4f}\")\n",
    "        \n",
    "#         # Set model to evaluation mode\n",
    "#         self.model.eval()\n",
    "#         print(\"Model loaded successfully and set to evaluation mode\")\n",
    "        \n",
    "#         return self.model\n",
    "    \n",
    "#     def export_predictions(self, predictions, true_labels=None, dataset_name=\"test\"):\n",
    "#         \"\"\"\n",
    "#         Export model predictions to a txt file with index and prediction format\n",
    "        \n",
    "#         Args:\n",
    "#             predictions: List or array of predictions (0 or 1)\n",
    "#             true_labels: Optional list of true labels for comparison\n",
    "#             dataset_name: Name to include in the filename (e.g., \"test\", \"cwe119\")\n",
    "            \n",
    "#         Returns:\n",
    "#             Path to the exported file\n",
    "#         \"\"\"\n",
    "#         # Create timestamp for unique filename\n",
    "#         timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        \n",
    "#         # Create filename\n",
    "#         if \"cwe\" in dataset_name.lower():\n",
    "#             filename = f\"predict_codet5_{dataset_name}_{timestamp}.txt\"\n",
    "#         else:\n",
    "#             filename = f\"predict_codet5_cwe_{timestamp}.txt\"\n",
    "        \n",
    "#         # Full path for the output file\n",
    "#         output_path = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "#         # Write predictions to file\n",
    "#         with open(output_path, 'w') as f:\n",
    "#             for idx, pred in enumerate(predictions):\n",
    "#                 f.write(f\"{idx}\\t{pred}\\n\")\n",
    "        \n",
    "#         print(f\"Predictions exported to: {output_path}\")\n",
    "#         print(f\"Total predictions exported: {len(predictions)}\")\n",
    "        \n",
    "#         # If true labels are provided, also create a comparison file\n",
    "#         if true_labels is not None:\n",
    "#             comparison_filename = f\"prediction_comparison_{dataset_name}_{timestamp}.txt\"\n",
    "#             comparison_path = os.path.join(self.output_dir, comparison_filename)\n",
    "            \n",
    "#             with open(comparison_path, 'w') as f:\n",
    "#                 f.write(\"Index\\tPrediction\\tTrue_Label\\tCorrect\\n\")\n",
    "#                 correct_count = 0\n",
    "#                 for idx, (pred, true) in enumerate(zip(predictions, true_labels)):\n",
    "#                     is_correct = pred == true\n",
    "#                     if is_correct:\n",
    "#                         correct_count += 1\n",
    "#                     f.write(f\"{idx}\\t{pred}\\t{true}\\t{is_correct}\\n\")\n",
    "            \n",
    "#             accuracy = correct_count / len(predictions) if len(predictions) > 0 else 0\n",
    "#             print(f\"Prediction comparison exported to: {comparison_path}\")\n",
    "#             print(f\"Accuracy: {accuracy:.4f} ({correct_count}/{len(predictions)})\")\n",
    "        \n",
    "#         return output_path\n",
    "    \n",
    "#     def predict(self, code_text):\n",
    "#         \"\"\"\n",
    "#         Make a prediction on a single code sample\n",
    "        \n",
    "#         Args:\n",
    "#             code_text: String containing the code to analyze\n",
    "            \n",
    "#         Returns:\n",
    "#             Dictionary with prediction results\n",
    "#         \"\"\"\n",
    "#         if self.model is None:\n",
    "#             raise ValueError(\"No model loaded. Call train_model or load_model first.\")\n",
    "        \n",
    "#         # Preprocess and tokenize the code\n",
    "#         encoding = self.preprocessor.tokenize(\n",
    "#             code_text, \n",
    "#             truncation=True,\n",
    "#             padding='max_length',\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "        \n",
    "#         # Move tensors to device\n",
    "#         input_ids = encoding['input_ids'].to(device)\n",
    "#         attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "#         # Set model to evaluation mode\n",
    "#         self.model.eval()\n",
    "        \n",
    "#         # Make prediction\n",
    "#         with torch.no_grad():\n",
    "#             outputs = self.model(input_ids, attention_mask)\n",
    "#             probabilities = torch.softmax(outputs, dim=1)\n",
    "#             confidence, prediction = torch.max(probabilities, dim=1)\n",
    "        \n",
    "#         result = {\n",
    "#             'prediction': prediction.item(),  # 0: not vulnerable, 1: vulnerable\n",
    "#             'confidence': confidence.item(),\n",
    "#             'probabilities': probabilities[0].cpu().numpy().tolist(),\n",
    "#             'label_names': ['Not Vulnerable', 'Vulnerable']\n",
    "#         }\n",
    "        \n",
    "#         return result\n",
    "\n",
    "# def free_gpu_memory():\n",
    "#     \"\"\"Free up GPU memory\"\"\"\n",
    "#     gc.collect()\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3ac000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.710238Z",
     "iopub.status.busy": "2025-06-03T05:57:30.710061Z",
     "iopub.status.idle": "2025-06-03T05:57:30.712972Z",
     "shell.execute_reply": "2025-06-03T05:57:30.712393Z"
    },
    "papermill": {
     "duration": 0.01088,
     "end_time": "2025-06-03T05:57:30.713955",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.703075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Reload data and try with smaller batch size\n",
    "# trainer = CodeT5Trainer(batch_size=16, epochs=5)\n",
    "# results1 = trainer.run_all(train_data=train_399, test_data=test_399)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0650db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.727535Z",
     "iopub.status.busy": "2025-06-03T05:57:30.727365Z",
     "iopub.status.idle": "2025-06-03T05:57:30.730231Z",
     "shell.execute_reply": "2025-06-03T05:57:30.729736Z"
    },
    "papermill": {
     "duration": 0.010804,
     "end_time": "2025-06-03T05:57:30.731220",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.720416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results2 = trainer.run_all(train_data=train_119, test_data=test_119)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01591e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.744527Z",
     "iopub.status.busy": "2025-06-03T05:57:30.744362Z",
     "iopub.status.idle": "2025-06-03T05:57:30.747232Z",
     "shell.execute_reply": "2025-06-03T05:57:30.746692Z"
    },
    "papermill": {
     "duration": 0.01065,
     "end_time": "2025-06-03T05:57:30.748188",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.737538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results3 = trainer.run_all(train_data=train_189, test_data=test_189)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d2d687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.761837Z",
     "iopub.status.busy": "2025-06-03T05:57:30.761675Z",
     "iopub.status.idle": "2025-06-03T05:57:30.764705Z",
     "shell.execute_reply": "2025-06-03T05:57:30.764011Z"
    },
    "papermill": {
     "duration": 0.010917,
     "end_time": "2025-06-03T05:57:30.765659",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.754742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results4 = trainer.run_all(train_data=train_416, test_data=test_416)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227fea58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.779252Z",
     "iopub.status.busy": "2025-06-03T05:57:30.779055Z",
     "iopub.status.idle": "2025-06-03T05:57:30.781803Z",
     "shell.execute_reply": "2025-06-03T05:57:30.781296Z"
    },
    "papermill": {
     "duration": 0.01065,
     "end_time": "2025-06-03T05:57:30.782859",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.772209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results5 = trainer.run_all(train_data=train_20, test_data=test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ecb039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:30.797076Z",
     "iopub.status.busy": "2025-06-03T05:57:30.796858Z",
     "iopub.status.idle": "2025-06-03T05:57:32.125297Z",
     "shell.execute_reply": "2025-06-03T05:57:32.124757Z"
    },
    "papermill": {
     "duration": 1.337129,
     "end_time": "2025-06-03T05:57:32.126810",
     "exception": false,
     "start_time": "2025-06-03T05:57:30.789681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import sklearn.metrics\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def centriod_init(K, min_distance):\n",
    "    random_center = []\n",
    "    attempts = 0\n",
    "\n",
    "    while len(random_center) < K:\n",
    "        num = random.uniform(0, 1)\n",
    "        if all(abs(num - existing) >= min_distance for existing in random_center):\n",
    "            random_center.append(num)\n",
    "        attempts += 1\n",
    "        if attempts > 100:  # Avoid infinite loops\n",
    "            raise ValueError(\n",
    "                \"Failed to generate numbers with the required minimum distance. Try a different min_distance.\")\n",
    "\n",
    "    return np.array(random_center)\n",
    "\n",
    "def get_fitness_score(pre_result_path, adv_file_path, snippet_len, penalty):\n",
    "  \"\"\"\n",
    "  This function calculates the fitness score of the expected adversarial files.\n",
    "\n",
    "  input:\n",
    "  pre_result_path: Path of the predicted results;\n",
    "  adv_file_path: Path of the advesarial files (with labels);\n",
    "\n",
    "  output:\n",
    "  The fitness score of the created adveersrial file.\n",
    "  \"\"\"\n",
    "\n",
    "  f = open(pre_result_path)\n",
    "  line = f.readline()\n",
    "  pre_dic = {}\n",
    "  while line:\n",
    "      split_data = line.split('\\t')\n",
    "      pre_dic[int(split_data[0])] = int(split_data[1].split('\\n')[0])\n",
    "      line = f.readline()\n",
    "  f.close()\n",
    "\n",
    "\n",
    "  test_lines = []\n",
    "  for line in open(adv_file_path, 'r'):\n",
    "    test_lines.append(json.loads(line))\n",
    "  test_data_dic = {}\n",
    "  for i in test_lines:\n",
    "      test_data_dic[i['idx']]=i['target']\n",
    "\n",
    "\n",
    "  pre_list = []\n",
    "  true_list = []\n",
    "  for i in test_data_dic.keys():\n",
    "      pre_list.append(pre_dic[i] )\n",
    "      true_list.append(test_data_dic[i])\n",
    "\n",
    "  return 1 - sklearn.metrics.accuracy_score(true_list,pre_list) - penalty * snippet_len\n",
    "\n",
    "\n",
    "def calcaulate_weight(data, centroid_array):\n",
    "\n",
    "    cluster_num = len(centroid_array)\n",
    "    weight = []\n",
    "\n",
    "    for j in range(cluster_num):\n",
    "        up = data - centroid_array[j]\n",
    "        weights_array = np.array([((up/(data - center))**2)**(1/cluster_num-1) if abs(data - center) > 1e-10 else 1e10 for center in centroid_array])\n",
    "        weight.append(1/np.sum(weights_array))\n",
    "\n",
    "    return np.array(weight)\n",
    "\n",
    "def calculate_cost(weight, data, centroid_array, alpha):\n",
    "\n",
    "    pal_weight = weight ** alpha\n",
    "    dis = np.array([np.abs(data - center) for center in centroid_array])\n",
    "    cost = np.dot(pal_weight, dis)\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def select(pop_dict, centroid, centriod_array, decay_rate):    # nature selection wrt pop's fitness\n",
    "\n",
    "    fitness_values = []\n",
    "    keys_list = []\n",
    "\n",
    "    for key in pop_dict.keys():\n",
    "      fitness_values.append(pop_dict[key])\n",
    "      keys_list.append(key)\n",
    "\n",
    "    sorted_values = sorted(fitness_values, reverse=True)\n",
    "    factor = []\n",
    "    for value in sorted_values:\n",
    "        weights_array = np.array([(((value - centroid) / (value - center)) ** 2) ** (1 / len(centriod_array) - 1) for center in centriod_array])\n",
    "        weight = 1/np.sum(weights_array)\n",
    "        f = (weight ** decay_rate) * np.abs(value - centroid)\n",
    "        factor.append(math.exp(f))\n",
    "\n",
    "    f_sum = np.sum(factor)\n",
    "    p = np.array([element/f_sum for element in factor])\n",
    "    candidate = np.random.choice(sorted_values, p=p.ravel())\n",
    "    index = fitness_values.index(candidate)\n",
    "    can_snippet = keys_list[index]\n",
    "    return can_snippet\n",
    "\n",
    "def update_global_pop(offsprings, total_pop, fit_scores):\n",
    "\n",
    "    pop_num = len(total_pop)\n",
    "\n",
    "    for idx in range(len(offsprings)):\n",
    "        offspring = offsprings[idx]\n",
    "        fit_score = fit_scores[idx]\n",
    "        total_pop[offspring] = fit_score\n",
    "\n",
    "    sorted_pop = dict(sorted(total_pop.items(), key=lambda x: x[1], reverse=True))\n",
    "    current_num = len(sorted_pop)\n",
    "    cut_memeber = list(sorted_pop.keys())[pop_num:current_num]\n",
    "    for member in cut_memeber:\n",
    "        sorted_pop.pop(member)\n",
    "\n",
    "    return sorted_pop\n",
    "\n",
    "def get_vul_idx(label_list, pred, target):\n",
    "    vul_idx = []\n",
    "\n",
    "    for i in label_list:\n",
    "      if pred[i] == 1 and target[i] == 1:\n",
    "        vul_idx.append(i)\n",
    "\n",
    "    return vul_idx\n",
    "\n",
    "def get_vul_codes(test_dicts, vul_idx):\n",
    "    vul_codes = {}\n",
    "\n",
    "    for i in test_dicts:\n",
    "       if i['idx'] in vul_idx:\n",
    "         vul_codes[i['idx']] = i['func']\n",
    "    return vul_codes\n",
    "\n",
    "def read_adv_code_snippet(adv_snippet_file_path):\n",
    "    with open(adv_snippet_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    adver_content = []\n",
    "    for i in range(len(lines)):\n",
    "        if i >= 1:\n",
    "          line_list = lines[i].split()\n",
    "          del line_list[1:3]\n",
    "          line = \" \".join(line_list)\n",
    "          if line != \"\":\n",
    "              adver_content.append(line)\n",
    "\n",
    "    return adver_content\n",
    "\n",
    "def add_adver_sample_2_ast(vul_codes, insert_position, ad_content):\n",
    "\n",
    "    temp = []\n",
    "    names = []\n",
    "    for item in tqdm(vul_codes.keys()):\n",
    "        codes = vul_codes[item].split()\n",
    "        codes_len = len(codes)\n",
    "        # insert_idx = random.randint(0, codes_len)\n",
    "        insert_idx = 15\n",
    "\n",
    "        for i in range(len(ad_content)):\n",
    "            codes.insert(insert_position, ad_content[i])\n",
    "            insert_idx+=1\n",
    "        temp.append(\" \".join(codes))\n",
    "        names.append(item)\n",
    "\n",
    "    return temp, names\n",
    "\n",
    "def write_adv_to_json(ast_test_codes, ast_test_names, ast_test_labels, output_name):\n",
    "    from collections import defaultdict\n",
    "    ast_dicts = []\n",
    "\n",
    "    for i in tqdm(range(len(ast_test_codes))):\n",
    "        record = defaultdict()\n",
    "\n",
    "        record['func'] = ast_test_codes[i]\n",
    "        record['idx'] = i\n",
    "        record['project'] = ast_test_names[i]\n",
    "        record['target'] = ast_test_labels[i]\n",
    "\n",
    "        ast_dicts.append(record)\n",
    "\n",
    "    with open(output_name, 'w') as f:\n",
    "        for data in ast_dicts:\n",
    "            line = json.dumps(data)\n",
    "            f.write(line+'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7e87d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:32.142726Z",
     "iopub.status.busy": "2025-06-03T05:57:32.142379Z",
     "iopub.status.idle": "2025-06-03T05:57:59.309811Z",
     "shell.execute_reply": "2025-06-03T05:57:59.308992Z"
    },
    "papermill": {
     "duration": 27.176888,
     "end_time": "2025-06-03T05:57:59.311009",
     "exception": false,
     "start_time": "2025-06-03T05:57:32.134121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 05:57:47.235857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748930267.456280      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748930267.526224      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import T5ForConditionalGeneration, RobertaTokenizer, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    print(\"Warning: Seaborn not installed. Some visualizations may not work.\")\n",
    "    sns = None\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class CodePreprocessor:\n",
    "    \"\"\"Preprocess code for CodeT5 model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "        self.max_length = 512  # Maximum sequence length for CodeT5\n",
    "    \n",
    "    def preprocess_code(self, code_text):\n",
    "        \"\"\"Basic preprocessing of code text\"\"\"\n",
    "        # Remove extra whitespace\n",
    "        code_text = re.sub(r'\\s+', ' ', code_text)\n",
    "        code_text = code_text.strip()\n",
    "        return code_text\n",
    "    \n",
    "    def tokenize(self, code_text, truncation=True, padding='max_length', return_tensors=None):\n",
    "        \"\"\"Tokenize code text using RobertaTokenizer\"\"\"\n",
    "        processed_code = self.preprocess_code(code_text)\n",
    "        return self.tokenizer(processed_code, \n",
    "                             truncation=truncation, \n",
    "                             max_length=self.max_length,\n",
    "                             padding=padding,\n",
    "                             return_tensors=return_tensors)\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    \"\"\"Dataset for code vulnerability detection using CodeT5\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(text, \n",
    "                                 truncation=True,\n",
    "                                 max_length=self.max_length,\n",
    "                                 padding='max_length',\n",
    "                                 return_tensors='pt')\n",
    "        \n",
    "        # Remove batch dimension added by tokenizer when return_tensors='pt'\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class CodeT5Classifier(nn.Module):\n",
    "    \"\"\"CodeT5 model for code vulnerability detection\"\"\"\n",
    "    \n",
    "    def __init__(self, freeze_base=False, dropout_rate=0.1):\n",
    "        super(CodeT5Classifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained CodeT5 model\n",
    "        self.codet5 = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base\")\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # For classification, we'll use the encoder's last hidden state\n",
    "        # Get hidden size from the model config\n",
    "        self.hidden_size = self.codet5.config.d_model\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(self.hidden_size, 2)  # Binary classification\n",
    "        \n",
    "        # Freeze CodeT5 layers if specified\n",
    "        if freeze_base:\n",
    "            for param in self.codet5.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get CodeT5 encoder outputs\n",
    "        encoder_outputs = self.codet5.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        # Use the mean of the last hidden state for classification\n",
    "        # Shape: (batch_size, sequence_length, hidden_size)\n",
    "        last_hidden_state = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Create a mask to exclude padding tokens from the mean\n",
    "        # Shape: (batch_size, sequence_length, 1)\n",
    "        mask = attention_mask.unsqueeze(-1).float()\n",
    "        \n",
    "        # Apply mask and compute mean over sequence length\n",
    "        # Shape: (batch_size, hidden_size)\n",
    "        pooled_output = torch.sum(last_hidden_state * mask, dim=1) / torch.sum(mask, dim=1)\n",
    "        \n",
    "        # Apply dropout and classify\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits \n",
    "\n",
    "class CodeT5Trainer:\n",
    "    \"\"\"Trainer for CodeT5 model\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=None, batch_size=8, epochs=4, learning_rate=2e-5):\n",
    "        self.preprocessor = CodePreprocessor()\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "        self.best_model_state = None\n",
    "        self.best_val_accuracy = 0.0\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_precision': [],\n",
    "            'val_recall': [],\n",
    "            'val_f1': []\n",
    "        }\n",
    "        self.output_dir = os.path.join(os.getcwd(), 'codet5_outputs')\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        if data_path:\n",
    "            self.load_data(data_path)\n",
    "    \n",
    "    def load_data(self, data_path):\n",
    "        \"\"\"\n",
    "        Load data from file or DataFrame\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to a data file (CSV, Excel, JSON) or a pandas DataFrame\n",
    "        \"\"\"\n",
    "        print(f\"DEBUG: Type of data_path in load_data: {type(data_path)}\")\n",
    "        \n",
    "        # If data_path is already a DataFrame, use it directly\n",
    "        if isinstance(data_path, pd.DataFrame):\n",
    "            self.data = data_path\n",
    "            print(f\"Using provided DataFrame with {len(self.data)} samples.\")\n",
    "            \n",
    "        # If it's a string, try to load from file\n",
    "        elif isinstance(data_path, str):\n",
    "            print(f\"DEBUG: Trying to load from file path: '{data_path}'\")\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if not os.path.exists(data_path):\n",
    "                raise FileNotFoundError(f\"File not found: '{data_path}'\")\n",
    "                \n",
    "            file_ext = os.path.splitext(data_path.lower())[1]\n",
    "            print(f\"DEBUG: File extension detected: '{file_ext}'\")\n",
    "            \n",
    "            if file_ext == '.csv':\n",
    "                self.data = pd.read_csv(data_path)\n",
    "            elif file_ext in ['.xls', '.xlsx']:\n",
    "                self.data = pd.read_excel(data_path)\n",
    "            elif file_ext == '.json':\n",
    "                self.data = pd.read_json(data_path)\n",
    "            elif file_ext == '.pkl' or file_ext == '.pickle':\n",
    "                self.data = pd.read_pickle(data_path)\n",
    "            elif file_ext == '':\n",
    "                # Try to infer the format if no extension is given\n",
    "                try:\n",
    "                    # First try CSV as it's most common\n",
    "                    self.data = pd.read_csv(data_path)\n",
    "                    print(f\"Inferred file format as CSV for: {data_path}\")\n",
    "                except:\n",
    "                    try:\n",
    "                        # Then try JSON\n",
    "                        self.data = pd.read_json(data_path)\n",
    "                        print(f\"Inferred file format as JSON for: {data_path}\")\n",
    "                    except:\n",
    "                        raise ValueError(f\"Could not determine file format for: '{data_path}'. Please specify a file with extension or provide a DataFrame.\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format: '{file_ext}'. Supported formats: CSV, Excel, JSON, Pickle\")\n",
    "        else:\n",
    "            raise TypeError(f\"data_path must be either a string file path or a pandas DataFrame, got {type(data_path).__name__}\")\n",
    "        \n",
    "        # Check if required columns exist\n",
    "        if 'functionSource' not in self.data.columns or 'label' not in self.data.columns:\n",
    "            raise ValueError(\"Data must contain 'functionSource' and 'label' columns.\")\n",
    "        \n",
    "        print(f\"Loaded data with {len(self.data)} samples.\")\n",
    "        print(f\"Label distribution: {self.data['label'].value_counts().to_dict()}\")\n",
    "    \n",
    "    def set_data(self, dataframe):\n",
    "        \"\"\"Set data directly from a pandas DataFrame\"\"\"\n",
    "        if not isinstance(dataframe, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be a pandas DataFrame.\")\n",
    "        \n",
    "        # Check if required columns exist\n",
    "        if 'functionSource' not in dataframe.columns or 'label' not in dataframe.columns:\n",
    "            raise ValueError(\"Data must contain 'functionSource' and 'label' columns.\")\n",
    "        \n",
    "        self.data = dataframe\n",
    "        print(f\"Set data with {len(self.data)} samples.\")\n",
    "        print(f\"Label distribution: {self.data['label'].value_counts().to_dict()}\")\n",
    "    \n",
    "    def prepare_data(self, train_data, test_data):\n",
    "        \"\"\"Prepare data for model training using pre-split train and test data\"\"\"\n",
    "        if self.data is None and (train_data is None or test_data is None):\n",
    "            raise ValueError(\"No data provided. Provide train_data and test_data or call load_data/set_data first.\")\n",
    "        \n",
    "        # Use provided train and test data\n",
    "        train_texts = train_data['functionSource'].values\n",
    "        train_labels = train_data['label'].values\n",
    "        test_texts = test_data['functionSource'].values\n",
    "        test_labels = test_data['label'].values\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = CodeDataset(\n",
    "            train_texts, \n",
    "            train_labels, \n",
    "            self.preprocessor.tokenizer, \n",
    "            self.preprocessor.max_length\n",
    "        )\n",
    "        \n",
    "        test_dataset = CodeDataset(\n",
    "            test_texts, \n",
    "            test_labels, \n",
    "            self.preprocessor.tokenizer, \n",
    "            self.preprocessor.max_length\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        print(f\"Train samples: {len(train_dataset)}\")\n",
    "        print(f\"Test samples: {len(test_dataset)}\")\n",
    "        \n",
    "        return {\n",
    "            'train_loader': train_loader,\n",
    "            'val_loader': test_loader,  # Use test loader for validation\n",
    "            'test_loader': test_loader,\n",
    "            'test_texts': test_texts,\n",
    "            'test_labels': test_labels\n",
    "        } \n",
    "\n",
    "    def run_all(self, data_source=None, train_data=None, test_data=None, freeze_base=False, dataset_name=\"test\"):\n",
    "        \"\"\"Run all steps: data preparation, training, evaluation, and saving\"\"\"\n",
    "        # Load data if provided as a single source\n",
    "        if data_source is not None:\n",
    "            if isinstance(data_source, str):\n",
    "                self.load_data(data_source)\n",
    "            elif isinstance(data_source, pd.DataFrame):\n",
    "                self.set_data(data_source)\n",
    "        \n",
    "        # If train_data and test_data are provided, use them; otherwise, ensure data is loaded\n",
    "        if train_data is not None and test_data is not None:\n",
    "            if not isinstance(train_data, pd.DataFrame) or not isinstance(test_data, pd.DataFrame):\n",
    "                raise ValueError(\"train_data and test_data must be pandas DataFrames.\")\n",
    "            if 'functionSource' not in train_data.columns or 'label' not in train_data.columns:\n",
    "                raise ValueError(\"train_data must contain 'functionSource' and 'label' columns.\")\n",
    "            if 'functionSource' not in test_data.columns or 'label' not in test_data.columns:\n",
    "                raise ValueError(\"test_data must contain 'functionSource' and 'label' columns.\")\n",
    "            print(f\"Using provided train_data with {len(train_data)} samples.\")\n",
    "            print(f\"Using provided test_data with {len(test_data)} samples.\")\n",
    "        elif self.data is None:\n",
    "            raise ValueError(\"No data loaded. Provide data_source or train_data/test_data.\")\n",
    "        \n",
    "        # Prepare data using provided train/test split or loaded data\n",
    "        if train_data is not None and test_data is not None:\n",
    "            data_loaders = self.prepare_data(train_data, test_data)\n",
    "        else:\n",
    "            data_loaders = self.prepare_data(self.data, self.data)  # Fallback (though not used in your case)\n",
    "        \n",
    "        # Train model\n",
    "        self.train_model(data_loaders, freeze_base=freeze_base)\n",
    "        \n",
    "        # Plot training history\n",
    "        self.plot_training_history()\n",
    "        \n",
    "        # Evaluate model with dataset name for proper file naming\n",
    "        results = self.evaluate_model(data_loaders['test_loader'], dataset_name=dataset_name)\n",
    "        \n",
    "        # Save model\n",
    "        model_dir = self.save_model()\n",
    "        \n",
    "        # Save evaluation results\n",
    "        with open(os.path.join(model_dir, 'evaluation_results.json'), 'w') as f:\n",
    "            # Convert numpy values to Python types for JSON serialization\n",
    "            serializable_results = {\n",
    "                k: v if not isinstance(v, np.ndarray) else v.tolist()\n",
    "                for k, v in results.items()\n",
    "            }\n",
    "            json.dump(serializable_results, f)\n",
    "        \n",
    "        print(\"\\n=== Training and Evaluation Complete ===\")\n",
    "        print(f\"All outputs saved to: {model_dir}\")\n",
    "        \n",
    "        # Free up GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def train_model(self, data_loaders, freeze_base=False):\n",
    "        \"\"\"Train the CodeT5 model\"\"\"\n",
    "        # Initialize model\n",
    "        self.model = CodeT5Classifier(freeze_base=freeze_base)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        # Calculate total training steps for learning rate scheduler\n",
    "        total_steps = len(data_loaders['train_loader']) * self.epochs\n",
    "        \n",
    "        # Create learning rate scheduler\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        # Define loss function\n",
    "        criterion = CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop\n",
    "        print(\"\\n=== Training CodeT5 Model ===\")\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.epochs}\")\n",
    "            \n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            progress_bar = tqdm(data_loaders['train_loader'], desc=\"Training\")\n",
    "            for batch in progress_bar:\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                # Zero gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                # Update training loss\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            # Calculate average training loss\n",
    "            avg_train_loss = train_loss / len(data_loaders['train_loader'])\n",
    "            self.history['train_loss'].append(avg_train_loss)\n",
    "            \n",
    "            # Validation phase\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_predictions = []\n",
    "            val_true_labels = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(data_loaders['val_loader'], desc=\"Validation\"):\n",
    "                    # Move batch to device\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = self.model(input_ids, attention_mask)\n",
    "                    \n",
    "                    # Calculate loss\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Update validation loss\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "                    \n",
    "                    # Store predictions and true labels\n",
    "                    val_predictions.extend(preds.cpu().tolist())\n",
    "                    val_true_labels.extend(labels.cpu().tolist())\n",
    "            \n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(data_loaders['val_loader'])\n",
    "            self.history['val_loss'].append(avg_val_loss)\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "            val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
    "                val_true_labels, val_predictions, average='binary'\n",
    "            )\n",
    "            \n",
    "            self.history['val_accuracy'].append(val_accuracy)\n",
    "            self.history['val_precision'].append(val_precision)\n",
    "            self.history['val_recall'].append(val_recall)\n",
    "            self.history['val_f1'].append(val_f1)\n",
    "            \n",
    "            print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "            print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "            print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "            print(f\"Validation F1: {val_f1:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_accuracy > self.best_val_accuracy:\n",
    "                self.best_val_accuracy = val_accuracy\n",
    "                self.best_model_state = self.model.state_dict().copy()\n",
    "                print(f\"New best model with validation accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Load best model for testing\n",
    "        if self.best_model_state is not None:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            print(f\"Loaded best model with validation accuracy: {self.best_val_accuracy:.4f}\")\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot training loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history['train_loss'], label='Training Loss')\n",
    "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot validation metrics\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.plot(self.history['val_precision'], label='Validation Precision')\n",
    "        plt.plot(self.history['val_recall'], label='Validation Recall')\n",
    "        plt.plot(self.history['val_f1'], label='Validation F1')\n",
    "        plt.title('Model Validation Metrics')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate_model(self, test_loader, dataset_name=\"test\", export_predictions=True):\n",
    "        \"\"\"Evaluate the model on test data\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model trained. Call train_model first.\")\n",
    "        \n",
    "        print(\"\\n=== Evaluating Model on Test Set ===\")\n",
    "        \n",
    "        # Explicitly load the best model state for evaluation\n",
    "        if self.best_model_state is not None:\n",
    "            print(f\"Loading best model with validation accuracy: {self.best_val_accuracy:.4f}\")\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            self.model.eval()\n",
    "        else:\n",
    "            print(\"Warning: No best model state found, using current model state\")\n",
    "            self.model.eval()\n",
    "        \n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Get predictions\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                \n",
    "                # Store predictions and true labels\n",
    "                test_predictions.extend(preds.cpu().tolist())\n",
    "                test_true_labels.extend(labels.cpu().tolist())\n",
    "        \n",
    "        # Calculate test metrics\n",
    "        test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(\n",
    "            test_true_labels, test_predictions, average='binary'\n",
    "        )\n",
    "        \n",
    "        # Generate classification report\n",
    "        class_report = classification_report(test_true_labels, test_predictions)\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        conf_matrix = confusion_matrix(test_true_labels, test_predictions)\n",
    "        \n",
    "        print(f\"\\n=== BEST MODEL EVALUATION RESULTS ===\")\n",
    "        if self.best_model_state is not None:\n",
    "            print(f\"Using best model from training (Validation Accuracy: {self.best_val_accuracy:.4f})\")\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"Test Precision: {test_precision:.4f}\")\n",
    "        print(f\"Test Recall: {test_recall:.4f}\")\n",
    "        print(f\"Test F1: {test_f1:.4f}\")\n",
    "        print(\"\\n=== DETAILED CLASSIFICATION REPORT (BEST MODEL) ===\")\n",
    "        print(class_report)\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        if sns is not None:\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                       xticklabels=['Not Vulnerable', 'Vulnerable'],\n",
    "                       yticklabels=['Not Vulnerable', 'Vulnerable'])\n",
    "        else:\n",
    "            # Fallback to matplotlib if seaborn is not available\n",
    "            plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "            plt.colorbar()\n",
    "            # Add text annotations\n",
    "            for i in range(conf_matrix.shape[0]):\n",
    "                for j in range(conf_matrix.shape[1]):\n",
    "                    plt.text(j, i, str(conf_matrix[i, j]), \n",
    "                            ha='center', va='center', color='black')\n",
    "            plt.xticks([0, 1], ['Not Vulnerable', 'Vulnerable'])\n",
    "            plt.yticks([0, 1], ['Not Vulnerable', 'Vulnerable'])\n",
    "        \n",
    "        plt.title(f'Confusion Matrix - Best Model (Val Acc: {self.best_val_accuracy:.4f})')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'confusion_matrix.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': test_accuracy,\n",
    "            'precision': test_precision,\n",
    "            'recall': test_recall,\n",
    "            'f1': test_f1,\n",
    "            'classification_report': class_report,\n",
    "            'confusion_matrix': conf_matrix.tolist(),\n",
    "            'predictions': test_predictions,\n",
    "            'true_labels': test_true_labels,\n",
    "            'best_val_accuracy': self.best_val_accuracy\n",
    "        }\n",
    "        \n",
    "        # Export predictions if requested\n",
    "        if export_predictions:\n",
    "            export_path = self.export_predictions(\n",
    "                test_predictions, \n",
    "                test_true_labels, \n",
    "                dataset_name\n",
    "            )\n",
    "            results['export_path'] = export_path\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_model(self):\n",
    "        \"\"\"Save trained model and tokenizer, and create a zip archive\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"No model to save.\")\n",
    "            return\n",
    "        \n",
    "        # Create timestamp for unique folder\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        model_dir = os.path.join(self.output_dir, f'model')\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        if self.best_model_state is not None:\n",
    "            torch.save(self.best_model_state, os.path.join(model_dir, 'best_model.pt'))\n",
    "        else:\n",
    "            torch.save(self.model.state_dict(), os.path.join(model_dir, 'model.pt'))\n",
    "        \n",
    "        # Save model configuration\n",
    "        model_config = {\n",
    "            'hidden_size': self.model.hidden_size,\n",
    "            'vocab_size': self.preprocessor.tokenizer.vocab_size,\n",
    "            'num_labels': 2,\n",
    "            'max_length': self.preprocessor.max_length\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(model_dir, 'model_config.json'), 'w') as f:\n",
    "            json.dump(model_config, f)\n",
    "        \n",
    "        # Save tokenizer\n",
    "        self.preprocessor.tokenizer.save_pretrained(model_dir)\n",
    "        \n",
    "        # Save training history\n",
    "        with open(os.path.join(model_dir, 'training_history.json'), 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "        \n",
    "        print(f\"Model saved to {model_dir}\")\n",
    "        \n",
    "        # Create zip archive of the model directory\n",
    "        zip_path = f\"{model_dir}_{timestamp}.zip\"\n",
    "        try:\n",
    "            print(f\"Creating zip archive: {zip_path}\")\n",
    "            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                # Walk through the model directory and add all files\n",
    "                for root, dirs, files in os.walk(model_dir):\n",
    "                    for file in files:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        # Create archive path relative to the model directory\n",
    "                        arcname = os.path.relpath(file_path, os.path.dirname(model_dir))\n",
    "                        zipf.write(file_path, arcname)\n",
    "            \n",
    "            # Get zip file size for user feedback\n",
    "            zip_size = os.path.getsize(zip_path)\n",
    "            zip_size_mb = zip_size / (1024 * 1024)\n",
    "            print(f\"‚úÖ Model archive created successfully: {zip_path}\")\n",
    "            print(f\"üì¶ Archive size: {zip_size_mb:.2f} MB\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not create zip archive: {str(e)}\")\n",
    "            print(f\"Model files are still available in: {model_dir}\")\n",
    "        \n",
    "        return model_dir\n",
    "    \n",
    "    def load_model(self, model_dir):\n",
    "        \"\"\"\n",
    "        Load a previously saved CodeT5 model from the specified directory\n",
    "        \n",
    "        Args:\n",
    "            model_dir: Path to the directory containing the saved model\n",
    "            \n",
    "        Returns:\n",
    "            The loaded CodeT5Classifier model\n",
    "        \"\"\"\n",
    "        if not os.path.exists(model_dir):\n",
    "            raise ValueError(f\"Model directory {model_dir} does not exist\")\n",
    "            \n",
    "        print(f\"Loading model from {model_dir}\")\n",
    "        \n",
    "        # Check for model config file\n",
    "        config_path = os.path.join(model_dir, 'model_config.json')\n",
    "        if not os.path.exists(config_path):\n",
    "            raise ValueError(f\"Model config file not found in {model_dir}\")\n",
    "            \n",
    "        # Load model configuration\n",
    "        with open(config_path, 'r') as f:\n",
    "            model_config = json.load(f)\n",
    "            \n",
    "        # Initialize model\n",
    "        self.model = CodeT5Classifier()\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # Check for model state file (either best_model.pt or model.pt)\n",
    "        best_model_path = os.path.join(model_dir, 'best_model.pt')\n",
    "        model_path = os.path.join(model_dir, 'model.pt')\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            state_dict = torch.load(best_model_path, map_location=device)\n",
    "            print(\"Loading best model checkpoint\")\n",
    "        elif os.path.exists(model_path):\n",
    "            state_dict = torch.load(model_path, map_location=device)\n",
    "            print(\"Loading regular model checkpoint\")\n",
    "        else:\n",
    "            raise ValueError(f\"No model checkpoint found in {model_dir}\")\n",
    "            \n",
    "        # Load model state\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.best_model_state = state_dict\n",
    "        \n",
    "        # Load tokenizer if available\n",
    "        tokenizer_path = os.path.join(model_dir, 'special_tokens_map.json')\n",
    "        if os.path.exists(tokenizer_path):\n",
    "            self.preprocessor.tokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "            print(\"Loaded tokenizer from saved model\")\n",
    "            \n",
    "        # Load training history if available\n",
    "        history_path = os.path.join(model_dir, 'training_history.json')\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'r') as f:\n",
    "                self.history = json.load(f)\n",
    "            \n",
    "            # Set best accuracy from history if available\n",
    "            if self.history.get('val_accuracy'):\n",
    "                self.best_val_accuracy = max(self.history['val_accuracy'])\n",
    "                print(f\"Loaded training history. Best validation accuracy: {self.best_val_accuracy:.4f}\")\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "        print(\"Model loaded successfully and set to evaluation mode\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def export_predictions(self, predictions, true_labels=None, dataset_name=\"test\"):\n",
    "        \"\"\"\n",
    "        Export model predictions to a txt file with index and prediction format\n",
    "        \n",
    "        Args:\n",
    "            predictions: List or array of predictions (0 or 1)\n",
    "            true_labels: Optional list of true labels for comparison\n",
    "            dataset_name: Name to include in the filename (e.g., \"test\", \"cwe119\")\n",
    "            \n",
    "        Returns:\n",
    "            Path to the exported file\n",
    "        \"\"\"\n",
    "        # Create timestamp for unique filename\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        \n",
    "        # Create filename\n",
    "        if \"cwe\" in dataset_name.lower():\n",
    "            filename = f\"predict_codet5_{dataset_name}_{timestamp}.txt\"\n",
    "        else:\n",
    "            filename = f\"predict_codet5_cwe_{timestamp}.txt\"\n",
    "        \n",
    "        # Full path for the output file\n",
    "        output_path = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "        # Write predictions to file\n",
    "        with open(output_path, 'w') as f:\n",
    "            for idx, pred in enumerate(predictions):\n",
    "                f.write(f\"{idx}\\t{pred}\\n\")\n",
    "        \n",
    "        print(f\"Predictions exported to: {output_path}\")\n",
    "        print(f\"Total predictions exported: {len(predictions)}\")\n",
    "        \n",
    "        # If true labels are provided, also create a comparison file\n",
    "        if true_labels is not None:\n",
    "            comparison_filename = f\"prediction_comparison_{dataset_name}_{timestamp}.txt\"\n",
    "            comparison_path = os.path.join(self.output_dir, comparison_filename)\n",
    "            \n",
    "            with open(comparison_path, 'w') as f:\n",
    "                f.write(\"Index\\tPrediction\\tTrue_Label\\tCorrect\\n\")\n",
    "                correct_count = 0\n",
    "                for idx, (pred, true) in enumerate(zip(predictions, true_labels)):\n",
    "                    is_correct = pred == true\n",
    "                    if is_correct:\n",
    "                        correct_count += 1\n",
    "                    f.write(f\"{idx}\\t{pred}\\t{true}\\t{is_correct}\\n\")\n",
    "            \n",
    "            accuracy = correct_count / len(predictions) if len(predictions) > 0 else 0\n",
    "            print(f\"Prediction comparison exported to: {comparison_path}\")\n",
    "            print(f\"Accuracy: {accuracy:.4f} ({correct_count}/{len(predictions)})\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def predict(self, code_text):\n",
    "        \"\"\"\n",
    "        Make a prediction on a single code sample\n",
    "        \n",
    "        Args:\n",
    "            code_text: String containing the code to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with prediction results\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model loaded. Call train_model or load_model first.\")\n",
    "        \n",
    "        # Preprocess and tokenize the code\n",
    "        encoding = self.preprocessor.tokenize(\n",
    "            code_text, \n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Move tensors to device\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            confidence, prediction = torch.max(probabilities, dim=1)\n",
    "        \n",
    "        result = {\n",
    "            'prediction': prediction.item(),  # 0: not vulnerable, 1: vulnerable\n",
    "            'confidence': confidence.item(),\n",
    "            'probabilities': probabilities[0].cpu().numpy().tolist(),\n",
    "            'label_names': ['Not Vulnerable', 'Vulnerable']\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "def free_gpu_memory():\n",
    "    \"\"\"Free up GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Example 1: Train and evaluate model on CWE dataset\n",
    "    def train_on_cwe_dataset(cwe_type):\n",
    "        print(f\"\\n=== Training CodeT5 Model on {cwe_type} Dataset ===\")\n",
    "        \n",
    "        # Paths to training and testing data\n",
    "        train_path = f\"{cwe_type}_train.csv\"\n",
    "        test_path = f\"{cwe_type}_test.csv\"\n",
    "        \n",
    "        # Create trainer with default hyperparameters\n",
    "        trainer = CodeT5Trainer(batch_size=8, epochs=3)\n",
    "        \n",
    "        try:\n",
    "            # Load training and testing data\n",
    "            train_data = pd.read_csv(train_path)\n",
    "            test_data = pd.read_csv(test_path)\n",
    "            \n",
    "            # Run training, evaluation, and save model\n",
    "            results = trainer.run_all(\n",
    "                train_data=train_data,\n",
    "                test_data=test_data,\n",
    "                freeze_base=False,  # Don't freeze the base model\n",
    "                dataset_name=cwe_type\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n=== Results for {cwe_type} ===\")\n",
    "            print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "            print(f\"Precision: {results['precision']:.4f}\")\n",
    "            print(f\"Recall: {results['recall']:.4f}\")\n",
    "            print(f\"F1 Score: {results['f1']:.4f}\")\n",
    "            \n",
    "            return trainer, results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training on {cwe_type}: {str(e)}\")\n",
    "            return None, None\n",
    "    \n",
    "    # Example 2: Load a saved model and make predictions\n",
    "    def predict_with_saved_model(model_dir, code_snippet):\n",
    "        print(\"\\n=== Making Predictions with Saved Model ===\")\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = CodeT5Trainer()\n",
    "        \n",
    "        try:\n",
    "            # Load saved model\n",
    "            trainer.load_model(model_dir)\n",
    "            \n",
    "            # Make prediction\n",
    "            result = trainer.predict(code_snippet)\n",
    "            \n",
    "            print(\"\\n=== Prediction Result ===\")\n",
    "            print(f\"Label: {result['label_names'][result['prediction']]}\")\n",
    "            print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "            print(f\"Probabilities: {result['probabilities']}\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error making prediction: {str(e)}\")\n",
    "            return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923465d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:59.331275Z",
     "iopub.status.busy": "2025-06-03T05:57:59.330827Z",
     "iopub.status.idle": "2025-06-03T05:57:59.445106Z",
     "shell.execute_reply": "2025-06-03T05:57:59.444391Z"
    },
    "papermill": {
     "duration": 0.127861,
     "end_time": "2025-06-03T05:57:59.446257",
     "exception": false,
     "start_time": "2025-06-03T05:57:59.318396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    print(\"Warning: Seaborn not installed. Some visualizations may not work.\")\n",
    "\n",
    "# Import CodeT5 trainer and utility function\n",
    "\n",
    "\n",
    "class AdversarialLearning:\n",
    "    \"\"\"\n",
    "    Adversarial Learning class implementing Fuzzy Genetic Algorithm for\n",
    "    optimizing adversarial samples against a CodeT5 vulnerability detection model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, attack_pool_path=\"attack_pool.csv\", model_path=None, \n",
    "                 pop_size=20, clusters=3, max_generations=50, decay_rate=1.5, \n",
    "                 alpha=2.0, penalty=0.01, verbose=1):\n",
    "        \"\"\"\n",
    "        Initialize the Adversarial Learning with FGA\n",
    "        \n",
    "        Args:\n",
    "            attack_pool_path: Path to the attack pool CSV\n",
    "            model_path: Path to the trained CodeT5 model (optional)\n",
    "            pop_size: Population size for genetic algorithm\n",
    "            clusters: Number of fuzzy clusters\n",
    "            max_generations: Maximum number of generations\n",
    "            decay_rate: Decay rate for fuzzy clustering\n",
    "            alpha: Fuzziness factor\n",
    "            penalty: Penalty factor for code snippet length\n",
    "            verbose: Verbosity level\n",
    "        \"\"\"\n",
    "        self.attack_pool_path = attack_pool_path\n",
    "        self.model_path = model_path\n",
    "        self.pop_size = pop_size\n",
    "        self.clusters = clusters\n",
    "        self.max_generations = max_generations\n",
    "        self.decay_rate = decay_rate\n",
    "        self.alpha = alpha\n",
    "        self.penalty = penalty\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Load attack pool\n",
    "        self.attack_pool = self._load_attack_pool()\n",
    "        \n",
    "        # Initialize model trainer and model\n",
    "        self.trainer = None\n",
    "        self.model = None\n",
    "        if model_path:\n",
    "            self._load_model(model_path)\n",
    "        \n",
    "        # Initialize population and centroids\n",
    "        self.population = {}\n",
    "        self.centroids = None\n",
    "        \n",
    "        # Add storage for loaded predictions\n",
    "        self.original_predictions = None\n",
    "        self.prediction_file_path = None\n",
    "        \n",
    "    def _load_attack_pool(self):\n",
    "        \"\"\"Load the attack pool CSV file\"\"\"\n",
    "        if not os.path.exists(self.attack_pool_path):\n",
    "            raise FileNotFoundError(f\"Attack pool file not found: {self.attack_pool_path}\")\n",
    "        \n",
    "        attack_pool = pd.read_csv(self.attack_pool_path)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n=== ATTACK POOL LOADING ===\")\n",
    "            print(f\"Raw attack pool shape: {attack_pool.shape}\")\n",
    "            print(f\"Available columns: {list(attack_pool.columns)}\")\n",
    "        \n",
    "        # Handle different attack pool formats - only expect adversarial code\n",
    "        if 'adversarial_code' in attack_pool.columns:\n",
    "            # Standard format: adversarial_code column\n",
    "            if self.verbose:\n",
    "                print(f\"Detected attack pool format with 'adversarial_code' column\")\n",
    "            attack_pool_standardized = attack_pool[['adversarial_code']].copy()\n",
    "            \n",
    "        else:\n",
    "            # Try to auto-detect format based on available columns\n",
    "            available_columns = list(attack_pool.columns)\n",
    "            if self.verbose:\n",
    "                print(f\"Available columns in attack pool: {available_columns}\")\n",
    "            \n",
    "            # If there's only one column, assume it contains adversarial code\n",
    "            if len(available_columns) == 1:\n",
    "                adversarial_column = available_columns[0]\n",
    "                if self.verbose:\n",
    "                    print(f\"Using single column '{adversarial_column}' as adversarial code\")\n",
    "                \n",
    "                attack_pool_standardized = pd.DataFrame({\n",
    "                    'adversarial_code': attack_pool[adversarial_column].values\n",
    "                })\n",
    "            else:\n",
    "                raise ValueError(f\"Attack pool format not recognized. Expected 'adversarial_code' column. Found columns: {available_columns}\")\n",
    "        \n",
    "        # Remove any rows with NaN values\n",
    "        initial_size = len(attack_pool_standardized)\n",
    "        attack_pool_standardized = attack_pool_standardized.dropna()\n",
    "        final_size = len(attack_pool_standardized)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Attack pool processed successfully:\")\n",
    "            print(f\"  Initial size: {initial_size}\")\n",
    "            print(f\"  After removing NaN: {final_size}\")\n",
    "            print(f\"  Final shape: {attack_pool_standardized.shape}\")\n",
    "            print(f\"Sample adversarial codes:\")\n",
    "            for i, code in enumerate(attack_pool_standardized['adversarial_code'].head(3)):\n",
    "                print(f\"  [{i+1}] {code[:100]}{'...' if len(code) > 100 else ''}\")\n",
    "        \n",
    "        return attack_pool_standardized\n",
    "    \n",
    "    def _load_model(self, model_path):\n",
    "        \"\"\"Load the CodeT5 model\"\"\"\n",
    "        try:\n",
    "            # Initialize the trainer\n",
    "            self.trainer = CodeT5Trainer()\n",
    "            \n",
    "            # Load model from saved path\n",
    "            if os.path.exists(model_path):\n",
    "                self.model = self.trainer.load_model(model_path)\n",
    "                \n",
    "                # CRITICAL FIX: Ensure model is in evaluation mode\n",
    "                if self.model is not None:\n",
    "                    self.model.eval()\n",
    "                    # Also ensure trainer's model is in eval mode\n",
    "                    if hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                        self.trainer.model.eval()\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"Successfully loaded model from {model_path}\")\n",
    "                    print(f\"Model is in eval mode: {not self.model.training}\")\n",
    "                    \n",
    "                    # Test model prediction to verify it's working\n",
    "                    test_code = \"void test() { char buf[10]; }\"\n",
    "                    try:\n",
    "                        test_pred = self.trainer.predict(test_code)\n",
    "                        print(f\"Model test prediction: {test_pred}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Model test prediction failed: {str(e)}\")\n",
    "            else:\n",
    "                self.model = None\n",
    "                if self.verbose:\n",
    "                    print(f\"Model path {model_path} not found. Will train a new model when needed.\")\n",
    "        except Exception as e:\n",
    "            self.model = None\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            print(f\"Model path attempted: {model_path}\")\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Path exists but model loading failed\")\n",
    "                # List files in model directory for debugging\n",
    "                if os.path.isdir(model_path):\n",
    "                    print(f\"Files in model directory: {os.listdir(model_path)}\")\n",
    "            else:\n",
    "                print(f\"Model path does not exist\")\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize the population with random adversarial code snippets\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"\\n=== POPULATION INITIALIZATION ===\")\n",
    "            print(f\"Attack pool size: {len(self.attack_pool)}\")\n",
    "            print(f\"Requested population size: {self.pop_size}\")\n",
    "        \n",
    "        # Sample from attack pool to create initial population\n",
    "        if len(self.attack_pool) < self.pop_size:\n",
    "            # If attack pool is smaller than pop_size, duplicate some samples\n",
    "            indices = np.random.choice(len(self.attack_pool), self.pop_size, replace=True)\n",
    "            if self.verbose:\n",
    "                print(f\"Attack pool smaller than population size - sampling with replacement\")\n",
    "        else:\n",
    "            # Sample without replacement\n",
    "            indices = np.random.choice(len(self.attack_pool), self.pop_size, replace=False)\n",
    "            if self.verbose:\n",
    "                print(f\"Attack pool larger than population size - sampling without replacement\")\n",
    "        \n",
    "        # Initialize population dictionary with fitness scores set to 0\n",
    "        self.population = {}\n",
    "        for idx in indices:\n",
    "            adv_code = self.attack_pool.iloc[idx]['adversarial_code']\n",
    "            self.population[adv_code] = 0  # Initial fitness score\n",
    "        \n",
    "        # Initialize centroids from uniform distribution\n",
    "        min_distance = 1.0 / (self.clusters * 2)  # Ensure centroids are reasonably spaced\n",
    "        self.centroids = centriod_init(self.clusters, min_distance)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Population successfully initialized:\")\n",
    "            print(f\"  Population size: {len(self.population)}\")\n",
    "            print(f\"  Unique adversarial codes: {len(set(self.population.keys()))}\")\n",
    "            print(f\"  Clusters: {self.clusters}\")\n",
    "            print(f\"  Initial centroids: {self.centroids}\")\n",
    "            \n",
    "            # Show a few sample adversarial codes from the population\n",
    "            print(f\"Sample population codes:\")\n",
    "            for i, code in enumerate(list(self.population.keys())[:3]):\n",
    "                print(f\"  [{i+1}] {code[:80]}{'...' if len(code) > 80 else ''}\")\n",
    "        \n",
    "        return self.population, self.centroids\n",
    "    \n",
    "    def calculate_fitness(self, original_df, adversarial_code, model=None, return_attack_rate=False):\n",
    "        \"\"\"\n",
    "        Calculate fitness score for an adversarial code snippet\n",
    "        \n",
    "        Args:\n",
    "            original_df: DataFrame containing original code\n",
    "            adversarial_code: Adversarial code snippet\n",
    "            model: Trained model (if None, will use loaded predictions from txt)\n",
    "            \n",
    "        Returns:\n",
    "            Fitness score based on attack success rate and snippet length\n",
    "        \"\"\"\n",
    "        # Create a copy of the original dataframe\n",
    "        adv_df = original_df.copy()\n",
    "        \n",
    "        # Apply the adversarial code to each sample\n",
    "        # Only add adversarial code to samples labeled as vulnerable (label=1)\n",
    "        vulnerable_samples = adv_df['label'] == 1\n",
    "        num_vulnerable = vulnerable_samples.sum()\n",
    "        \n",
    "        if num_vulnerable == 0:\n",
    "            # If no vulnerable samples, make some samples vulnerable for testing\n",
    "            if self.verbose >= 2:\n",
    "                print(\"No vulnerable samples found. Creating synthetic vulnerable samples.\")\n",
    "            # Mark a portion of samples as vulnerable for testing\n",
    "            sample_indices = np.random.choice(len(adv_df), max(1, len(adv_df) // 4), replace=False)\n",
    "            adv_df.loc[sample_indices, 'label'] = 1\n",
    "            vulnerable_samples = adv_df['label'] == 1\n",
    "            num_vulnerable = vulnerable_samples.sum()\n",
    "        \n",
    "        # ENHANCED DIAGNOSTICS: Show dataset composition\n",
    "        if self.verbose >= 2:\n",
    "            total_samples = len(original_df)\n",
    "            vulnerable_labeled = (original_df['label'] == 1).sum()\n",
    "            benign_labeled = (original_df['label'] == 0).sum()\n",
    "            print(f\"\\n=== DATASET COMPOSITION ===\")\n",
    "            print(f\"Total samples: {total_samples}\")\n",
    "            print(f\"Labeled as vulnerable: {vulnerable_labeled}\")\n",
    "            print(f\"Labeled as benign: {benign_labeled}\")\n",
    "            print(f\"Applying adversarial code to {num_vulnerable} vulnerable samples\")\n",
    "        \n",
    "        # Use loaded predictions if available, otherwise use model\n",
    "        if self.original_predictions is not None:\n",
    "            if self.verbose >= 2:\n",
    "                print(\"Using loaded predictions from txt file\")\n",
    "            \n",
    "            # Ensure predictions match the dataset size\n",
    "            if len(self.original_predictions) != len(original_df):\n",
    "                print(f\"Warning: Prediction length ({len(self.original_predictions)}) doesn't match dataset length ({len(original_df)})\")\n",
    "                # Try to align predictions with dataset\n",
    "                if len(self.original_predictions) > len(original_df):\n",
    "                    original_predictions = self.original_predictions[:len(original_df)]\n",
    "                else:\n",
    "                    # Pad with zeros if needed\n",
    "                    original_predictions = np.pad(self.original_predictions, \n",
    "                                                (0, len(original_df) - len(self.original_predictions)), \n",
    "                                                constant_values=0)\n",
    "            else:\n",
    "                original_predictions = self.original_predictions.copy()\n",
    "        else:\n",
    "            # Fall back to model predictions if no txt file is loaded\n",
    "            if self.verbose >= 2:\n",
    "                print(\"No loaded predictions found, using model to predict\")\n",
    "            \n",
    "            # Set verbosity based on self.verbose level\n",
    "            if self.verbose <= 1:\n",
    "                # Temporarily reduce print output\n",
    "                old_stdout = sys.stdout\n",
    "                sys.stdout = open(os.devnull, 'w')\n",
    "            \n",
    "            # Function to get predictions using the model directly\n",
    "            def get_predictions(df):\n",
    "                predictions = []\n",
    "                try:\n",
    "                    # CRITICAL FIX: Ensure model is in evaluation mode before predictions\n",
    "                    if hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                        self.trainer.model.eval()\n",
    "                    \n",
    "                    for _, row in df.iterrows():\n",
    "                        code = row['functionSource']\n",
    "                        # Try the trainer's predict method with error handling\n",
    "                        try:\n",
    "                            pred = self.trainer.predict(code)\n",
    "                            if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                                predictions.append(pred['prediction'])\n",
    "                            else:\n",
    "                                # If the predict method returns an unexpected format,\n",
    "                                # just use a default prediction of non-vulnerable\n",
    "                                if self.verbose >= 2:\n",
    "                                    print(f\"Predict returned unexpected format: {pred}\")\n",
    "                                predictions.append(0)  # Default to non-vulnerable\n",
    "                        except Exception as e:\n",
    "                            if self.verbose >= 2:\n",
    "                                print(f\"Error in prediction for sample: {str(e)}\")\n",
    "                                print(f\"Code length: {len(code)}\")\n",
    "                            # Default to predicting as non-vulnerable (0) if there's an error\n",
    "                            predictions.append(0)\n",
    "                except Exception as e:\n",
    "                    if self.verbose >= 2:\n",
    "                        print(f\"Error in get_predictions: {str(e)}\")\n",
    "                    # Return all zeros if there's a major error\n",
    "                    predictions = [0] * len(df)\n",
    "                return np.array(predictions)\n",
    "            \n",
    "            # Get predictions on original data\n",
    "            original_predictions = get_predictions(original_df)\n",
    "            \n",
    "            if self.verbose <= 1:\n",
    "                # Restore print output\n",
    "                sys.stdout.close()\n",
    "                sys.stdout = old_stdout\n",
    "\n",
    "        # Count initially vulnerable samples that were correctly predicted as vulnerable\n",
    "        vulnerable_indices = np.where(vulnerable_samples)[0]\n",
    "        correctly_identified_vulnerabilities = sum(1 for i in vulnerable_indices \n",
    "                                                 if original_predictions[i] == 1)\n",
    "\n",
    "        # ENHANCED DIAGNOSTICS: Show model performance breakdown\n",
    "        if self.verbose >= 2:\n",
    "            print(f\"\\n=== MODEL PERFORMANCE BREAKDOWN ===\")\n",
    "            \n",
    "            # Count predictions by true label\n",
    "            true_vulnerable_indices = np.where(original_df['label'] == 1)[0]\n",
    "            true_benign_indices = np.where(original_df['label'] == 0)[0]\n",
    "            \n",
    "            # For vulnerable samples\n",
    "            vuln_pred_as_vuln = sum(1 for i in true_vulnerable_indices if original_predictions[i] == 1)\n",
    "            vuln_pred_as_benign = sum(1 for i in true_vulnerable_indices if original_predictions[i] == 0)\n",
    "            \n",
    "            # For benign samples  \n",
    "            benign_pred_as_vuln = sum(1 for i in true_benign_indices if original_predictions[i] == 1)\n",
    "            benign_pred_as_benign = sum(1 for i in true_benign_indices if original_predictions[i] == 0)\n",
    "            \n",
    "            print(f\"Vulnerable samples (label=1): {len(true_vulnerable_indices)} total\")\n",
    "            print(f\"  ‚Üí Predicted as vulnerable: {vuln_pred_as_vuln}\")\n",
    "            print(f\"  ‚Üí Predicted as benign: {vuln_pred_as_benign}\")\n",
    "            print(f\"Benign samples (label=0): {len(true_benign_indices)} total\")\n",
    "            print(f\"  ‚Üí Predicted as vulnerable: {benign_pred_as_vuln}\")\n",
    "            print(f\"  ‚Üí Predicted as benign: {benign_pred_as_benign}\")\n",
    "            \n",
    "            model_accuracy = (vuln_pred_as_vuln + benign_pred_as_benign) / len(original_df)\n",
    "            vulnerable_recall = vuln_pred_as_vuln / len(true_vulnerable_indices) if len(true_vulnerable_indices) > 0 else 0\n",
    "            \n",
    "            print(f\"Model accuracy: {model_accuracy:.4f}\")\n",
    "            print(f\"Vulnerable recall: {vulnerable_recall:.4f}\")\n",
    "            print(f\"Samples available for attack: {correctly_identified_vulnerabilities}\")\n",
    "        \n",
    "        if correctly_identified_vulnerabilities == 0:\n",
    "            if self.verbose >= 2:\n",
    "                print(\"No vulnerabilities correctly identified by model. Attack cannot succeed.\")\n",
    "            # Return zero fitness since we can't measure attack success\n",
    "            if return_attack_rate:\n",
    "                return 0.0, 0.0\n",
    "            else:\n",
    "                return 0.0\n",
    "        \n",
    "        # Insert adversarial code into vulnerable samples using improved strategies\n",
    "        for idx in adv_df.index[vulnerable_samples]:\n",
    "            # Skip samples not originally predicted as vulnerable\n",
    "            if original_predictions[idx] != 1:\n",
    "                continue\n",
    "                \n",
    "            # Insert adversarial code using multiple improved strategies\n",
    "            orig_code = adv_df.loc[idx, 'functionSource']\n",
    "            \n",
    "            # Strategy 1: Insert at function level (after function declaration)\n",
    "            # Strategy 2: Insert at variable declaration level\n",
    "            # Strategy 3: Insert at loop/conditional level\n",
    "            # Strategy 4: Insert at critical computation points\n",
    "            \n",
    "            code_lines = orig_code.split('\\n')\n",
    "            code_len = len(code_lines)\n",
    "            \n",
    "            # More sophisticated insertion strategy\n",
    "            # Look for function declarations, variable declarations, loops, etc.\n",
    "            enhanced_code_lines = code_lines.copy()\n",
    "            insertions_made = 0\n",
    "            \n",
    "            for i, line in enumerate(code_lines):\n",
    "                line_stripped = line.strip().lower()\n",
    "                \n",
    "                # Insert after function declarations\n",
    "                if (any(keyword in line_stripped for keyword in ['void ', 'int ', 'char ', 'function ', 'def ']) and \n",
    "                    ('(' in line and ')' in line and '{' in line) and insertions_made < 2):\n",
    "                    enhanced_code_lines.insert(i + 1 + insertions_made, f\"    {adversarial_code}\")\n",
    "                    insertions_made += 1\n",
    "                \n",
    "                # Insert before variable declarations involving user input\n",
    "                elif (any(keyword in line_stripped for keyword in ['scanf', 'gets', 'input', 'read']) and \n",
    "                      insertions_made < 3):\n",
    "                    enhanced_code_lines.insert(i + insertions_made, f\"    {adversarial_code}\")\n",
    "                    insertions_made += 1\n",
    "                \n",
    "                # Insert in loop bodies\n",
    "                elif (any(keyword in line_stripped for keyword in ['for ', 'while ', 'do ']) and \n",
    "                      insertions_made < 2):\n",
    "                    enhanced_code_lines.insert(i + 1 + insertions_made, f\"        {adversarial_code}\")\n",
    "                    insertions_made += 1\n",
    "            \n",
    "            # If no strategic insertions were made, fall back to fixed positions\n",
    "            if insertions_made == 0:\n",
    "                # Use more aggressive insertion at multiple fixed positions\n",
    "                positions = [\n",
    "                    min(2, code_len - 1),     # Near the beginning\n",
    "                    code_len // 2,            # Middle\n",
    "                    max(1, code_len - 2)      # Near the end\n",
    "                ]\n",
    "                \n",
    "                for i, pos in enumerate(positions):\n",
    "                    enhanced_code_lines.insert(pos + i, f\"    {adversarial_code}\")\n",
    "            \n",
    "            # Apply the modified code\n",
    "            adv_df.loc[idx, 'functionSource'] = '\\n'.join(enhanced_code_lines)\n",
    "        \n",
    "        # Get adversarial predictions\n",
    "        if self.original_predictions is not None and hasattr(self, 'trainer') and self.trainer is not None:\n",
    "            # Use model to predict adversarial samples since we need new predictions\n",
    "            if self.verbose >= 2:\n",
    "                print(\"Using model to predict adversarial samples\")\n",
    "            \n",
    "            # Set verbosity based on self.verbose level\n",
    "            if self.verbose <= 1:\n",
    "                # Temporarily reduce print output\n",
    "                old_stdout = sys.stdout\n",
    "                sys.stdout = open(os.devnull, 'w')\n",
    "            \n",
    "            # Function to get predictions using the model directly\n",
    "            def get_adversarial_predictions(df):\n",
    "                predictions = []\n",
    "                try:\n",
    "                    # CRITICAL FIX: Ensure model is in evaluation mode before predictions\n",
    "                    if hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                        self.trainer.model.eval()\n",
    "                    \n",
    "                    for _, row in df.iterrows():\n",
    "                        code = row['functionSource']\n",
    "                        # Try the trainer's predict method with error handling\n",
    "                        try:\n",
    "                            pred = self.trainer.predict(code)\n",
    "                            if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                                predictions.append(pred['prediction'])\n",
    "                            else:\n",
    "                                predictions.append(0)  # Default to non-vulnerable\n",
    "                        except Exception as e:\n",
    "                            if self.verbose >= 2:\n",
    "                                print(f\"Error in adversarial prediction for sample: {str(e)}\")\n",
    "                            predictions.append(0)\n",
    "                except Exception as e:\n",
    "                    if self.verbose >= 2:\n",
    "                        print(f\"Error in get_adversarial_predictions: {str(e)}\")\n",
    "                    predictions = [0] * len(df)\n",
    "                return np.array(predictions)\n",
    "            \n",
    "            # Get predictions on adversarial data\n",
    "            adversarial_predictions = get_adversarial_predictions(adv_df)\n",
    "            \n",
    "            if self.verbose <= 1:\n",
    "                # Restore print output\n",
    "                sys.stdout.close()\n",
    "                sys.stdout = old_stdout\n",
    "        else:\n",
    "            # If no model available, assume adversarial attack fails\n",
    "            adversarial_predictions = original_predictions.copy()\n",
    "        \n",
    "        # FIXED: Calculate attack success rate properly\n",
    "        # Focus only on vulnerable samples that were correctly identified initially\n",
    "        initially_vulnerable_and_detected = []\n",
    "        for i in vulnerable_indices:\n",
    "            if original_predictions[i] == 1:  # Was correctly identified as vulnerable\n",
    "                initially_vulnerable_and_detected.append(i)\n",
    "        \n",
    "        # Count successful attacks (vulnerable samples that became non-vulnerable)\n",
    "        successful_attacks = 0\n",
    "        total_prediction_changes = 0\n",
    "        zero_to_one = 0  # Non-vulnerable to vulnerable\n",
    "        one_to_zero = 0  # Vulnerable to non-vulnerable (this is what we want)\n",
    "        \n",
    "        for i in initially_vulnerable_and_detected:\n",
    "            if adversarial_predictions[i] != original_predictions[i]:\n",
    "                total_prediction_changes += 1\n",
    "                if original_predictions[i] == 1 and adversarial_predictions[i] == 0:\n",
    "                    successful_attacks += 1\n",
    "                    one_to_zero += 1\n",
    "        \n",
    "        # Also check all samples for any changes (for debugging)\n",
    "        for i in range(len(original_predictions)):\n",
    "            if original_predictions[i] != adversarial_predictions[i]:\n",
    "                if original_predictions[i] == 0 and adversarial_predictions[i] == 1:\n",
    "                    zero_to_one += 1\n",
    "        \n",
    "        # Calculate attack success rate based on initially vulnerable and detected samples only\n",
    "        if len(initially_vulnerable_and_detected) > 0:\n",
    "            attack_success_rate = successful_attacks / len(initially_vulnerable_and_detected)\n",
    "        else:\n",
    "            attack_success_rate = 0.0\n",
    "        \n",
    "        if self.verbose >= 2:\n",
    "            print(f\"Attack success rate: {attack_success_rate:.4f} ({successful_attacks}/{len(initially_vulnerable_and_detected)} samples changed prediction)\")\n",
    "            print(f\"  - 0‚Üí1 changes: {zero_to_one}/{len(original_predictions)} ({zero_to_one/len(original_predictions):.4f})\")\n",
    "            print(f\"  - 1‚Üí0 changes: {one_to_zero}/{len(original_predictions)} ({one_to_zero/len(original_predictions):.4f})\")\n",
    "        \n",
    "        # Calculate penalty for code snippet length\n",
    "        snippet_length = len(adversarial_code.splitlines())\n",
    "        length_penalty = self.penalty * snippet_length\n",
    "        \n",
    "        # Calculate fitness score - heavily weight attack success\n",
    "        # Use a more aggressive fitness function that rewards high attack success rates\n",
    "        if attack_success_rate > 0.8:  # Bonus for very high success rates\n",
    "            fitness_score = attack_success_rate + 0.2 - length_penalty\n",
    "        elif attack_success_rate > 0.5:  # Bonus for moderate success rates\n",
    "            fitness_score = attack_success_rate + 0.1 - length_penalty\n",
    "        else:\n",
    "            fitness_score = attack_success_rate - length_penalty\n",
    "        \n",
    "        if self.verbose >= 2:\n",
    "            print(f\"Adversarial snippet length: {snippet_length}\")\n",
    "            print(f\"Length penalty: {length_penalty:.4f}\")\n",
    "            print(f\"Fitness score: {fitness_score:.4f}\")\n",
    "        \n",
    "        if return_attack_rate:\n",
    "            return fitness_score, attack_success_rate\n",
    "        else:\n",
    "            return fitness_score\n",
    "    \n",
    "    def perform_fuzzy_clustering(self):\n",
    "        \"\"\"Perform fuzzy clustering on the population\"\"\"\n",
    "        # Get fitness scores as array\n",
    "        keys = list(self.population.keys())\n",
    "        scores = np.array([self.population[k] for k in keys])\n",
    "        \n",
    "        # Calculate fuzzy membership weights for each sample\n",
    "        membership_weights = {}\n",
    "        for key, score in zip(keys, scores):\n",
    "            weight = calcaulate_weight(score, self.centroids)\n",
    "            membership_weights[key] = weight\n",
    "        \n",
    "        # Update centroids based on weighted scores\n",
    "        new_centroids = np.zeros_like(self.centroids)\n",
    "        for k in range(len(self.centroids)):\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            \n",
    "            for key, score in zip(keys, scores):\n",
    "                weight = membership_weights[key][k]\n",
    "                weight_alpha = weight ** self.alpha\n",
    "                numerator += weight_alpha * score\n",
    "                denominator += weight_alpha\n",
    "            \n",
    "            new_centroids[k] = numerator / denominator if denominator > 0 else self.centroids[k]\n",
    "        \n",
    "        # Check for convergence\n",
    "        centroid_change = np.sum(np.abs(new_centroids - self.centroids))\n",
    "        self.centroids = new_centroids\n",
    "        \n",
    "        if self.verbose >= 2:\n",
    "            print(f\"Updated centroids: {self.centroids}\")\n",
    "            print(f\"Centroid change: {centroid_change:.6f}\")\n",
    "        \n",
    "        return membership_weights, centroid_change\n",
    "    \n",
    "    def select_clusters(self):\n",
    "        \"\"\"Select top 2 clusters based on centroid magnitude\"\"\"\n",
    "        # Sort centroids by magnitude (fitness score)\n",
    "        sorted_indices = np.argsort(self.centroids)[::-1]\n",
    "        top_clusters = sorted_indices[:2]  # Select top 2 clusters\n",
    "        \n",
    "        if self.verbose >= 2:\n",
    "            print(f\"Selected top clusters: {top_clusters} with centroids {self.centroids[top_clusters]}\")\n",
    "        \n",
    "        return top_clusters\n",
    "    \n",
    "    def perform_crossover(self, membership_weights, top_clusters):\n",
    "        \"\"\"Perform crossover operation to create offspring\"\"\"\n",
    "        keys = list(self.population.keys())\n",
    "        \n",
    "        # Select parents from top clusters\n",
    "        parents = []\n",
    "        for _ in range(self.pop_size // 2):  # Create pop_size/2 offspring\n",
    "            # Use the original select function from fga_selection.py with error handling\n",
    "            try:\n",
    "                # Select parent from first top cluster\n",
    "                parent1 = select(self.population, self.centroids[top_clusters[0]], \n",
    "                                self.centroids, self.decay_rate)\n",
    "                \n",
    "                # Select parent from second top cluster  \n",
    "                parent2 = select(self.population, self.centroids[top_clusters[1]], \n",
    "                                self.centroids, self.decay_rate)\n",
    "                \n",
    "                parents.append((parent1, parent2))\n",
    "            except (ZeroDivisionError, ValueError, np.linalg.LinAlgError, OverflowError) as e:\n",
    "                # Handle numerical issues from original select function\n",
    "                if self.verbose >= 2:\n",
    "                    print(f\"Numerical error in parent selection: {str(e)}\")\n",
    "                    print(\"Falling back to random selection\")\n",
    "                \n",
    "                parent1 = random.choice(keys)\n",
    "                parent2 = random.choice(keys)\n",
    "                parents.append((parent1, parent2))\n",
    "            except Exception as e:\n",
    "                # Fallback to random selection if there's any other issue\n",
    "                if self.verbose >= 2:\n",
    "                    print(f\"Error in parent selection: {str(e)}\")\n",
    "                    print(\"Falling back to random selection\")\n",
    "                \n",
    "                parent1 = random.choice(keys)\n",
    "                parent2 = random.choice(keys)\n",
    "                parents.append((parent1, parent2))\n",
    "        \n",
    "        # Create offspring through improved crossover strategies\n",
    "        offspring = []\n",
    "        for parent1, parent2 in parents:\n",
    "            # Enhanced crossover: create multiple offspring variations per parent pair\n",
    "            for variation in range(2):  # Create 2 variations per parent pair\n",
    "                p1_lines = parent1.split('\\n')\n",
    "                p2_lines = parent2.split('\\n')\n",
    "                \n",
    "                # Intelligent crossover that preserves vulnerability patterns\n",
    "                if len(p1_lines) <= 1 or len(p2_lines) <= 1:\n",
    "                    # For very short snippets, combine them strategically\n",
    "                    if variation == 0:\n",
    "                        child = parent1 + '; ' + parent2  # Combine on same line\n",
    "                    else:\n",
    "                        child = parent1 + '\\n' + parent2  # Combine on separate lines\n",
    "                else:\n",
    "                    # Multiple sophisticated crossover strategies\n",
    "                    strategy = random.choice(['semantic_mix', 'vulnerability_focused', 'pattern_preservation', 'obfuscation_mix'])\n",
    "                    \n",
    "                    if strategy == 'semantic_mix':\n",
    "                        # Mix based on semantic patterns (vulnerabilities vs normal code)\n",
    "                        vuln_keywords = ['malloc', 'free', 'strcpy', 'gets', 'sprintf', 'system', 'exec']\n",
    "                        \n",
    "                        # Separate vulnerable and normal lines\n",
    "                        p1_vuln = [line for line in p1_lines if any(kw in line.lower() for kw in vuln_keywords)]\n",
    "                        p1_normal = [line for line in p1_lines if not any(kw in line.lower() for kw in vuln_keywords)]\n",
    "                        p2_vuln = [line for line in p2_lines if any(kw in line.lower() for kw in vuln_keywords)]\n",
    "                        p2_normal = [line for line in p2_lines if not any(kw in line.lower() for kw in vuln_keywords)]\n",
    "                        \n",
    "                        # Combine vulnerable parts from both parents with normal parts\n",
    "                        child_lines = []\n",
    "                        if p1_vuln: child_lines.extend(p1_vuln[:2])  # Take first 2 vuln lines from p1\n",
    "                        if p2_normal: child_lines.extend(p2_normal[:1])  # Mix with normal from p2\n",
    "                        if p2_vuln: child_lines.extend(p2_vuln[:2])  # Take vuln lines from p2\n",
    "                        if p1_normal: child_lines.extend(p1_normal[:1])  # Mix with normal from p1\n",
    "                    \n",
    "                    elif strategy == 'vulnerability_focused':\n",
    "                        # Focus on combining different types of vulnerabilities\n",
    "                        # Take the most dangerous-looking lines from each parent\n",
    "                        danger_keywords = ['overflow', 'injection', 'format', 'buffer', 'memory', 'null', 'free', 'alloc']\n",
    "                        \n",
    "                        p1_danger = [line for line in p1_lines if any(kw in line.lower() for kw in danger_keywords)]\n",
    "                        p2_danger = [line for line in p2_lines if any(kw in line.lower() for kw in danger_keywords)]\n",
    "                        \n",
    "                        child_lines = []\n",
    "                        # Interleave dangerous patterns\n",
    "                        max_danger = max(len(p1_danger), len(p2_danger))\n",
    "                        for i in range(max_danger):\n",
    "                            if i < len(p1_danger):\n",
    "                                child_lines.append(p1_danger[i])\n",
    "                            if i < len(p2_danger):\n",
    "                                child_lines.append(p2_danger[i])\n",
    "                        \n",
    "                        # Fill in with remaining lines if needed\n",
    "                        if not child_lines:\n",
    "                            child_lines = p1_lines[:len(p1_lines)//2] + p2_lines[len(p2_lines)//2:]\n",
    "                    \n",
    "                    elif strategy == 'pattern_preservation':\n",
    "                        # Preserve important patterns while mixing\n",
    "                        # Look for function calls, variable declarations, etc.\n",
    "                        p1_funcs = [line for line in p1_lines if '(' in line and ')' in line]\n",
    "                        p1_vars = [line for line in p1_lines if any(typ in line.lower() for typ in ['char', 'int', 'void', 'size_t'])]\n",
    "                        p2_funcs = [line for line in p2_lines if '(' in line and ')' in line]\n",
    "                        p2_vars = [line for line in p2_lines if any(typ in line.lower() for typ in ['char', 'int', 'void', 'size_t'])]\n",
    "                        \n",
    "                        child_lines = []\n",
    "                        # Combine variable declarations and function calls strategically\n",
    "                        if p1_vars: child_lines.extend(p1_vars[:2])\n",
    "                        if p2_funcs: child_lines.extend(p2_funcs[:2])\n",
    "                        if p2_vars: child_lines.extend(p2_vars[:1])\n",
    "                        if p1_funcs: child_lines.extend(p1_funcs[:2])\n",
    "                    \n",
    "                    else:  # obfuscation_mix\n",
    "                        # Create obfuscated combinations\n",
    "                        # Take parts from each parent and add obfuscating comments\n",
    "                        p1_half = len(p1_lines) // 2\n",
    "                        p2_half = len(p2_lines) // 2\n",
    "                        \n",
    "                        child_lines = []\n",
    "                        child_lines.extend(p1_lines[:p1_half])\n",
    "                        child_lines.append(\"// Security check passed\")  # Obfuscating comment\n",
    "                        child_lines.extend(p2_lines[p2_half:])\n",
    "                        if random.random() < 0.5:\n",
    "                            child_lines.append(\"// Code reviewed and approved\")  # More obfuscation\n",
    "                \n",
    "                child = '\\n'.join(child_lines) if 'child_lines' in locals() else parent1\n",
    "                \n",
    "                # Ensure the child is not empty or too short\n",
    "                if len(child.strip()) < 5:\n",
    "                    child = parent1 if len(parent1) > len(parent2) else parent2  # Use longer parent\n",
    "                \n",
    "                # Add mutation to create more diversity\n",
    "                if random.random() < 0.3:  # 30% mutation rate\n",
    "                    child = self._mutate_adversarial_code(child)\n",
    "                    \n",
    "                offspring.append(child)\n",
    "        \n",
    "        # Ensure we don't exceed population size\n",
    "        offspring = offspring[:self.pop_size//2]\n",
    "        \n",
    "        if self.verbose >= 2:\n",
    "            print(f\"Created {len(offspring)} offspring through enhanced crossover\")\n",
    "        \n",
    "        return offspring\n",
    "    \n",
    "    def _mutate_adversarial_code(self, code):\n",
    "        \"\"\"Apply mutation to adversarial code to increase diversity\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        \n",
    "        mutation_types = ['add_comment', 'modify_variable', 'add_vulnerability', 'obfuscate']\n",
    "        mutation = random.choice(mutation_types)\n",
    "        \n",
    "        if mutation == 'add_comment':\n",
    "            # Add misleading comments\n",
    "            comments = [\n",
    "                \"// Bounds checked above\",\n",
    "                \"// Input sanitized\",\n",
    "                \"// Memory properly allocated\",\n",
    "                \"// Safe operation confirmed\",\n",
    "                \"// Validated by security team\"\n",
    "            ]\n",
    "            insert_pos = random.randint(0, len(lines))\n",
    "            lines.insert(insert_pos, random.choice(comments))\n",
    "            \n",
    "        elif mutation == 'modify_variable':\n",
    "            # Modify variable names to be more misleading\n",
    "            replacements = {\n",
    "                'buffer': 'safe_buffer',\n",
    "                'input': 'validated_input',\n",
    "                'ptr': 'safe_ptr',\n",
    "                'query': 'sanitized_query'\n",
    "            }\n",
    "            for i, line in enumerate(lines):\n",
    "                for old, new in replacements.items():\n",
    "                    if old in line:\n",
    "                        lines[i] = line.replace(old, new)\n",
    "                        break\n",
    "        \n",
    "        elif mutation == 'add_vulnerability':\n",
    "            # Add additional vulnerability patterns\n",
    "            vuln_patterns = [\n",
    "                \"strcpy(temp, user_data); // Fast copy\",\n",
    "                \"system(command); // Execute utility\",\n",
    "                \"free(ptr); // Cleanup memory\",\n",
    "                \"sprintf(msg, format, data); // Format message\"\n",
    "            ]\n",
    "            insert_pos = random.randint(0, len(lines))\n",
    "            lines.insert(insert_pos, random.choice(vuln_patterns))\n",
    "            \n",
    "        else:  # obfuscate\n",
    "            # Add obfuscating code\n",
    "            obfuscations = [\n",
    "                \"if(1) { // Always true condition\",\n",
    "                \"int dummy = 0; // Temporary variable\",\n",
    "                \"/* Multi-line comment for clarity */\",\n",
    "                \"#ifdef DEBUG\",\n",
    "                \"#endif\"\n",
    "            ]\n",
    "            insert_pos = random.randint(0, len(lines))\n",
    "            lines.insert(insert_pos, random.choice(obfuscations))\n",
    "        \n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    def run(self, original_data_path=None, prediction_file_path=None):\n",
    "        \"\"\"\n",
    "        Run the adversarial learning process\n",
    "        \n",
    "        Args:\n",
    "            original_data_path: Path to original data CSV (if None, will create synthetic data)\n",
    "            prediction_file_path: Path to txt file containing model predictions (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Best adversarial code snippet\n",
    "        \"\"\"\n",
    "        print(\"\\n===== ADVERSARIAL LEARNING DIAGNOSTICS =====\")\n",
    "        \n",
    "        # Load predictions from txt file if provided\n",
    "        if prediction_file_path:\n",
    "            print(f\"Loading predictions from: {prediction_file_path}\")\n",
    "            self.load_predictions_from_txt(prediction_file_path)\n",
    "        \n",
    "        # Load or create original data\n",
    "        if original_data_path and os.path.exists(original_data_path):\n",
    "            original_df = pd.read_csv(original_data_path)\n",
    "            if 'functionSource' not in original_df.columns or 'label' not in original_df.columns:\n",
    "                raise ValueError(\"Original data must contain 'functionSource' and 'label' columns\")\n",
    "            print(f\"Loaded original data from {original_data_path}\")\n",
    "        else:\n",
    "            # Create synthetic data for testing purposes\n",
    "            print(\"No original data path provided, creating synthetic data for testing...\")\n",
    "            synthetic_functions = [\n",
    "                \"void func1() { char buf[100]; return; }\",\n",
    "                \"int func2(char* input) { int len = strlen(input); return len; }\",\n",
    "                \"void func3() { int* ptr = malloc(sizeof(int)); free(ptr); }\",\n",
    "                \"char* func4(int size) { return malloc(size); }\",\n",
    "                \"void func5(char* str) { printf(\\\"%s\\\", str); }\",\n",
    "                \"int func6() { char buffer[256]; gets(buffer); return 0; }\",\n",
    "                \"void func7(char* dest, char* src) { strcpy(dest, src); }\",\n",
    "                \"int func8(char* cmd) { return system(cmd); }\",\n",
    "            ]\n",
    "            \n",
    "            # Repeat synthetic functions to match attack pool size if needed\n",
    "            num_samples = max(len(self.attack_pool), 50)  # At least 50 samples\n",
    "            extended_functions = []\n",
    "            for i in range(num_samples):\n",
    "                base_func = synthetic_functions[i % len(synthetic_functions)]\n",
    "                # Add variation to make functions unique\n",
    "                modified_func = base_func.replace(\"func\", f\"func_{i}\")\n",
    "                extended_functions.append(modified_func)\n",
    "            \n",
    "            original_df = pd.DataFrame({\n",
    "                'functionSource': extended_functions,\n",
    "                'label': np.zeros(len(extended_functions), dtype=int)  # All non-vulnerable initially\n",
    "            })\n",
    "            \n",
    "            # Add some vulnerable examples\n",
    "            vulnerable_indices = np.random.choice(len(original_df), len(original_df) // 3, replace=False)\n",
    "            original_df.loc[vulnerable_indices, 'label'] = 1\n",
    "            print(f\"Created synthetic data with {len(original_df)} samples ({len(vulnerable_indices)} vulnerable)\")\n",
    "        \n",
    "        # Print data composition\n",
    "        vulnerable_count = (original_df['label'] == 1).sum()\n",
    "        benign_count = (original_df['label'] == 0).sum()\n",
    "        print(f\"Data composition: {vulnerable_count} vulnerable, {benign_count} benign samples\")\n",
    "        \n",
    "        if vulnerable_count == 0:\n",
    "            print(\"WARNING: No vulnerable samples in dataset! Creating synthetic vulnerable examples.\")\n",
    "            # Create some synthetic vulnerable examples\n",
    "            n_synthetic = max(10, len(original_df) // 4)\n",
    "            synthetic_indices = np.random.choice(len(original_df), n_synthetic, replace=False)\n",
    "            original_df.loc[synthetic_indices, 'label'] = 1\n",
    "            vulnerable_count = (original_df['label'] == 1).sum()\n",
    "            print(f\"Added {vulnerable_count} synthetic vulnerable examples\")\n",
    "        \n",
    "        # Initialize population and centroids\n",
    "        self.initialize_population()\n",
    "        \n",
    "        # Create more aggressive adversarial examples for the initial population\n",
    "        print(\"Enhancing attack pool with more aggressive adversarial examples...\")\n",
    "        aggressive_examples = [\n",
    "            # Comments to mislead\n",
    "            \"// This is a harmless comment that might confuse the model\",\n",
    "            \"/* This code was previously flagged as vulnerable */\",\n",
    "            \"// Code reviewed by security team\",\n",
    "            \n",
    "            # Actual vulnerable patterns but used in harmless ways\n",
    "            \"char buffer[100]; // Large enough buffer\",\n",
    "            \"if(strlen(input) < sizeof(buffer)) strcpy(buffer, input);\",\n",
    "            \"system(\\\"echo Hello\\\"); // Fixed command, not injection\",\n",
    "            \n",
    "            # Confusing constructs\n",
    "            \"int *ptr = malloc(10); if(ptr != NULL) { free(ptr); ptr = NULL; }\",\n",
    "            \"char *sql = \\\"SELECT * FROM users WHERE id=?\\\"; // Parameterized query\",\n",
    "            \"FILE *f = fopen(filename, \\\"r\\\"); if(f != NULL) { fclose(f); }\",\n",
    "            \n",
    "            # Code that looks harmless but has subtle issues\n",
    "            \"char *p = malloc(strlen(s)); strcpy(p, s); // Missing +1 for null terminator\",\n",
    "            \"int size = n * sizeof(int); char *buf = malloc(size); // Potential integer overflow\",\n",
    "            \"printf(\\\"Value: %s\\\", str); // Potentially format string vulnerability if str contains %\",\n",
    "            \n",
    "            # More aggressive exploits (obvious vulnerabilities)\n",
    "            \"gets(buffer); // Known buffer overflow\",\n",
    "            \"strcpy(dst, src); // No bounds checking\",\n",
    "            \"system(user_input); // Command injection\",\n",
    "            \"exec(user_input); // Command execution\",\n",
    "            \"sprintf(query, \\\"SELECT * FROM users WHERE name='%s'\\\", user_input); // SQL injection\",\n",
    "            \"free(ptr); free(ptr); // Double free\"\n",
    "        ]\n",
    "        \n",
    "        # Replace some population members with these examples\n",
    "        population_keys = list(self.population.keys())\n",
    "        for i in range(min(len(aggressive_examples), len(population_keys))):\n",
    "            self.population[aggressive_examples[i]] = 0\n",
    "            if i < len(population_keys):\n",
    "                del self.population[population_keys[i]]\n",
    "        \n",
    "        # Initialize model if needed (only if predictions weren't loaded from txt)\n",
    "        if self.original_predictions is None:\n",
    "            print(\"Initializing model...\")\n",
    "            if not hasattr(self, 'model') or self.model is None:\n",
    "                if self.trainer is None:\n",
    "                    self.trainer = CodeT5Trainer(batch_size=8, epochs=3)\n",
    "                \n",
    "                # Check if we have a pre-trained model to load\n",
    "                if self.model_path and os.path.exists(self.model_path):\n",
    "                    # Load pre-trained model\n",
    "                    print(f\"Loading model from {self.model_path}\")\n",
    "                    self.model = self.trainer.load_model(self.model_path)\n",
    "                    \n",
    "                    # CRITICAL FIX: Ensure model is in evaluation mode after loading\n",
    "                    if self.model is not None:\n",
    "                        self.model.eval()\n",
    "                        if hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                            self.trainer.model.eval()\n",
    "                        print(\"Model loaded successfully and set to evaluation mode\")\n",
    "                    else:\n",
    "                        print(\"ERROR: Model loading returned None!\")\n",
    "                        raise ValueError(\"Failed to load model from specified path\")\n",
    "                else:\n",
    "                    # Train a new model only if no pre-trained model exists\n",
    "                    print(\"Training a new model\")\n",
    "                    from sklearn.model_selection import train_test_split\n",
    "                    train_data, test_data = train_test_split(original_df, test_size=0.2, random_state=42)\n",
    "                    \n",
    "                    # Set trainer data\n",
    "                    self.trainer.set_data(train_data)\n",
    "                    \n",
    "                    # Prepare data loaders\n",
    "                    data_loaders = self.trainer.prepare_data(train_data, test_data)\n",
    "                    \n",
    "                    # Train the model\n",
    "                    self.model = self.trainer.train_model(data_loaders, freeze_base=False)\n",
    "                    print(\"Model trained successfully\")\n",
    "            else:\n",
    "                print(\"Using pre-loaded model\")\n",
    "                # CRITICAL FIX: Ensure the pre-loaded model is in evaluation mode\n",
    "                if hasattr(self, 'model') and self.model is not None:\n",
    "                    self.model.eval()\n",
    "                if hasattr(self, 'trainer') and hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                    self.trainer.model.eval()\n",
    "        else:\n",
    "            print(\"Using loaded predictions from txt file, skipping model initialization\")\n",
    "            # Still need trainer for adversarial predictions if model_path is provided\n",
    "            if self.model_path and not hasattr(self, 'trainer'):\n",
    "                print(\"Loading model for adversarial prediction generation...\")\n",
    "                self.trainer = CodeT5Trainer()\n",
    "                self.model = self.trainer.load_model(self.model_path)\n",
    "                if self.model is not None:\n",
    "                    self.model.eval()\n",
    "                    if hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                        self.trainer.model.eval()\n",
    "            elif self.model_path and hasattr(self, 'trainer') and self.trainer is None:\n",
    "                print(\"Loading model for adversarial prediction generation...\")\n",
    "                self.trainer = CodeT5Trainer()\n",
    "                self.model = self.trainer.load_model(self.model_path)\n",
    "                if self.model is not None:\n",
    "                    self.model.eval()\n",
    "                    if hasattr(self.trainer, 'model') and self.trainer.model is not None:\n",
    "                        self.trainer.model.eval()\n",
    "            elif not self.model_path:\n",
    "                print(\"Warning: No model path provided and using loaded predictions.\")\n",
    "                print(\"Adversarial predictions cannot be generated without a model.\")\n",
    "                # Initialize a dummy trainer to prevent AttributeError\n",
    "                self.trainer = None\n",
    "        \n",
    "        # Calculate initial fitness scores\n",
    "        print(\"Calculating initial fitness scores...\")\n",
    "        \n",
    "        # Make sure the model is available for calculate_fitness\n",
    "        # FIXED: Handle case when using loaded predictions and no trainer is available\n",
    "        if hasattr(self, 'model') and self.model is not None:\n",
    "            model = self.model\n",
    "        elif hasattr(self, 'trainer') and self.trainer is not None and hasattr(self.trainer, 'model'):\n",
    "            model = self.trainer.model\n",
    "        else:\n",
    "            model = None\n",
    "        \n",
    "        # DEBUG: Validate model predictions on original data (only if trainer is available)\n",
    "        if self.original_predictions is None and hasattr(self, 'trainer') and self.trainer is not None:\n",
    "            print(\"\\n===== MODEL PREDICTION VALIDATION =====\")\n",
    "            # Get counts of vulnerable samples in original data\n",
    "            vulnerable_count = (original_df['label'] == 1).sum()\n",
    "            print(f\"Dataset has {vulnerable_count} labeled vulnerable samples out of {len(original_df)} total\")\n",
    "            \n",
    "            # Check original predictions\n",
    "            if hasattr(self.trainer, 'predict'):\n",
    "                correct_predictions = 0\n",
    "                vulnerable_correctly_identified = 0\n",
    "                vulnerable_samples = original_df['label'] == 1\n",
    "                \n",
    "                for idx, row in original_df.iterrows():\n",
    "                    code = row['functionSource']\n",
    "                    true_label = row['label']\n",
    "                    try:\n",
    "                        pred = self.trainer.predict(code)\n",
    "                        if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                            prediction = pred['prediction']\n",
    "                            if prediction == true_label:\n",
    "                                correct_predictions += 1\n",
    "                                if true_label == 1:\n",
    "                                    vulnerable_correctly_identified += 1\n",
    "                            \n",
    "                            # Print info for all vulnerable samples\n",
    "                            if true_label == 1:\n",
    "                                print(f\"Vulnerable sample {idx}: Predicted as {'vulnerable' if prediction == 1 else 'benign'}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error predicting sample {idx}: {str(e)}\")\n",
    "                \n",
    "                accuracy = correct_predictions / len(original_df) if len(original_df) > 0 else 0\n",
    "                vulnerability_recall = vulnerable_correctly_identified / vulnerable_count if vulnerable_count > 0 else 0\n",
    "                \n",
    "                print(f\"Model accuracy: {accuracy:.4f} ({correct_predictions}/{len(original_df)})\")\n",
    "                print(f\"Vulnerability detection rate: {vulnerability_recall:.4f} ({vulnerable_correctly_identified}/{vulnerable_count})\")\n",
    "                \n",
    "                if vulnerability_recall < 0.1:\n",
    "                    print(\"WARNING: Model is detecting very few vulnerabilities, adversarial attacks will likely fail!\")\n",
    "                    print(\"Consider retraining the model or providing clearer vulnerable examples.\")\n",
    "                    \n",
    "                    # Create more obvious vulnerable examples for testing\n",
    "                    if vulnerable_correctly_identified == 0:\n",
    "                        print(\"CRITICAL: No vulnerabilities detected. Creating synthetic examples for testing.\")\n",
    "                        # Create an obvious example with a known vulnerability\n",
    "                        test_code = \"\"\"void vulnerable_func() {\n",
    "                            char buffer[10];\n",
    "                            gets(buffer);  // Known buffer overflow\n",
    "                            printf(\"%s\", buffer);\n",
    "                        }\"\"\"\n",
    "                        \n",
    "                        try:\n",
    "                            pred = self.trainer.predict(test_code)\n",
    "                            print(f\"Test vulnerability prediction: {pred}\")\n",
    "                            if isinstance(pred, dict) and pred.get('prediction') != 1:\n",
    "                                print(\"SEVERE WARNING: Model fails to detect even obvious vulnerabilities!\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in test prediction: {str(e)}\")\n",
    "        else:\n",
    "            print(\"\\n===== USING LOADED PREDICTIONS =====\")\n",
    "            print(f\"Loaded {len(self.original_predictions)} predictions from txt file\")\n",
    "            print(\"Skipping model validation since predictions are pre-computed\")\n",
    "        \n",
    "        # Track the actual attack success rates for the best code\n",
    "        attack_success_rates = {}\n",
    "        \n",
    "        # Calculate fitness for each member of the population\n",
    "        for adv_code in tqdm(list(self.population.keys()), desc=\"Initial fitness\"):\n",
    "            fitness, attack_rate = self.calculate_fitness(original_df, adv_code, model, return_attack_rate=True)\n",
    "            self.population[adv_code] = fitness\n",
    "            attack_success_rates[adv_code] = attack_rate\n",
    "        \n",
    "        # Diagnose the best initial adversarial code (only if trainer is available)\n",
    "        if self.population and hasattr(self, 'trainer') and self.trainer is not None:\n",
    "            best_initial_code = max(self.population.items(), key=lambda x: x[1])[0]\n",
    "            print(f\"\\n=== DIAGNOSING BEST INITIAL ADVERSARIAL CODE ===\")\n",
    "            self.diagnose_attack_effectiveness(original_df, best_initial_code, model)\n",
    "        \n",
    "        # Free GPU memory\n",
    "        free_gpu_memory()\n",
    "        \n",
    "        # Run generations\n",
    "        best_fitness = max(self.population.values()) if self.population else 0\n",
    "        best_code = max(self.population.items(), key=lambda x: x[1])[0] if self.population else None\n",
    "        best_attack_rate = attack_success_rates.get(best_code, 0.0)\n",
    "        \n",
    "        for gen in range(self.max_generations):\n",
    "            if self.verbose:\n",
    "                print(f\"\\n=== Generation {gen+1}/{self.max_generations} ===\")\n",
    "                print(f\"Best fitness so far: {best_fitness:.4f}\")\n",
    "                print(f\"Best attack success rate: {best_attack_rate:.4f}\")\n",
    "            \n",
    "            # Perform fuzzy clustering\n",
    "            membership_weights, centroid_change = self.perform_fuzzy_clustering()\n",
    "            \n",
    "            # Select top clusters\n",
    "            top_clusters = self.select_clusters()\n",
    "            \n",
    "            # Perform crossover\n",
    "            offspring = self.perform_crossover(membership_weights, top_clusters)\n",
    "            \n",
    "            # Calculate fitness for offspring\n",
    "            offspring_fitness = []\n",
    "            for adv_code in tqdm(offspring, desc=\"Offspring fitness\"):\n",
    "                fitness, attack_rate = self.calculate_fitness(original_df, adv_code, model, return_attack_rate=True)\n",
    "                offspring_fitness.append(fitness)\n",
    "                attack_success_rates[adv_code] = attack_rate\n",
    "            \n",
    "            # Update population with offspring\n",
    "            self.population = update_global_pop(offspring, self.population, offspring_fitness)\n",
    "            \n",
    "            # Check for new best fitness\n",
    "            current_best = max(self.population.values())\n",
    "            if current_best > best_fitness:\n",
    "                best_fitness = current_best\n",
    "                best_code = max(self.population.items(), key=lambda x: x[1])[0]\n",
    "                best_attack_rate = attack_success_rates.get(best_code, 0.0)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"New best fitness: {best_fitness:.4f}\")\n",
    "                    print(f\"New best attack success rate: {best_attack_rate:.4f}\")\n",
    "                    print(f\"Best code snippet length: {len(best_code.splitlines())}\")\n",
    "            \n",
    "            # Check for perfect attack (100% success rate)\n",
    "            if best_fitness > 0.99 - self.penalty:  # Allow for length penalty\n",
    "                if self.verbose:\n",
    "                    print(f\"Found optimal adversarial code with fitness {best_fitness:.4f}\")\n",
    "                break\n",
    "            \n",
    "            # Check for convergence\n",
    "            if centroid_change < 1e-6:\n",
    "                if self.verbose:\n",
    "                    print(f\"Converged after {gen+1} generations with best fitness {best_fitness:.4f}\")\n",
    "                break\n",
    "        \n",
    "        # Calculate the direct attack success rate with the best code\n",
    "        # This matches the logic in the user's code sample\n",
    "        print(\"\\n=== Direct Attack Success Rate Calculation ===\")\n",
    "        \n",
    "        # Use loaded predictions if available, otherwise get predictions from model\n",
    "        if self.original_predictions is not None:\n",
    "            print(\"Using loaded predictions for direct attack calculation...\")\n",
    "            original_predictions = self.original_predictions.copy()\n",
    "        else:\n",
    "            # Get predictions on original data using model\n",
    "            def get_predictions(df):\n",
    "                predictions = []\n",
    "                if hasattr(self, 'trainer') and self.trainer is not None:\n",
    "                    for _, row in df.iterrows():\n",
    "                        code = row['functionSource']\n",
    "                        try:\n",
    "                            pred = self.trainer.predict(code)\n",
    "                            if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                                predictions.append(pred['prediction'])\n",
    "                            else:\n",
    "                                predictions.append(0)\n",
    "                        except Exception as e:\n",
    "                            if self.verbose >= 2:\n",
    "                                print(f\"Error in prediction: {str(e)}\")\n",
    "                            predictions.append(0)\n",
    "                else:\n",
    "                    # No trainer available, return all zeros\n",
    "                    predictions = [0] * len(df)\n",
    "                return np.array(predictions)\n",
    "            \n",
    "            print(\"Getting original predictions from model...\")\n",
    "            original_predictions = get_predictions(original_df)\n",
    "        \n",
    "        # Generate adversarial predictions only if trainer is available\n",
    "        if hasattr(self, 'trainer') and self.trainer is not None:\n",
    "            # Create a copy for adversarial testing\n",
    "            adv_df = original_df.copy()\n",
    "            vulnerable_samples = adv_df['label'] == 1\n",
    "            num_vulnerable = vulnerable_samples.sum()\n",
    "            \n",
    "            print(f\"Found {num_vulnerable} vulnerable samples for adversarial testing\")\n",
    "            \n",
    "            # Insert adversarial code into vulnerable samples\n",
    "            for idx in adv_df.index[vulnerable_samples]:\n",
    "                orig_code = adv_df.loc[idx, 'functionSource']\n",
    "                code_lines = orig_code.split('\\n')\n",
    "                insert_pos = min(15, max(1, len(code_lines) - 1))  # Try to use position 15 like in user's code\n",
    "                code_lines.insert(insert_pos, best_code)\n",
    "                adv_df.loc[idx, 'functionSource'] = '\\n'.join(code_lines)\n",
    "            \n",
    "            # Get adversarial predictions\n",
    "            print(\"Getting adversarial predictions...\")\n",
    "            adversarial_predictions = []\n",
    "            for _, row in adv_df.iterrows():\n",
    "                code = row['functionSource']\n",
    "                try:\n",
    "                    pred = self.trainer.predict(code)\n",
    "                    if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                        adversarial_predictions.append(pred['prediction'])\n",
    "                    else:\n",
    "                        adversarial_predictions.append(0)\n",
    "                except Exception as e:\n",
    "                    if self.verbose >= 2:\n",
    "                        print(f\"Error in adversarial prediction: {str(e)}\")\n",
    "                    adversarial_predictions.append(0)\n",
    "            \n",
    "            adversarial_predictions = np.array(adversarial_predictions)\n",
    "            \n",
    "            # Calculate direct attack success rate (percent of predictions that changed)\n",
    "            vul_indices = np.where(original_df['label'] == 1)[0]\n",
    "            prediction_changes = sum(1 for i in vul_indices \n",
    "                                   if original_predictions[i] != adversarial_predictions[i])\n",
    "            \n",
    "            direct_attack_success_rate = prediction_changes / len(vul_indices) if len(vul_indices) > 0 else 0\n",
    "            \n",
    "            # Count how many 1‚Üí0 changes (matching user's code logic - vulnerable to benign)\n",
    "            one_to_zero = sum(1 for i in vul_indices\n",
    "                              if original_predictions[i] == 1 and adversarial_predictions[i] == 0)\n",
    "            \n",
    "            one_to_zero_rate = one_to_zero / len(vul_indices) if len(vul_indices) > 0 else 0\n",
    "        else:\n",
    "            print(\"No trainer available for direct attack calculation, using fitness-based estimates\")\n",
    "            direct_attack_success_rate = best_attack_rate  # Use the best attack rate from fitness calculation\n",
    "            one_to_zero_rate = best_attack_rate\n",
    "            one_to_zero = int(best_attack_rate * (original_df['label'] == 1).sum())\n",
    "            vul_indices = np.where(original_df['label'] == 1)[0]\n",
    "            adversarial_predictions = original_predictions.copy() if self.original_predictions is not None else np.zeros(len(original_df))\n",
    "        \n",
    "        print(\"\\n=== Final Attack Success Results ===\")\n",
    "        print(f\"Overall Attack Success Rate (any change): {best_attack_rate:.4f}\")\n",
    "        if hasattr(self, 'trainer') and self.trainer is not None:\n",
    "            print(f\"Direct Attack Success Rate (vulnerable samples only): {direct_attack_success_rate:.4f}\")\n",
    "            print(f\"Vulnerable to Benign Changes (1‚Üí0): {one_to_zero_rate:.4f} ({one_to_zero}/{len(vul_indices)})\")\n",
    "        print(f\"Fitness Score: {best_fitness:.4f}\")\n",
    "        \n",
    "        best_snippet_length = len(best_code.splitlines())\n",
    "        length_penalty = self.penalty * best_snippet_length\n",
    "        print(f\"Length Penalty: {length_penalty:.4f}\")\n",
    "        print(f\"Code Snippet Length: {best_snippet_length}\")\n",
    "        \n",
    "        # Generate and save adversarial predictions with the best code\n",
    "        print(\"\\n=== GENERATING ADVERSARIAL PREDICTIONS ===\")\n",
    "        \n",
    "        # Apply the best adversarial code to create adversarial dataset\n",
    "        final_adv_df = original_df.copy()\n",
    "        vulnerable_samples = final_adv_df['label'] == 1\n",
    "        \n",
    "        # Insert best adversarial code into vulnerable samples\n",
    "        for idx in final_adv_df.index[vulnerable_samples]:\n",
    "            orig_code = final_adv_df.loc[idx, 'functionSource']\n",
    "            code_lines = orig_code.split('\\n')\n",
    "            insert_pos = min(15, max(1, len(code_lines) - 1))\n",
    "            code_lines.insert(insert_pos, best_code)\n",
    "            final_adv_df.loc[idx, 'functionSource'] = '\\n'.join(code_lines)\n",
    "        \n",
    "        # Generate adversarial predictions\n",
    "        if hasattr(self, 'trainer') and self.trainer is not None:\n",
    "            print(\"Generating adversarial predictions with best code...\")\n",
    "            final_adversarial_predictions = []\n",
    "            \n",
    "            for _, row in tqdm(final_adv_df.iterrows(), desc=\"Generating adversarial predictions\", total=len(final_adv_df)):\n",
    "                code = row['functionSource']\n",
    "                try:\n",
    "                    pred = self.trainer.predict(code)\n",
    "                    if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                        final_adversarial_predictions.append(pred['prediction'])\n",
    "                    else:\n",
    "                        final_adversarial_predictions.append(0)\n",
    "                except Exception as e:\n",
    "                    if self.verbose >= 2:\n",
    "                        print(f\"Error in final adversarial prediction: {str(e)}\")\n",
    "                    final_adversarial_predictions.append(0)\n",
    "            \n",
    "            final_adversarial_predictions = np.array(final_adversarial_predictions)\n",
    "            \n",
    "            # Extract dataset name from original_data_path for consistent naming\n",
    "            dataset_name = \"test\"  # Default\n",
    "            if original_data_path:\n",
    "                # Extract CWE ID from path like 'cwe399_test.csv'\n",
    "                import re\n",
    "                cwe_match = re.search(r'cwe(\\d+)', os.path.basename(original_data_path).lower())\n",
    "                if cwe_match:\n",
    "                    dataset_name = f\"cwe{cwe_match.group(1)}\"\n",
    "            \n",
    "            # Save adversarial predictions\n",
    "            adv_predictions_path = self.save_adversarial_predictions(\n",
    "                final_adversarial_predictions, \n",
    "                dataset_name\n",
    "            )\n",
    "            \n",
    "            # Calculate final adversarial attack statistics\n",
    "            if self.original_predictions is not None:\n",
    "                original_preds = self.original_predictions\n",
    "            else:\n",
    "                # Use original predictions from earlier calculation\n",
    "                original_preds = original_predictions\n",
    "            \n",
    "            # Calculate attack effectiveness on final adversarial predictions\n",
    "            total_changes = np.sum(original_preds != final_adversarial_predictions)\n",
    "            vuln_to_benign = np.sum((original_preds == 1) & (final_adversarial_predictions == 0))\n",
    "            benign_to_vuln = np.sum((original_preds == 0) & (final_adversarial_predictions == 1))\n",
    "            \n",
    "            # Calculate original model performance metrics\n",
    "            original_accuracy = accuracy_score(original_df['label'], original_preds)\n",
    "            original_precision = precision_score(original_df['label'], original_preds, average='binary', zero_division=0)\n",
    "            original_recall = recall_score(original_df['label'], original_preds, average='binary', zero_division=0)\n",
    "            original_f1 = f1_score(original_df['label'], original_preds, average='binary', zero_division=0)\n",
    "            \n",
    "            print(f\"\\n=== FINAL ADVERSARIAL ATTACK RESULTS ===\")\n",
    "            print(f\"Total prediction changes: {total_changes}/{len(original_preds)} ({total_changes/len(original_preds):.4f})\")\n",
    "            print(f\"Vulnerable‚ÜíBenign changes: {vuln_to_benign}\")\n",
    "            print(f\"Benign‚ÜíVulnerable changes: {benign_to_vuln}\")\n",
    "            print(f\"Adversarial predictions saved to: {adv_predictions_path}\")\n",
    "            print(f\"\\n=== ORIGINAL MODEL PERFORMANCE ===\")\n",
    "            print(f\"Accuracy: {original_accuracy:.4f}\")\n",
    "            print(f\"Precision: {original_precision:.4f}\")\n",
    "            print(f\"Recall: {original_recall:.4f}\")\n",
    "            print(f\"F1-Score: {original_f1:.4f}\")\n",
    "            \n",
    "            # Create results in the desired format\n",
    "            results = {\n",
    "                'best_adversarial_code': best_code,\n",
    "                'best_fitness': best_fitness,\n",
    "                'attack_success_rate': best_attack_rate,\n",
    "                'original_f1_score': round(original_f1, 4),\n",
    "                'original_accuracy': round(original_accuracy, 4),\n",
    "                'original_precision': round(original_precision, 4),\n",
    "                'original_recall': round(original_recall, 4),\n",
    "                'parameters': {\n",
    "                    'pop_size': self.pop_size,\n",
    "                    'clusters': self.clusters,\n",
    "                    'max_generations': self.max_generations,\n",
    "                    'decay_rate': self.decay_rate,\n",
    "                    'alpha': self.alpha,\n",
    "                    'penalty': self.penalty\n",
    "                },\n",
    "                'adversarial_predictions_file': adv_predictions_path,\n",
    "                'vulnerable_to_benign_changes': int(vuln_to_benign)\n",
    "            }\n",
    "        else:\n",
    "            print(\"No model available for generating adversarial predictions\")\n",
    "            adv_predictions_path = None\n",
    "            \n",
    "            # For cases without model, we can't calculate detailed metrics\n",
    "            # Provide basic results structure\n",
    "            results = {\n",
    "                'best_adversarial_code': best_code,\n",
    "                'best_fitness': best_fitness,\n",
    "                'attack_success_rate': best_attack_rate,\n",
    "                'original_f1_score': 0.0,\n",
    "                'original_accuracy': 0.0,\n",
    "                'original_precision': 0.0,\n",
    "                'original_recall': 0.0,\n",
    "                'parameters': {\n",
    "                    'pop_size': self.pop_size,\n",
    "                    'clusters': self.clusters,\n",
    "                    'max_generations': self.max_generations,\n",
    "                    'decay_rate': self.decay_rate,\n",
    "                    'alpha': self.alpha,\n",
    "                    'penalty': self.penalty\n",
    "                },\n",
    "                'adversarial_predictions_file': None,\n",
    "                'vulnerable_to_benign_changes': 0\n",
    "            }\n",
    "        \n",
    "        # Extract CWE ID from original_data_path to create filename suffix\n",
    "        if original_data_path:\n",
    "            # Extract CWE ID from path like '/kaggle/input/eatvul/cwe399_test.csv'\n",
    "            import re\n",
    "            cwe_match = re.search(r'cwe(\\d+)', os.path.basename(original_data_path).lower())\n",
    "            if cwe_match:\n",
    "                cwe_id = cwe_match.group(1)\n",
    "                results_filename = f'adversarial_results_cwe{cwe_id}.json'\n",
    "            else:\n",
    "                results_filename = 'adversarial_results.json'\n",
    "        else:\n",
    "            results_filename = 'adversarial_results.json'\n",
    "        \n",
    "        # Save best adversarial code\n",
    "        with open(results_filename, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"Results saved to {results_filename}\")\n",
    "        \n",
    "        return best_code, best_fitness\n",
    "\n",
    "    def diagnose_attack_effectiveness(self, original_df, adversarial_code, model=None):\n",
    "        \"\"\"\n",
    "        Detailed diagnosis of why an adversarial attack might be failing\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== ATTACK EFFECTIVENESS DIAGNOSIS ===\")\n",
    "        print(f\"Adversarial code being tested:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(adversarial_code)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get model predictions function\n",
    "        def get_prediction_details(code):\n",
    "            try:\n",
    "                pred = self.trainer.predict(code)\n",
    "                return pred\n",
    "            except Exception as e:\n",
    "                print(f\"Error in prediction: {str(e)}\")\n",
    "                return {'prediction': 0, 'confidence': 0.5, 'probabilities': [0.5, 0.5]}\n",
    "        \n",
    "        # Test on a few vulnerable samples\n",
    "        vulnerable_samples = original_df[original_df['label'] == 1].head(10)\n",
    "        \n",
    "        print(f\"\\nTesting on {len(vulnerable_samples)} vulnerable samples:\")\n",
    "        \n",
    "        successful_attacks = 0\n",
    "        for idx, row in vulnerable_samples.iterrows():\n",
    "            function_code = row['functionSource']\n",
    "            \n",
    "            # Get original prediction\n",
    "            orig_pred = get_prediction_details(function_code)\n",
    "            \n",
    "            # If original is not predicted as vulnerable, skip\n",
    "            if orig_pred['prediction'] != 1:\n",
    "                print(f\"Sample {idx}: Originally not detected as vulnerable (pred={orig_pred['prediction']}, conf={orig_pred['confidence']:.3f})\")\n",
    "                continue\n",
    "            \n",
    "            # Create adversarial version\n",
    "            code_lines = function_code.split('\\n')\n",
    "            # Insert adversarial code at position 2 (after function declaration typically)\n",
    "            insert_pos = min(2, len(code_lines) - 1)\n",
    "            code_lines.insert(insert_pos, adversarial_code)\n",
    "            adv_code = '\\n'.join(code_lines)\n",
    "            \n",
    "            # Get adversarial prediction\n",
    "            adv_pred = get_prediction_details(adv_code)\n",
    "            \n",
    "            # Check if attack was successful\n",
    "            attack_success = (orig_pred['prediction'] == 1 and adv_pred['prediction'] == 0)\n",
    "            if attack_success:\n",
    "                successful_attacks += 1\n",
    "            \n",
    "            print(f\"Sample {idx}:\")\n",
    "            print(f\"  Original: pred={orig_pred['prediction']}, conf={orig_pred['confidence']:.3f}\")\n",
    "            print(f\"  Adversarial: pred={adv_pred['prediction']}, conf={adv_pred['confidence']:.3f}\")\n",
    "            print(f\"  Attack success: {attack_success}\")\n",
    "            print(f\"  Confidence change: {orig_pred['confidence']:.3f} -> {adv_pred['confidence']:.3f}\")\n",
    "            \n",
    "            # Show a snippet of the adversarial code\n",
    "            print(f\"  Adversarial code snippet:\")\n",
    "            adv_lines = adv_code.split('\\n')\n",
    "            for i, line in enumerate(adv_lines[max(0, insert_pos-1):insert_pos+3]):\n",
    "                marker = \">>> \" if i == 1 else \"    \"\n",
    "                print(f\"    {marker}{line}\")\n",
    "            print()\n",
    "        \n",
    "        attack_rate = successful_attacks / len(vulnerable_samples) if len(vulnerable_samples) > 0 else 0\n",
    "        print(f\"Overall attack success rate: {attack_rate:.4f} ({successful_attacks}/{len(vulnerable_samples)})\")\n",
    "        \n",
    "        # Additional diagnostics\n",
    "        print(f\"\\n=== ADDITIONAL DIAGNOSTICS ===\")\n",
    "        \n",
    "        # Test if the adversarial code itself is detected as vulnerable\n",
    "        test_func = f\"\"\"void test_function() {{\n",
    "    {adversarial_code}\n",
    "    return;\n",
    "}}\"\"\"\n",
    "        \n",
    "        test_pred = get_prediction_details(test_func)\n",
    "        print(f\"Adversarial code in isolation:\")\n",
    "        print(f\"  Prediction: {test_pred['prediction']} (0=benign, 1=vulnerable)\")\n",
    "        print(f\"  Confidence: {test_pred['confidence']:.3f}\")\n",
    "        \n",
    "        if test_pred['prediction'] == 0:\n",
    "            print(\"  -> Adversarial code itself is not detected as vulnerable\")\n",
    "            print(\"  -> This might explain low attack success rates\")\n",
    "        else:\n",
    "            print(\"  -> Adversarial code is detected as vulnerable when isolated\")\n",
    "            print(\"  -> The problem might be in how it's inserted into existing code\")\n",
    "        \n",
    "        return attack_rate\n",
    "\n",
    "    def load_predictions_from_txt(self, prediction_file_path):\n",
    "        \"\"\"\n",
    "        Load model predictions from exported txt file\n",
    "        \n",
    "        Args:\n",
    "            prediction_file_path: Path to the txt file containing predictions\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        if not os.path.exists(prediction_file_path):\n",
    "            raise FileNotFoundError(f\"Prediction file not found: {prediction_file_path}\")\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n=== LOADING PREDICTIONS FROM TXT ===\")\n",
    "            print(f\"Loading predictions from: {prediction_file_path}\")\n",
    "        \n",
    "        with open(prediction_file_path, 'r') as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if line:  # Skip empty lines\n",
    "                    try:\n",
    "                        parts = line.split('\\t')\n",
    "                        if len(parts) == 2:\n",
    "                            index, prediction = parts\n",
    "                            predictions.append(int(prediction))\n",
    "                        else:\n",
    "                            # Try space separator if tab doesn't work\n",
    "                            parts = line.split()\n",
    "                            if len(parts) == 2:\n",
    "                                index, prediction = parts\n",
    "                                predictions.append(int(prediction))\n",
    "                            else:\n",
    "                                print(f\"Warning: Skipping malformed line {line_num + 1}: {line}\")\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Warning: Error parsing line {line_num + 1}: {line} - {str(e)}\")\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Loaded {len(predictions)} predictions\")\n",
    "            print(f\"Prediction distribution: {np.bincount(predictions)}\")\n",
    "            print(f\"  0 (not vulnerable): {np.sum(predictions == 0)}\")\n",
    "            print(f\"  1 (vulnerable): {np.sum(predictions == 1)}\")\n",
    "        \n",
    "        self.original_predictions = predictions\n",
    "        self.prediction_file_path = prediction_file_path\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def save_adversarial_predictions(self, adversarial_predictions, dataset_name=\"test\"):\n",
    "        \"\"\"\n",
    "        Save adversarial predictions to txt file\n",
    "        \n",
    "        Args:\n",
    "            adversarial_predictions: Array of adversarial predictions\n",
    "            dataset_name: Name to include in filename\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved file\n",
    "        \"\"\"\n",
    "        # Create timestamp for unique filename\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        \n",
    "        # Create filename\n",
    "        if \"cwe\" in dataset_name.lower():\n",
    "            filename = f\"prediction_adv_{dataset_name}_{timestamp}.txt\"\n",
    "        else:\n",
    "            filename = f\"prediction_adv_cwe_{timestamp}.txt\"\n",
    "        \n",
    "        # Determine output directory - handle read-only input directories\n",
    "        output_dir = os.getcwd()  # Default to current working directory\n",
    "        \n",
    "        if self.prediction_file_path:\n",
    "            input_dir = os.path.dirname(self.prediction_file_path)\n",
    "            \n",
    "            # Test if the input directory is writable\n",
    "            try:\n",
    "                test_file = os.path.join(input_dir, '.test_write_permission')\n",
    "                with open(test_file, 'w') as f:\n",
    "                    f.write('test')\n",
    "                os.remove(test_file)\n",
    "                # If we get here, the directory is writable\n",
    "                output_dir = input_dir\n",
    "                if self.verbose:\n",
    "                    print(f\"Using input directory for output: {output_dir}\")\n",
    "            except (OSError, PermissionError):\n",
    "                # Directory is read-only, use current working directory\n",
    "                output_dir = os.getcwd()\n",
    "                if self.verbose:\n",
    "                    print(f\"Input directory is read-only, using current directory: {output_dir}\")\n",
    "        \n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Write predictions to file\n",
    "        with open(output_path, 'w') as f:\n",
    "            for idx, pred in enumerate(adversarial_predictions):\n",
    "                f.write(f\"{idx}\\t{pred}\\n\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Adversarial predictions exported to: {output_path}\")\n",
    "            print(f\"Total adversarial predictions exported: {len(adversarial_predictions)}\")\n",
    "        \n",
    "        return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544f3732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T05:57:59.461326Z",
     "iopub.status.busy": "2025-06-03T05:57:59.461093Z",
     "iopub.status.idle": "2025-06-03T06:03:31.346930Z",
     "shell.execute_reply": "2025-06-03T06:03:31.346141Z"
    },
    "papermill": {
     "duration": 331.894371,
     "end_time": "2025-06-03T06:03:31.348079",
     "exception": false,
     "start_time": "2025-06-03T05:57:59.453708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ATTACK POOL LOADING ===\n",
      "Raw attack pool shape: (200, 3)\n",
      "Available columns: ['original_code', 'adversarial_code', 'label']\n",
      "Detected attack pool format with 'adversarial_code' column\n",
      "Attack pool processed successfully:\n",
      "  Initial size: 200\n",
      "  After removing NaN: 200\n",
      "  Final shape: (200, 1)\n",
      "Sample adversarial codes:\n",
      "  [1] nsSMILTimeContainer* container_var = nullptr;\n",
      "double aoffsetseconds_var = aOffsetSeconds;\n",
      "nsSMILTime...\n",
      "  [2] void* sa_var;\n",
      "struct task_struct* task_struct_var;\n",
      "struct k_sigaction* ka_var;\n",
      "if(task_struct_var &&...\n",
      "  [3] const int const_var = 0;\n",
      "nsPresContext* nsprescontext_var = nullptr;\n",
      "nsIFrame* getparent_var = nullp...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980f09caa20b4c1f92ed694a906dda97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5fbe906a4243148089da26897338bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e1c988cc6e4c138bb41bb9f9ebf329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a020a65f4a4213b784c8d02f32ff43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3554d3750f5f475f8ad4c7cb8ac29881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /kaggle/input/eatvul/cwe399-codet5-model/model/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3d02a7dd97463387ca6d8d448efa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5ad09871ff4bdba83f6a30b81f1d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9df952e6e1f4b68a26cc7a6006cf0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model checkpoint\n",
      "Loaded tokenizer from saved model\n",
      "Loaded training history. Best validation accuracy: 0.8921\n",
      "Model loaded successfully and set to evaluation mode\n",
      "Successfully loaded model from /kaggle/input/eatvul/cwe399-codet5-model/model/\n",
      "Model is in eval mode: True\n",
      "Model test prediction: {'prediction': 0, 'confidence': 0.953629195690155, 'probabilities': [0.953629195690155, 0.04637076333165169], 'label_names': ['Not Vulnerable', 'Vulnerable']}\n",
      "\n",
      "===== ADVERSARIAL LEARNING DIAGNOSTICS =====\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe399.txt\n",
      "\n",
      "=== LOADING PREDICTIONS FROM TXT ===\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe399.txt\n",
      "Loaded 732 predictions\n",
      "Prediction distribution: [402 330]\n",
      "  0 (not vulnerable): 402\n",
      "  1 (vulnerable): 330\n",
      "Loaded original data from /kaggle/input/eatvul/cwe399_test.csv\n",
      "Data composition: 333 vulnerable, 399 benign samples\n",
      "\n",
      "=== POPULATION INITIALIZATION ===\n",
      "Attack pool size: 200\n",
      "Requested population size: 10\n",
      "Attack pool larger than population size - sampling without replacement\n",
      "Population successfully initialized:\n",
      "  Population size: 10\n",
      "  Unique adversarial codes: 10\n",
      "  Clusters: 3\n",
      "  Initial centroids: [0.83674095 0.1742856  0.53387772]\n",
      "Sample population codes:\n",
      "  [1] int argc_var = argc > 1 ? 1 : 0;\n",
      "if (argc_var) {} else if(str == NULL) {int fope...\n",
      "  [2] void dummy(){\n",
      "const struct ast_party_id *guide_var = NULL;\n",
      "struct ast_party_id *...\n",
      "  [3] int imgirequest_var = 0;\n",
      "int mimagestatus_var = 0;\n",
      "int stateframestopped_var = 0...\n",
      "Enhancing attack pool with more aggressive adversarial examples...\n",
      "Using loaded predictions from txt file, skipping model initialization\n",
      "Calculating initial fitness scores...\n",
      "\n",
      "===== USING LOADED PREDICTIONS =====\n",
      "Loaded 732 predictions from txt file\n",
      "Skipping model validation since predictions are pre-computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [03:06<00:00, 18.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNOSING BEST INITIAL ADVERSARIAL CODE ===\n",
      "\n",
      "=== ATTACK EFFECTIVENESS DIAGNOSIS ===\n",
      "Adversarial code being tested:\n",
      "--------------------------------------------------\n",
      "int *ptr = malloc(10); if(ptr != NULL) { free(ptr); ptr = NULL; }\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing on 10 vulnerable samples:\n",
      "Sample 4: Originally not detected as vulnerable (pred=0, conf=0.959)\n",
      "Sample 6: Originally not detected as vulnerable (pred=0, conf=0.987)\n",
      "Sample 7: Originally not detected as vulnerable (pred=0, conf=0.986)\n",
      "Sample 8: Originally not detected as vulnerable (pred=0, conf=0.936)\n",
      "Sample 9: Originally not detected as vulnerable (pred=0, conf=0.950)\n",
      "Sample 11: Originally not detected as vulnerable (pred=0, conf=0.960)\n",
      "Sample 12: Originally not detected as vulnerable (pred=0, conf=0.954)\n",
      "Sample 14: Originally not detected as vulnerable (pred=0, conf=0.937)\n",
      "Sample 18: Originally not detected as vulnerable (pred=0, conf=0.973)\n",
      "Sample 20: Originally not detected as vulnerable (pred=0, conf=0.986)\n",
      "Overall attack success rate: 0.0000 (0/10)\n",
      "\n",
      "=== ADDITIONAL DIAGNOSTICS ===\n",
      "Adversarial code in isolation:\n",
      "  Prediction: 0 (0=benign, 1=vulnerable)\n",
      "  Confidence: 0.980\n",
      "  -> Adversarial code itself is not detected as vulnerable\n",
      "  -> This might explain low attack success rates\n",
      "\n",
      "=== Generation 1/1 ===\n",
      "Best fitness so far: 1.1900\n",
      "Best attack success rate: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offspring fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:33<00:00, 18.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found optimal adversarial code with fitness 1.1900\n",
      "\n",
      "=== Direct Attack Success Rate Calculation ===\n",
      "Using loaded predictions for direct attack calculation...\n",
      "Found 333 vulnerable samples for adversarial testing\n",
      "Getting adversarial predictions...\n",
      "\n",
      "=== Final Attack Success Results ===\n",
      "Overall Attack Success Rate (any change): 1.0000\n",
      "Direct Attack Success Rate (vulnerable samples only): 0.8649\n",
      "Vulnerable to Benign Changes (1‚Üí0): 0.8649 (288/333)\n",
      "Fitness Score: 1.1900\n",
      "Length Penalty: 0.0100\n",
      "Code Snippet Length: 1\n",
      "\n",
      "=== GENERATING ADVERSARIAL PREDICTIONS ===\n",
      "Generating adversarial predictions with best code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating adversarial predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 732/732 [00:18<00:00, 39.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory is read-only, using current directory: /kaggle/working\n",
      "Adversarial predictions exported to: /kaggle/working/prediction_adv_cwe399_2025-06-03_06-03-31.txt\n",
      "Total adversarial predictions exported: 732\n",
      "\n",
      "=== FINAL ADVERSARIAL ATTACK RESULTS ===\n",
      "Total prediction changes: 326/732 (0.4454)\n",
      "Vulnerable‚ÜíBenign changes: 326\n",
      "Benign‚ÜíVulnerable changes: 0\n",
      "Adversarial predictions saved to: /kaggle/working/prediction_adv_cwe399_2025-06-03_06-03-31.txt\n",
      "\n",
      "=== ORIGINAL MODEL PERFORMANCE ===\n",
      "Accuracy: 0.8921\n",
      "Precision: 0.8848\n",
      "Recall: 0.8769\n",
      "F1-Score: 0.8808\n",
      "Results saved to adversarial_results_cwe399.json\n",
      "\n",
      "Best adversarial code found:\n",
      "--------------------------------------------------\n",
      "int *ptr = malloc(10); if(ptr != NULL) { free(ptr); ptr = NULL; }\n",
      "--------------------------------------------------\n",
      "Best fitness: 1.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize adversarial learning\n",
    "adversarial_learner = AdversarialLearning(\n",
    "    attack_pool_path=\"/kaggle/input/eatvul/cwe399_attack_pool.csv\",  # Replace with your attack pool\n",
    "    model_path='/kaggle/input/eatvul/cwe399-codet5-model/model/',  # For generating adversarial predictions\n",
    "    pop_size=10,\n",
    "    max_generations=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run adversarial learning with loaded predictions\n",
    "try:\n",
    "    best_code, best_fitness = adversarial_learner.run(\n",
    "        original_data_path='/kaggle/input/eatvul/cwe399_test.csv',\n",
    "        prediction_file_path='/kaggle/input/eatvul/predict_codet5_cwe399.txt'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest adversarial code found:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(best_code)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best fitness: {best_fitness:.4f}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    print(\"Please ensure your data and prediction files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbfdfbc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T06:03:31.379376Z",
     "iopub.status.busy": "2025-06-03T06:03:31.378981Z",
     "iopub.status.idle": "2025-06-03T06:10:11.621304Z",
     "shell.execute_reply": "2025-06-03T06:10:11.620687Z"
    },
    "papermill": {
     "duration": 400.258725,
     "end_time": "2025-06-03T06:10:11.622450",
     "exception": false,
     "start_time": "2025-06-03T06:03:31.363725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ATTACK POOL LOADING ===\n",
      "Raw attack pool shape: (200, 3)\n",
      "Available columns: ['original_code', 'adversarial_code', 'label']\n",
      "Detected attack pool format with 'adversarial_code' column\n",
      "Attack pool processed successfully:\n",
      "  Initial size: 200\n",
      "  After removing NaN: 200\n",
      "  Final shape: (200, 1)\n",
      "Sample adversarial codes:\n",
      "  [1] nsSMILTimeContainer* container_var = nullptr;\n",
      "double aoffsetseconds_var = aOffsetSeconds;\n",
      "nsSMILTime...\n",
      "  [2] void* sa_var;\n",
      "struct task_struct* task_struct_var;\n",
      "struct k_sigaction* ka_var;\n",
      "if(task_struct_var &&...\n",
      "  [3] const int const_var = 0;\n",
      "nsPresContext* nsprescontext_var = nullptr;\n",
      "nsIFrame* getparent_var = nullp...\n",
      "Loading model from /kaggle/input/eatvul/cwe119-codet5-model/model/\n",
      "Loading best model checkpoint\n",
      "Loaded tokenizer from saved model\n",
      "Loaded training history. Best validation accuracy: 0.9565\n",
      "Model loaded successfully and set to evaluation mode\n",
      "Successfully loaded model from /kaggle/input/eatvul/cwe119-codet5-model/model/\n",
      "Model is in eval mode: True\n",
      "Model test prediction: {'prediction': 0, 'confidence': 0.6612788438796997, 'probabilities': [0.6612788438796997, 0.3387211263179779], 'label_names': ['Not Vulnerable', 'Vulnerable']}\n",
      "\n",
      "===== ADVERSARIAL LEARNING DIAGNOSTICS =====\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe119.txt\n",
      "\n",
      "=== LOADING PREDICTIONS FROM TXT ===\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe119.txt\n",
      "Loaded 851 predictions\n",
      "Prediction distribution: [439 412]\n",
      "  0 (not vulnerable): 439\n",
      "  1 (vulnerable): 412\n",
      "Loaded original data from /kaggle/input/eatvul/cwe119_test.csv\n",
      "Data composition: 425 vulnerable, 426 benign samples\n",
      "\n",
      "=== POPULATION INITIALIZATION ===\n",
      "Attack pool size: 200\n",
      "Requested population size: 10\n",
      "Attack pool larger than population size - sampling without replacement\n",
      "Population successfully initialized:\n",
      "  Population size: 10\n",
      "  Unique adversarial codes: 10\n",
      "  Clusters: 3\n",
      "  Initial centroids: [0.83876563 0.62730259 0.41220483]\n",
      "Sample population codes:\n",
      "  [1] void (*g_free_var)(void*) = g_free;\n",
      "Tile* tile_var = NULL;\n",
      "void (*tile_cache_flu...\n",
      "  [2] const int sdp_start_var = req->sdp_start;\n",
      "int stop_var = stop;\n",
      "int start_var = *...\n",
      "  [3] vorbis_block *vb_var=vb;\n",
      "vorbis_look_residue *vl_var=vl;\n",
      "int ch_var=ch;\n",
      "if(used>...\n",
      "Enhancing attack pool with more aggressive adversarial examples...\n",
      "Using loaded predictions from txt file, skipping model initialization\n",
      "Calculating initial fitness scores...\n",
      "\n",
      "===== USING LOADED PREDICTIONS =====\n",
      "Loaded 851 predictions from txt file\n",
      "Skipping model validation since predictions are pre-computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [03:49<00:00, 22.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNOSING BEST INITIAL ADVERSARIAL CODE ===\n",
      "\n",
      "=== ATTACK EFFECTIVENESS DIAGNOSIS ===\n",
      "Adversarial code being tested:\n",
      "--------------------------------------------------\n",
      "/* This code was previously flagged as vulnerable */\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing on 10 vulnerable samples:\n",
      "Sample 1: Originally not detected as vulnerable (pred=0, conf=0.531)\n",
      "Sample 3:\n",
      "  Original: pred=1, conf=0.997\n",
      "  Adversarial: pred=1, conf=0.997\n",
      "  Attack success: False\n",
      "  Confidence change: 0.997 -> 0.997\n",
      "  Adversarial code snippet:\n",
      "                OMX_INDEXTYPE index, OMX_PTR params) {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "         switch (index) {\n",
      "         case OMX_IndexParamVideoPortFormat:\n",
      "\n",
      "Sample 4:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        OMX_IN OMX_INDEXTYPE paramIndex,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        OMX_IN OMX_PTR        paramData)\n",
      "        {\n",
      "\n",
      "Sample 5:\n",
      "  Original: pred=1, conf=0.997\n",
      "  Adversarial: pred=1, conf=0.997\n",
      "  Attack success: False\n",
      "  Confidence change: 0.997 -> 0.997\n",
      "  Adversarial code snippet:\n",
      "        uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        switch (code) {\n",
      "        case LIVES_LOCALLY:\n",
      "\n",
      "Sample 6: Originally not detected as vulnerable (pred=0, conf=0.701)\n",
      "Sample 9:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        struct sshbuf *b = NULL;\n",
      "        struct sshcomp *comp;\n",
      "\n",
      "Sample 10:\n",
      "  Original: pred=1, conf=0.970\n",
      "  Adversarial: pred=1, conf=0.906\n",
      "  Attack success: False\n",
      "  Confidence change: 0.970 -> 0.906\n",
      "  Adversarial code snippet:\n",
      "             : m_object(0)\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "             , m_attachmentCount(0)\n",
      "             , m_deleted(false)\n",
      "\n",
      "Sample 11:\n",
      "  Original: pred=1, conf=0.980\n",
      "  Adversarial: pred=1, conf=0.980\n",
      "  Attack success: False\n",
      "  Confidence change: 0.980 -> 0.980\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "            struct xlx_ethlite *s = qemu_get_nic_opaque(nc);\n",
      "            unsigned int rxbase = s->rxbuf * (0x800 / 4);\n",
      "\n",
      "Sample 13:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        \n",
      "        /*\n",
      "\n",
      "Sample 14:\n",
      "  Original: pred=1, conf=0.994\n",
      "  Adversarial: pred=1, conf=0.994\n",
      "  Attack success: False\n",
      "  Confidence change: 0.994 -> 0.994\n",
      "  Adversarial code snippet:\n",
      "        \t\tbool *path_nulls, int path_len,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        \t\tJsonbParseState **st, int level, Jsonb *newval, bool create)\n",
      "        {\n",
      "\n",
      "Overall attack success rate: 0.0000 (0/10)\n",
      "\n",
      "=== ADDITIONAL DIAGNOSTICS ===\n",
      "Adversarial code in isolation:\n",
      "  Prediction: 0 (0=benign, 1=vulnerable)\n",
      "  Confidence: 0.738\n",
      "  -> Adversarial code itself is not detected as vulnerable\n",
      "  -> This might explain low attack success rates\n",
      "\n",
      "=== Generation 1/1 ===\n",
      "Best fitness so far: 0.0175\n",
      "Best attack success rate: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offspring fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:54<00:00, 22.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Direct Attack Success Rate Calculation ===\n",
      "Using loaded predictions for direct attack calculation...\n",
      "Found 425 vulnerable samples for adversarial testing\n",
      "Getting adversarial predictions...\n",
      "\n",
      "=== Final Attack Success Results ===\n",
      "Overall Attack Success Rate (any change): 0.0275\n",
      "Direct Attack Success Rate (vulnerable samples only): 0.0776\n",
      "Vulnerable to Benign Changes (1‚Üí0): 0.0212 (9/425)\n",
      "Fitness Score: 0.0175\n",
      "Length Penalty: 0.0100\n",
      "Code Snippet Length: 1\n",
      "\n",
      "=== GENERATING ADVERSARIAL PREDICTIONS ===\n",
      "Generating adversarial predictions with best code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating adversarial predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 851/851 [00:23<00:00, 36.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory is read-only, using current directory: /kaggle/working\n",
      "Adversarial predictions exported to: /kaggle/working/prediction_adv_cwe119_2025-06-03_06-10-11.txt\n",
      "Total adversarial predictions exported: 851\n",
      "\n",
      "=== FINAL ADVERSARIAL ATTACK RESULTS ===\n",
      "Total prediction changes: 373/851 (0.4383)\n",
      "Vulnerable‚ÜíBenign changes: 9\n",
      "Benign‚ÜíVulnerable changes: 364\n",
      "Adversarial predictions saved to: /kaggle/working/prediction_adv_cwe119_2025-06-03_06-10-11.txt\n",
      "\n",
      "=== ORIGINAL MODEL PERFORMANCE ===\n",
      "Accuracy: 0.9565\n",
      "Precision: 0.9709\n",
      "Recall: 0.9412\n",
      "F1-Score: 0.9558\n",
      "Results saved to adversarial_results_cwe119.json\n",
      "\n",
      "Best adversarial code found:\n",
      "--------------------------------------------------\n",
      "/* This code was previously flagged as vulnerable */\n",
      "--------------------------------------------------\n",
      "Best fitness: 0.0175\n"
     ]
    }
   ],
   "source": [
    "# Initialize adversarial learning\n",
    "adversarial_learner = AdversarialLearning(\n",
    "    attack_pool_path=\"/kaggle/input/eatvul/cwe399_attack_pool.csv\",  # Replace with your attack pool\n",
    "    model_path='/kaggle/input/eatvul/cwe119-codet5-model/model/',  # For generating adversarial predictions\n",
    "    pop_size=10,\n",
    "    max_generations=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run adversarial learning with loaded predictions\n",
    "try:\n",
    "    best_code, best_fitness = adversarial_learner.run(\n",
    "        original_data_path='/kaggle/input/eatvul/cwe119_test.csv',\n",
    "        prediction_file_path='/kaggle/input/eatvul/predict_codet5_cwe119.txt'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest adversarial code found:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(best_code)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best fitness: {best_fitness:.4f}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    print(\"Please ensure your data and prediction files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56eb99be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T06:10:11.672144Z",
     "iopub.status.busy": "2025-06-03T06:10:11.671893Z",
     "iopub.status.idle": "2025-06-03T06:11:21.533845Z",
     "shell.execute_reply": "2025-06-03T06:11:21.532902Z"
    },
    "papermill": {
     "duration": 69.887578,
     "end_time": "2025-06-03T06:11:21.534956",
     "exception": false,
     "start_time": "2025-06-03T06:10:11.647378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ATTACK POOL LOADING ===\n",
      "Raw attack pool shape: (200, 3)\n",
      "Available columns: ['original_code', 'adversarial_code', 'label']\n",
      "Detected attack pool format with 'adversarial_code' column\n",
      "Attack pool processed successfully:\n",
      "  Initial size: 200\n",
      "  After removing NaN: 200\n",
      "  Final shape: (200, 1)\n",
      "Sample adversarial codes:\n",
      "  [1] nsSMILTimeContainer* container_var = nullptr;\n",
      "double aoffsetseconds_var = aOffsetSeconds;\n",
      "nsSMILTime...\n",
      "  [2] void* sa_var;\n",
      "struct task_struct* task_struct_var;\n",
      "struct k_sigaction* ka_var;\n",
      "if(task_struct_var &&...\n",
      "  [3] const int const_var = 0;\n",
      "nsPresContext* nsprescontext_var = nullptr;\n",
      "nsIFrame* getparent_var = nullp...\n",
      "Loading model from /kaggle/input/eatvul/cwe189-codet5-model/model/\n",
      "Loading best model checkpoint\n",
      "Loaded tokenizer from saved model\n",
      "Loaded training history. Best validation accuracy: 0.9565\n",
      "Model loaded successfully and set to evaluation mode\n",
      "Successfully loaded model from /kaggle/input/eatvul/cwe189-codet5-model/model/\n",
      "Model is in eval mode: True\n",
      "Model test prediction: {'prediction': 0, 'confidence': 0.6612788438796997, 'probabilities': [0.6612788438796997, 0.3387211263179779], 'label_names': ['Not Vulnerable', 'Vulnerable']}\n",
      "\n",
      "===== ADVERSARIAL LEARNING DIAGNOSTICS =====\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe189.txt\n",
      "\n",
      "=== LOADING PREDICTIONS FROM TXT ===\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe189.txt\n",
      "Loaded 135 predictions\n",
      "Prediction distribution: [75 60]\n",
      "  0 (not vulnerable): 75\n",
      "  1 (vulnerable): 60\n",
      "Loaded original data from /kaggle/input/eatvul/cwe189_test.csv\n",
      "Data composition: 67 vulnerable, 68 benign samples\n",
      "\n",
      "=== POPULATION INITIALIZATION ===\n",
      "Attack pool size: 200\n",
      "Requested population size: 10\n",
      "Attack pool larger than population size - sampling without replacement\n",
      "Population successfully initialized:\n",
      "  Population size: 10\n",
      "  Unique adversarial codes: 10\n",
      "  Clusters: 3\n",
      "  Initial centroids: [0.22673667 0.46647682 0.00479383]\n",
      "Sample population codes:\n",
      "  [1] struct sctp_association *asoc_var = NULL;\n",
      "struct sock *sock_var = NULL;\n",
      "int (*sc...\n",
      "  [2] int slot_var = slot + 1;\n",
      "int mypmchildslot_var = MyPMChildSlot - 1;\n",
      "volatile int...\n",
      "  [3] JSRuntime *jsruntime_var = rt_var ? rt_var : NULL;\n",
      "jsbytecode *pc_var = pc ? pc ...\n",
      "Enhancing attack pool with more aggressive adversarial examples...\n",
      "Using loaded predictions from txt file, skipping model initialization\n",
      "Calculating initial fitness scores...\n",
      "\n",
      "===== USING LOADED PREDICTIONS =====\n",
      "Loaded 135 predictions from txt file\n",
      "Skipping model validation since predictions are pre-computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:36<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNOSING BEST INITIAL ADVERSARIAL CODE ===\n",
      "\n",
      "=== ATTACK EFFECTIVENESS DIAGNOSIS ===\n",
      "Adversarial code being tested:\n",
      "--------------------------------------------------\n",
      "/* This code was previously flagged as vulnerable */\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing on 10 vulnerable samples:\n",
      "Sample 0:\n",
      "  Original: pred=1, conf=0.997\n",
      "  Adversarial: pred=1, conf=0.996\n",
      "  Attack success: False\n",
      "  Confidence change: 0.997 -> 0.996\n",
      "  Adversarial code snippet:\n",
      "        GfxColorSpace *colorSpaceA) {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        GfxIndexedColorSpace *indexedCS;\n",
      "        GfxSeparationColorSpace *sepCS;\n",
      "\n",
      "Sample 1: Originally not detected as vulnerable (pred=0, conf=0.678)\n",
      "Sample 2:\n",
      "  Original: pred=1, conf=0.912\n",
      "  Adversarial: pred=1, conf=0.915\n",
      "  Attack success: False\n",
      "  Confidence change: 0.912 -> 0.915\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        \n",
      "        u64 nsec;\n",
      "\n",
      "Sample 3:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.997\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.997\n",
      "  Adversarial code snippet:\n",
      "        int width, int height,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        GfxImageColorMap *colorMap,\n",
      "        int *maskColors, GBool inlineImg) {\n",
      "\n",
      "Sample 4:\n",
      "  Original: pred=1, conf=0.921\n",
      "  Adversarial: pred=1, conf=0.921\n",
      "  Attack success: False\n",
      "  Confidence change: 0.921 -> 0.921\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        const char *s;\n",
      "        \n",
      "\n",
      "Sample 5:\n",
      "  Original: pred=1, conf=0.793\n",
      "  Adversarial: pred=1, conf=0.716\n",
      "  Attack success: False\n",
      "  Confidence change: 0.793 -> 0.716\n",
      "  Adversarial code snippet:\n",
      "            PowerLibrary* library, bool own) {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "          library_->power_lib_.SetImpl(library, own);\n",
      "        }\n",
      "\n",
      "Sample 6:\n",
      "  Original: pred=1, conf=0.996\n",
      "  Adversarial: pred=1, conf=0.996\n",
      "  Attack success: False\n",
      "  Confidence change: 0.996 -> 0.996\n",
      "  Adversarial code snippet:\n",
      "        gint    width,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        gint    height,\n",
      "        gint    rowstride)\n",
      "\n",
      "Sample 8:\n",
      "  Original: pred=1, conf=0.944\n",
      "  Adversarial: pred=1, conf=0.947\n",
      "  Attack success: False\n",
      "  Confidence change: 0.944 -> 0.947\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        \n",
      "        if (timr->it.mmtimer.clock == TIMER_OFF) {\n",
      "\n",
      "Sample 9:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        int stream_id, const media::AudioParameters& params,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        const std::string& device_id, bool automatic_gain_control) {\n",
      "        VLOG(1) << \"AudioInputRendererHost::OnCreateStream(stream_id=\"\n",
      "\n",
      "Sample 12:\n",
      "  Original: pred=1, conf=0.995\n",
      "  Adversarial: pred=1, conf=0.995\n",
      "  Attack success: False\n",
      "  Confidence change: 0.995 -> 0.995\n",
      "  Adversarial code snippet:\n",
      "        // Do nothing if we have encountered an error.\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        if (error_)\n",
      "        return;\n",
      "\n",
      "Overall attack success rate: 0.0000 (0/10)\n",
      "\n",
      "=== ADDITIONAL DIAGNOSTICS ===\n",
      "Adversarial code in isolation:\n",
      "  Prediction: 0 (0=benign, 1=vulnerable)\n",
      "  Confidence: 0.738\n",
      "  -> Adversarial code itself is not detected as vulnerable\n",
      "  -> This might explain low attack success rates\n",
      "\n",
      "=== Generation 1/1 ===\n",
      "Best fitness so far: 0.0590\n",
      "Best attack success rate: 0.0690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offspring fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:18<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Direct Attack Success Rate Calculation ===\n",
      "Using loaded predictions for direct attack calculation...\n",
      "Found 67 vulnerable samples for adversarial testing\n",
      "Getting adversarial predictions...\n",
      "\n",
      "=== Final Attack Success Results ===\n",
      "Overall Attack Success Rate (any change): 0.0690\n",
      "Direct Attack Success Rate (vulnerable samples only): 0.1791\n",
      "Vulnerable to Benign Changes (1‚Üí0): 0.0448 (3/67)\n",
      "Fitness Score: 0.0590\n",
      "Length Penalty: 0.0100\n",
      "Code Snippet Length: 1\n",
      "\n",
      "=== GENERATING ADVERSARIAL PREDICTIONS ===\n",
      "Generating adversarial predictions with best code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating adversarial predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 135/135 [00:03<00:00, 36.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory is read-only, using current directory: /kaggle/working\n",
      "Adversarial predictions exported to: /kaggle/working/prediction_adv_cwe189_2025-06-03_06-11-21.txt\n",
      "Total adversarial predictions exported: 135\n",
      "\n",
      "=== FINAL ADVERSARIAL ATTACK RESULTS ===\n",
      "Total prediction changes: 68/135 (0.5037)\n",
      "Vulnerable‚ÜíBenign changes: 3\n",
      "Benign‚ÜíVulnerable changes: 65\n",
      "Adversarial predictions saved to: /kaggle/working/prediction_adv_cwe189_2025-06-03_06-11-21.txt\n",
      "\n",
      "=== ORIGINAL MODEL PERFORMANCE ===\n",
      "Accuracy: 0.9185\n",
      "Precision: 0.9667\n",
      "Recall: 0.8657\n",
      "F1-Score: 0.9134\n",
      "Results saved to adversarial_results_cwe189.json\n",
      "\n",
      "Best adversarial code found:\n",
      "--------------------------------------------------\n",
      "/* This code was previously flagged as vulnerable */\n",
      "--------------------------------------------------\n",
      "Best fitness: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize adversarial learning\n",
    "adversarial_learner = AdversarialLearning(\n",
    "    attack_pool_path=\"/kaggle/input/eatvul/cwe399_attack_pool.csv\",  # Replace with your attack pool\n",
    "    model_path='/kaggle/input/eatvul/cwe189-codet5-model/model/',  # For generating adversarial predictions\n",
    "    pop_size=10,\n",
    "    max_generations=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run adversarial learning with loaded predictions\n",
    "try:\n",
    "    best_code, best_fitness = adversarial_learner.run(\n",
    "        original_data_path='/kaggle/input/eatvul/cwe189_test.csv',\n",
    "        prediction_file_path='/kaggle/input/eatvul/predict_codet5_cwe189.txt'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest adversarial code found:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(best_code)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best fitness: {best_fitness:.4f}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    print(\"Please ensure your data and prediction files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5560116d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T06:11:21.590306Z",
     "iopub.status.busy": "2025-06-03T06:11:21.589723Z",
     "iopub.status.idle": "2025-06-03T06:12:30.009457Z",
     "shell.execute_reply": "2025-06-03T06:12:30.008729Z"
    },
    "papermill": {
     "duration": 68.448217,
     "end_time": "2025-06-03T06:12:30.010756",
     "exception": false,
     "start_time": "2025-06-03T06:11:21.562539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ATTACK POOL LOADING ===\n",
      "Raw attack pool shape: (200, 3)\n",
      "Available columns: ['original_code', 'adversarial_code', 'label']\n",
      "Detected attack pool format with 'adversarial_code' column\n",
      "Attack pool processed successfully:\n",
      "  Initial size: 200\n",
      "  After removing NaN: 200\n",
      "  Final shape: (200, 1)\n",
      "Sample adversarial codes:\n",
      "  [1] nsSMILTimeContainer* container_var = nullptr;\n",
      "double aoffsetseconds_var = aOffsetSeconds;\n",
      "nsSMILTime...\n",
      "  [2] void* sa_var;\n",
      "struct task_struct* task_struct_var;\n",
      "struct k_sigaction* ka_var;\n",
      "if(task_struct_var &&...\n",
      "  [3] const int const_var = 0;\n",
      "nsPresContext* nsprescontext_var = nullptr;\n",
      "nsIFrame* getparent_var = nullp...\n",
      "Loading model from /kaggle/input/eatvul/cwe416-codet5-model/model/\n",
      "Loading best model checkpoint\n",
      "Loaded tokenizer from saved model\n",
      "Loaded training history. Best validation accuracy: 0.9565\n",
      "Model loaded successfully and set to evaluation mode\n",
      "Successfully loaded model from /kaggle/input/eatvul/cwe416-codet5-model/model/\n",
      "Model is in eval mode: True\n",
      "Model test prediction: {'prediction': 0, 'confidence': 0.6612788438796997, 'probabilities': [0.6612788438796997, 0.3387211263179779], 'label_names': ['Not Vulnerable', 'Vulnerable']}\n",
      "\n",
      "===== ADVERSARIAL LEARNING DIAGNOSTICS =====\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe416.txt\n",
      "\n",
      "=== LOADING PREDICTIONS FROM TXT ===\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe416.txt\n",
      "Loaded 132 predictions\n",
      "Prediction distribution: [80 52]\n",
      "  0 (not vulnerable): 80\n",
      "  1 (vulnerable): 52\n",
      "Loaded original data from /kaggle/input/eatvul/cwe416_test.csv\n",
      "Data composition: 66 vulnerable, 66 benign samples\n",
      "\n",
      "=== POPULATION INITIALIZATION ===\n",
      "Attack pool size: 200\n",
      "Requested population size: 10\n",
      "Attack pool larger than population size - sampling without replacement\n",
      "Population successfully initialized:\n",
      "  Population size: 10\n",
      "  Unique adversarial codes: 10\n",
      "  Clusters: 3\n",
      "  Initial centroids: [0.03921336 0.36804682 0.5617156 ]\n",
      "Sample population codes:\n",
      "  [1] bool isaboutblank_var = false;\n",
      "nsresult getter_addrefs_var = NS_OK;\n",
      "nsCOMPtr<nsI...\n",
      "  [2] unsigned char *data_var = NULL;\n",
      "unsigned short seq_var;\n",
      "void (*n2s_var)(unsigned...\n",
      "  [3] JSContext *jscontext_var = NULL;\n",
      "jsval id_var = JSVAL_VOID;\n",
      "JSContext *cx_var = ...\n",
      "Enhancing attack pool with more aggressive adversarial examples...\n",
      "Using loaded predictions from txt file, skipping model initialization\n",
      "Calculating initial fitness scores...\n",
      "\n",
      "===== USING LOADED PREDICTIONS =====\n",
      "Loaded 132 predictions from txt file\n",
      "Skipping model validation since predictions are pre-computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:35<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNOSING BEST INITIAL ADVERSARIAL CODE ===\n",
      "\n",
      "=== ATTACK EFFECTIVENESS DIAGNOSIS ===\n",
      "Adversarial code being tested:\n",
      "--------------------------------------------------\n",
      "// This is a harmless comment that might confuse the model\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing on 10 vulnerable samples:\n",
      "Sample 3:\n",
      "  Original: pred=1, conf=0.996\n",
      "  Adversarial: pred=1, conf=0.996\n",
      "  Attack success: False\n",
      "  Confidence change: 0.996 -> 0.996\n",
      "  Adversarial code snippet:\n",
      "        mojom::ClientProcessPtr client_process_ptr,\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        mojom::ProcessType process_type) {\n",
      "        DCHECK_CALLED_ON_VALID_THREAD(thread_checker_);\n",
      "\n",
      "Sample 7:\n",
      "  Original: pred=1, conf=0.934\n",
      "  Adversarial: pred=1, conf=0.949\n",
      "  Attack success: False\n",
      "  Confidence change: 0.934 -> 0.949\n",
      "  Adversarial code snippet:\n",
      "        int i;\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        \n",
      "        \tif (bin->hdr.filetype != MH_EXECUTE && bin->hdr.filetype != MH_DYLINKER)\n",
      "\n",
      "Sample 12:\n",
      "  Original: pred=1, conf=0.980\n",
      "  Adversarial: pred=1, conf=0.982\n",
      "  Attack success: False\n",
      "  Confidence change: 0.980 -> 0.982\n",
      "  Adversarial code snippet:\n",
      "        unsigned long addr, unsigned long flags)\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        {\n",
      "        int err;\n",
      "\n",
      "Sample 14:\n",
      "  Original: pred=1, conf=0.997\n",
      "  Adversarial: pred=1, conf=0.997\n",
      "  Attack success: False\n",
      "  Confidence change: 0.997 -> 0.997\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        \tzval *val;\n",
      "        \tchar sbuf[512];\n",
      "\n",
      "Sample 15:\n",
      "  Original: pred=1, conf=0.997\n",
      "  Adversarial: pred=1, conf=0.996\n",
      "  Attack success: False\n",
      "  Confidence change: 0.997 -> 0.996\n",
      "  Adversarial code snippet:\n",
      "               const int64* original_values, size_t original_count,\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "               const int64* received_values, size_t received_count,\n",
      "               const int64* original_with_data_reduction_proxy_enabled_values,\n",
      "\n",
      "Sample 16:\n",
      "  Original: pred=1, conf=0.969\n",
      "  Adversarial: pred=1, conf=0.968\n",
      "  Attack success: False\n",
      "  Confidence change: 0.969 -> 0.968\n",
      "  Adversarial code snippet:\n",
      "        ContainerNode& insertion_point) {\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        HTMLElement::InsertedInto(insertion_point);\n",
      "        LogAddElementIfIsolatedWorldAndInDocument(\"link\", relAttr, hrefAttr);\n",
      "\n",
      "Sample 18:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        \tconst char *endptr = val + vallen;\n",
      "        \tzval *session_vars;\n",
      "\n",
      "Sample 20:\n",
      "  Original: pred=1, conf=0.989\n",
      "  Adversarial: pred=1, conf=0.989\n",
      "  Attack success: False\n",
      "  Confidence change: 0.989 -> 0.989\n",
      "  Adversarial code snippet:\n",
      "        \t\t\t     struct netlink_ext_ack *extack)\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        {\n",
      "        \tstruct net *net = sock_net(skb->sk);\n",
      "\n",
      "Sample 21:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        struct load_command lc = {0, 0};\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        ut8 loadc[sizeof (struct load_command)] = {0};\n",
      "        bool is_first_thread = true;\n",
      "\n",
      "Sample 22:\n",
      "  Original: pred=1, conf=0.995\n",
      "  Adversarial: pred=1, conf=0.995\n",
      "  Attack success: False\n",
      "  Confidence change: 0.995 -> 0.995\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> // This is a harmless comment that might confuse the model\n",
      "        \tint rv = 0;\n",
      "        \tint i;\n",
      "\n",
      "Overall attack success rate: 0.0000 (0/10)\n",
      "\n",
      "=== ADDITIONAL DIAGNOSTICS ===\n",
      "Adversarial code in isolation:\n",
      "  Prediction: 0 (0=benign, 1=vulnerable)\n",
      "  Confidence: 0.706\n",
      "  -> Adversarial code itself is not detected as vulnerable\n",
      "  -> This might explain low attack success rates\n",
      "\n",
      "=== Generation 1/1 ===\n",
      "Best fitness so far: -0.0100\n",
      "Best attack success rate: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offspring fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:17<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Direct Attack Success Rate Calculation ===\n",
      "Using loaded predictions for direct attack calculation...\n",
      "Found 66 vulnerable samples for adversarial testing\n",
      "Getting adversarial predictions...\n",
      "\n",
      "=== Final Attack Success Results ===\n",
      "Overall Attack Success Rate (any change): 0.0000\n",
      "Direct Attack Success Rate (vulnerable samples only): 0.2273\n",
      "Vulnerable to Benign Changes (1‚Üí0): 0.0000 (0/66)\n",
      "Fitness Score: -0.0100\n",
      "Length Penalty: 0.0100\n",
      "Code Snippet Length: 1\n",
      "\n",
      "=== GENERATING ADVERSARIAL PREDICTIONS ===\n",
      "Generating adversarial predictions with best code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating adversarial predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132/132 [00:03<00:00, 37.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory is read-only, using current directory: /kaggle/working\n",
      "Adversarial predictions exported to: /kaggle/working/prediction_adv_cwe416_2025-06-03_06-12-29.txt\n",
      "Total adversarial predictions exported: 132\n",
      "\n",
      "=== FINAL ADVERSARIAL ATTACK RESULTS ===\n",
      "Total prediction changes: 71/132 (0.5379)\n",
      "Vulnerable‚ÜíBenign changes: 0\n",
      "Benign‚ÜíVulnerable changes: 71\n",
      "Adversarial predictions saved to: /kaggle/working/prediction_adv_cwe416_2025-06-03_06-12-29.txt\n",
      "\n",
      "=== ORIGINAL MODEL PERFORMANCE ===\n",
      "Accuracy: 0.8788\n",
      "Precision: 0.9808\n",
      "Recall: 0.7727\n",
      "F1-Score: 0.8644\n",
      "Results saved to adversarial_results_cwe416.json\n",
      "\n",
      "Best adversarial code found:\n",
      "--------------------------------------------------\n",
      "// This is a harmless comment that might confuse the model\n",
      "--------------------------------------------------\n",
      "Best fitness: -0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize adversarial learning\n",
    "adversarial_learner = AdversarialLearning(\n",
    "    attack_pool_path=\"/kaggle/input/eatvul/cwe399_attack_pool.csv\",  # Replace with your attack pool\n",
    "    model_path='/kaggle/input/eatvul/cwe416-codet5-model/model/',  # For generating adversarial predictions\n",
    "    pop_size=10,\n",
    "    max_generations=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run adversarial learning with loaded predictions\n",
    "try:\n",
    "    best_code, best_fitness = adversarial_learner.run(\n",
    "        original_data_path='/kaggle/input/eatvul/cwe416_test.csv',\n",
    "        prediction_file_path='/kaggle/input/eatvul/predict_codet5_cwe416.txt'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest adversarial code found:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(best_code)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best fitness: {best_fitness:.4f}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    print(\"Please ensure your data and prediction files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a88ef4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T06:12:30.071886Z",
     "iopub.status.busy": "2025-06-03T06:12:30.071238Z",
     "iopub.status.idle": "2025-06-03T06:16:05.470415Z",
     "shell.execute_reply": "2025-06-03T06:16:05.469695Z"
    },
    "papermill": {
     "duration": 215.43027,
     "end_time": "2025-06-03T06:16:05.471781",
     "exception": false,
     "start_time": "2025-06-03T06:12:30.041511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ATTACK POOL LOADING ===\n",
      "Raw attack pool shape: (200, 3)\n",
      "Available columns: ['original_code', 'adversarial_code', 'label']\n",
      "Detected attack pool format with 'adversarial_code' column\n",
      "Attack pool processed successfully:\n",
      "  Initial size: 200\n",
      "  After removing NaN: 200\n",
      "  Final shape: (200, 1)\n",
      "Sample adversarial codes:\n",
      "  [1] nsSMILTimeContainer* container_var = nullptr;\n",
      "double aoffsetseconds_var = aOffsetSeconds;\n",
      "nsSMILTime...\n",
      "  [2] void* sa_var;\n",
      "struct task_struct* task_struct_var;\n",
      "struct k_sigaction* ka_var;\n",
      "if(task_struct_var &&...\n",
      "  [3] const int const_var = 0;\n",
      "nsPresContext* nsprescontext_var = nullptr;\n",
      "nsIFrame* getparent_var = nullp...\n",
      "Loading model from /kaggle/input/eatvul/cwe20-codet5-model/model/\n",
      "Loading best model checkpoint\n",
      "Loaded tokenizer from saved model\n",
      "Loaded training history. Best validation accuracy: 0.9565\n",
      "Model loaded successfully and set to evaluation mode\n",
      "Successfully loaded model from /kaggle/input/eatvul/cwe20-codet5-model/model/\n",
      "Model is in eval mode: True\n",
      "Model test prediction: {'prediction': 0, 'confidence': 0.6612788438796997, 'probabilities': [0.6612788438796997, 0.3387211263179779], 'label_names': ['Not Vulnerable', 'Vulnerable']}\n",
      "\n",
      "===== ADVERSARIAL LEARNING DIAGNOSTICS =====\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe20.txt\n",
      "\n",
      "=== LOADING PREDICTIONS FROM TXT ===\n",
      "Loading predictions from: /kaggle/input/eatvul/predict_codet5_cwe20.txt\n",
      "Loaded 457 predictions\n",
      "Prediction distribution: [247 210]\n",
      "  0 (not vulnerable): 247\n",
      "  1 (vulnerable): 210\n",
      "Loaded original data from /kaggle/input/eatvul/cwe20_test.csv\n",
      "Data composition: 228 vulnerable, 229 benign samples\n",
      "\n",
      "=== POPULATION INITIALIZATION ===\n",
      "Attack pool size: 200\n",
      "Requested population size: 10\n",
      "Attack pool larger than population size - sampling without replacement\n",
      "Population successfully initialized:\n",
      "  Population size: 10\n",
      "  Unique adversarial codes: 10\n",
      "  Clusters: 3\n",
      "  Initial centroids: [0.26377389 0.73989204 0.52200116]\n",
      "Sample population codes:\n",
      "  [1] else{\n",
      "int g_string_append__var = 0;\n",
      "if(cfile . count > 100){\n",
      "GtkStatusbar* gtk_s...\n",
      "  [2] const InstanceTimeList* instancetimelist_var = &aList;\n",
      "const nsSMILTimeValue* ab...\n",
      "  [3] const int const_el = el;\n",
      "char *col_data_var = (char*)cinfo->col_data;\n",
      "int fmt_ma...\n",
      "Enhancing attack pool with more aggressive adversarial examples...\n",
      "Using loaded predictions from txt file, skipping model initialization\n",
      "Calculating initial fitness scores...\n",
      "\n",
      "===== USING LOADED PREDICTIONS =====\n",
      "Loaded 457 predictions from txt file\n",
      "Skipping model validation since predictions are pre-computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:01<00:00, 12.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNOSING BEST INITIAL ADVERSARIAL CODE ===\n",
      "\n",
      "=== ATTACK EFFECTIVENESS DIAGNOSIS ===\n",
      "Adversarial code being tested:\n",
      "--------------------------------------------------\n",
      "/* This code was previously flagged as vulnerable */\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing on 10 vulnerable samples:\n",
      "Sample 1:\n",
      "  Original: pred=1, conf=0.953\n",
      "  Adversarial: pred=1, conf=0.956\n",
      "  Attack success: False\n",
      "  Confidence change: 0.953 -> 0.956\n",
      "  Adversarial code snippet:\n",
      "            int window_id,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "            std::string* error) {\n",
      "          Browser* browser = NULL;\n",
      "\n",
      "Sample 4:\n",
      "  Original: pred=1, conf=0.994\n",
      "  Adversarial: pred=1, conf=0.994\n",
      "  Attack success: False\n",
      "  Confidence change: 0.994 -> 0.994\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        \tstruct net_device *dev;\n",
      "        \tstruct bnep_session *s, *ss;\n",
      "\n",
      "Sample 5:\n",
      "  Original: pred=1, conf=0.985\n",
      "  Adversarial: pred=1, conf=0.985\n",
      "  Attack success: False\n",
      "  Confidence change: 0.985 -> 0.985\n",
      "  Adversarial code snippet:\n",
      "        signin::AccountConsistencyMethod account_consistency) {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "            oauth2_service_delegate_.reset(new MutableProfileOAuth2TokenServiceDelegate(\n",
      "        client_.get(), &signin_error_controller_, &account_tracker_service_,\n",
      "\n",
      "Sample 8:\n",
      "  Original: pred=1, conf=0.754\n",
      "  Adversarial: pred=1, conf=0.767\n",
      "  Attack success: False\n",
      "  Confidence change: 0.754 -> 0.767\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        /* VPD - all zeros */\n",
      "        return MPTSAS_CONFIG_PACK(1, MPI_CONFIG_PAGETYPE_MANUFACTURING, 0x00,\n",
      "\n",
      "Sample 11:\n",
      "  Original: pred=1, conf=0.997\n",
      "  Adversarial: pred=1, conf=0.997\n",
      "  Attack success: False\n",
      "  Confidence change: 0.997 -> 0.997\n",
      "  Adversarial code snippet:\n",
      "        chrome_observer_.reset(new ChromeRenderProcessObserver());\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        extension_dispatcher_.reset(new ExtensionDispatcher());\n",
      "        histogram_snapshots_.reset(new RendererHistogramSnapshots());\n",
      "\n",
      "Sample 13:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        if (context_.get()) {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        return context_.get();\n",
      "        }\n",
      "\n",
      "Sample 14:\n",
      "  Original: pred=1, conf=0.994\n",
      "  Adversarial: pred=1, conf=0.995\n",
      "  Attack success: False\n",
      "  Confidence change: 0.994 -> 0.995\n",
      "  Adversarial code snippet:\n",
      "        CID_Parser*  parser )\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        {\n",
      "        CID_FaceDict  dict;\n",
      "\n",
      "Sample 16:\n",
      "  Original: pred=1, conf=0.986\n",
      "  Adversarial: pred=1, conf=0.985\n",
      "  Attack success: False\n",
      "  Confidence change: 0.986 -> 0.985\n",
      "  Adversarial code snippet:\n",
      "        struct msghdr *msg, size_t len, int flags)\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        {\n",
      "        int noblock = flags & MSG_DONTWAIT;\n",
      "\n",
      "Sample 18:\n",
      "  Original: pred=1, conf=0.998\n",
      "  Adversarial: pred=1, conf=0.998\n",
      "  Attack success: False\n",
      "  Confidence change: 0.998 -> 0.998\n",
      "  Adversarial code snippet:\n",
      "        {\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "          Image\n",
      "            *image;\n",
      "\n",
      "Sample 20:\n",
      "  Original: pred=1, conf=0.983\n",
      "  Adversarial: pred=1, conf=0.983\n",
      "  Attack success: False\n",
      "  Confidence change: 0.983 -> 0.983\n",
      "  Adversarial code snippet:\n",
      "        struct scatterlist *dst, struct scatterlist *src,\n",
      "    >>> /* This code was previously flagged as vulnerable */\n",
      "        unsigned int nbytes)\n",
      "        {\n",
      "\n",
      "Overall attack success rate: 0.0000 (0/10)\n",
      "\n",
      "=== ADDITIONAL DIAGNOSTICS ===\n",
      "Adversarial code in isolation:\n",
      "  Prediction: 0 (0=benign, 1=vulnerable)\n",
      "  Confidence: 0.738\n",
      "  -> Adversarial code itself is not detected as vulnerable\n",
      "  -> This might explain low attack success rates\n",
      "\n",
      "=== Generation 1/1 ===\n",
      "Best fitness so far: 0.0153\n",
      "Best attack success rate: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offspring fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:00<00:00, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Direct Attack Success Rate Calculation ===\n",
      "Using loaded predictions for direct attack calculation...\n",
      "Found 228 vulnerable samples for adversarial testing\n",
      "Getting adversarial predictions...\n",
      "\n",
      "=== Final Attack Success Results ===\n",
      "Overall Attack Success Rate (any change): 0.0253\n",
      "Direct Attack Success Rate (vulnerable samples only): 0.1360\n",
      "Vulnerable to Benign Changes (1‚Üí0): 0.0219 (5/228)\n",
      "Fitness Score: 0.0153\n",
      "Length Penalty: 0.0100\n",
      "Code Snippet Length: 1\n",
      "\n",
      "=== GENERATING ADVERSARIAL PREDICTIONS ===\n",
      "Generating adversarial predictions with best code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating adversarial predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 457/457 [00:12<00:00, 37.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory is read-only, using current directory: /kaggle/working\n",
      "Adversarial predictions exported to: /kaggle/working/prediction_adv_cwe20_2025-06-03_06-16-05.txt\n",
      "Total adversarial predictions exported: 457\n",
      "\n",
      "=== FINAL ADVERSARIAL ATTACK RESULTS ===\n",
      "Total prediction changes: 196/457 (0.4289)\n",
      "Vulnerable‚ÜíBenign changes: 6\n",
      "Benign‚ÜíVulnerable changes: 190\n",
      "Adversarial predictions saved to: /kaggle/working/prediction_adv_cwe20_2025-06-03_06-16-05.txt\n",
      "\n",
      "=== ORIGINAL MODEL PERFORMANCE ===\n",
      "Accuracy: 0.9081\n",
      "Precision: 0.9429\n",
      "Recall: 0.8684\n",
      "F1-Score: 0.9041\n",
      "Results saved to adversarial_results_cwe20.json\n",
      "\n",
      "Best adversarial code found:\n",
      "--------------------------------------------------\n",
      "/* This code was previously flagged as vulnerable */\n",
      "--------------------------------------------------\n",
      "Best fitness: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize adversarial learning\n",
    "adversarial_learner = AdversarialLearning(\n",
    "    attack_pool_path=\"/kaggle/input/eatvul/cwe399_attack_pool.csv\",  # Replace with your attack pool\n",
    "    model_path='/kaggle/input/eatvul/cwe20-codet5-model/model/',  # For generating adversarial predictions\n",
    "    pop_size=10,\n",
    "    max_generations=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run adversarial learning with loaded predictions\n",
    "try:\n",
    "    best_code, best_fitness = adversarial_learner.run(\n",
    "        original_data_path='/kaggle/input/eatvul/cwe20_test.csv',\n",
    "        prediction_file_path='/kaggle/input/eatvul/predict_codet5_cwe20.txt'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest adversarial code found:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(best_code)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best fitness: {best_fitness:.4f}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    print(\"Please ensure your data and prediction files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfa797",
   "metadata": {
    "papermill": {
     "duration": 0.035821,
     "end_time": "2025-06-03T06:16:05.544544",
     "exception": false,
     "start_time": "2025-06-03T06:16:05.508723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc403f",
   "metadata": {
    "papermill": {
     "duration": 0.035888,
     "end_time": "2025-06-03T06:16:05.617367",
     "exception": false,
     "start_time": "2025-06-03T06:16:05.581479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7267878,
     "sourceId": 12038821,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1124.702378,
   "end_time": "2025-06-03T06:16:09.467155",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-03T05:57:24.764777",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00d7c86323ab4d62b5ed7e98d708b9ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0586051b7c3d4fb58dc48c393715dec1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "079528d6ee6042d59440d8c847d1c727": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "092a47cda6a749c5840fd28321f31ade": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bf7b1229eeb4a8ea83aa06269d389d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ffaab9c06d94dbca33873946b3feb88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "11e12d2a33754ad59f5d1bae9d33f059": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1c683989928a4b5db1966657f6dc08ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b3f6a9522544a3d95096ddbfc078222",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_27b376439f3c45be9255c9cfc05f6841",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:‚Äá100%"
      }
     },
     "1df728c82d4642c68ff9182cdc6536fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ea39b8919544781993a973653c3824c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1f382ccc0414494c960bbfbbb1f2e91c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "211bebdb0541458fa28edb8f022ad530": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bed07fa1c61d4099b02aeb490b07169d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_a24275c62a3e48b09ccf3636c0619aac",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin:‚Äá100%"
      }
     },
     "21998d52230e4f90be81b70bbc389dbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21d0b4b3dfdd4704a8a3ba7ec7dc6369": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_21998d52230e4f90be81b70bbc389dbe",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_57626c02ba0b400a9cf457b37e8e9e59",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "26d8f06509fc42b3a1ab9fc8c80d801e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27b376439f3c45be9255c9cfc05f6841": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2a91a5968318469a9298be2e849f14b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2be14061918b4f95a9aeec00d5a9604e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_937182be356c429594b08e997815a731",
       "max": 1568.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ca9ddac70b4a43d2b2ba0ae26ffff7e8",
       "tabbable": null,
       "tooltip": null,
       "value": 1568.0
      }
     },
     "2fb4f3e5b83140fb9196a8c2bf66383b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3554d3750f5f475f8ad4c7cb8ac29881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9458c57ca0f4440eac33b549332a9bf2",
        "IPY_MODEL_38b2ae32d211419d902c10bc25798634",
        "IPY_MODEL_fdf9e43a4f034487995302a9945b4f78"
       ],
       "layout": "IPY_MODEL_1df728c82d4642c68ff9182cdc6536fa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "38b2ae32d211419d902c10bc25798634": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6877a803f90d4105ae7d8c73b0a99102",
       "max": 12512.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0ffaab9c06d94dbca33873946b3feb88",
       "tabbable": null,
       "tooltip": null,
       "value": 12512.0
      }
     },
     "3974a13db0e94fe6808ad338c7207b2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ce8a2df19844044b8167690af7029ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_26d8f06509fc42b3a1ab9fc8c80d801e",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9eaf98c8670c4ee7a237017b46342f5d",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:‚Äá100%"
      }
     },
     "3d3d02a7dd97463387ca6d8d448efa59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1c683989928a4b5db1966657f6dc08ef",
        "IPY_MODEL_2be14061918b4f95a9aeec00d5a9604e",
        "IPY_MODEL_ba15c4861f2341aa8d49b92585765794"
       ],
       "layout": "IPY_MODEL_3974a13db0e94fe6808ad338c7207b2b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3d5b8fd9d93346a188df86f512ca032f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40d4b8d36f8046c4b89dfe281c161f0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "440cef05d236403883169fe8c9d2c27d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f382ccc0414494c960bbfbbb1f2e91c",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_11e12d2a33754ad59f5d1bae9d33f059",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá892M/892M‚Äá[00:02&lt;00:00,‚Äá392MB/s]"
      }
     },
     "46e1c988cc6e4c138bb41bb9f9ebf329": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_760b6805f2584f94b55f5b08a3a7f85e",
        "IPY_MODEL_c1d9d1d7829648faa57a7f2276db2232",
        "IPY_MODEL_997d6af624804e73880aab62d82befa7"
       ],
       "layout": "IPY_MODEL_d81130e31dcb48c5bdb6f942be31146e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4bcb71dbc1f0483082b0473d69370f99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c4b3b5a20284dd0a4384ccee6f80997": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "517d0470f3da4fd281ff9622fc9303ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_092a47cda6a749c5840fd28321f31ade",
       "max": 703051.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_40d4b8d36f8046c4b89dfe281c161f0b",
       "tabbable": null,
       "tooltip": null,
       "value": 703051.0
      }
     },
     "523437b260a443a88f0af7d7809ab961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "555e2bdf55fc4c6c9a142acf890a2154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "57626c02ba0b400a9cf457b37e8e9e59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5a4633f6a3b34feaa9c0c3889d87140c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d2f6034a75c4cb1bf748231a498cba0",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ab29b9c0883347d3af61b6ad3ffa5b52",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:‚Äá100%"
      }
     },
     "5b3f6a9522544a3d95096ddbfc078222": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d2f6034a75c4cb1bf748231a498cba0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6487a8f6374440d48ab80618a629369a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4bcb71dbc1f0483082b0473d69370f99",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_75fe2dbcfde34664896c0b4bd216e041",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:‚Äá100%"
      }
     },
     "6877a803f90d4105ae7d8c73b0a99102": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a5ad09871ff4bdba83f6a30b81f1d2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_211bebdb0541458fa28edb8f022ad530",
        "IPY_MODEL_ffb66cec76bc49a2bdf71b4e53302391",
        "IPY_MODEL_440cef05d236403883169fe8c9d2c27d"
       ],
       "layout": "IPY_MODEL_b13833ad7bbf46d084985217ac96addc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6d738bb591324537b4a4c878afb8269a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71dd63fda6fe487dbd32a215e61cceed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "75fe2dbcfde34664896c0b4bd216e041": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "760b6805f2584f94b55f5b08a3a7f85e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9071a91ca7524ca6aa53c06c36fe4dbe",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_1ea39b8919544781993a973653c3824c",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:‚Äá100%"
      }
     },
     "7d46ea84c843446d988b04166a843ab7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e71b7d5d1ce497ba9ee88c93a9e81b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d46ea84c843446d988b04166a843ab7",
       "max": 1477.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_523437b260a443a88f0af7d7809ab961",
       "tabbable": null,
       "tooltip": null,
       "value": 1477.0
      }
     },
     "84f8732cf0d644048bd1e33f3777cd8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "87e7942f75dd485aa16194e221070d17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "89aece3756c14780a10cb9aaa39ffbee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a5bb906cc3f4372a331488b22f3a499": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8a5fbe906a4243148089da26897338bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a4633f6a3b34feaa9c0c3889d87140c",
        "IPY_MODEL_517d0470f3da4fd281ff9622fc9303ca",
        "IPY_MODEL_ca587fb8e58b48d3baa66d97981a87cb"
       ],
       "layout": "IPY_MODEL_f551f706d7df40b69ee5d2ef81f77769",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9071a91ca7524ca6aa53c06c36fe4dbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "916683a301c64e9fac160816a8e0b58f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "937182be356c429594b08e997815a731": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9458c57ca0f4440eac33b549332a9bf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_db2d74b5fb4a4c95bdee4b6a4601c3f2",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_dcf8e5d198764d2aa0b0b87be023810d",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:‚Äá100%"
      }
     },
     "980f09caa20b4c1f92ed694a906dda97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3ce8a2df19844044b8167690af7029ab",
        "IPY_MODEL_7e71b7d5d1ce497ba9ee88c93a9e81b6",
        "IPY_MODEL_bdbed9a75f5a461096bbd948868f3131"
       ],
       "layout": "IPY_MODEL_e86173be8a8541469b93dd1678a05b08",
       "tabbable": null,
       "tooltip": null
      }
     },
     "997d6af624804e73880aab62d82befa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89aece3756c14780a10cb9aaa39ffbee",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_2a91a5968318469a9298be2e849f14b3",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá294k/294k‚Äá[00:00&lt;00:00,‚Äá28.8MB/s]"
      }
     },
     "9eaf98c8670c4ee7a237017b46342f5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9f8d1761ae3b4480a2683b3e8a001e06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2291b7da1984e7ea634a7cdf71e18c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a24275c62a3e48b09ccf3636c0619aac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a68623098acc47eb95f7e5dacb135a45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0bf7b1229eeb4a8ea83aa06269d389d9",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_00d7c86323ab4d62b5ed7e98d708b9ad",
       "tabbable": null,
       "tooltip": null,
       "value": "added_tokens.json:‚Äá100%"
      }
     },
     "ab29b9c0883347d3af61b6ad3ffa5b52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ac325a848e7c47468882151a6954555a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adb40c0ee9e54c4b898d1ee1662f1f9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b13833ad7bbf46d084985217ac96addc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7a020a65f4a4213b784c8d02f32ff43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a68623098acc47eb95f7e5dacb135a45",
        "IPY_MODEL_21d0b4b3dfdd4704a8a3ba7ec7dc6369",
        "IPY_MODEL_ba016ec969fb4fad962a40c2ee382de7"
       ],
       "layout": "IPY_MODEL_0586051b7c3d4fb58dc48c393715dec1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ba016ec969fb4fad962a40c2ee382de7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd3ce8fc8d634408ab88e952772a2334",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_8a5bb906cc3f4372a331488b22f3a499",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2.00/2.00‚Äá[00:00&lt;00:00,‚Äá245B/s]"
      }
     },
     "ba15c4861f2341aa8d49b92585765794": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_916683a301c64e9fac160816a8e0b58f",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_87e7942f75dd485aa16194e221070d17",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.57k/1.57k‚Äá[00:00&lt;00:00,‚Äá196kB/s]"
      }
     },
     "bdbed9a75f5a461096bbd948868f3131": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c4b3b5a20284dd0a4384ccee6f80997",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ca60907af5ed40699334f8fc5ea999f1",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.48k/1.48k‚Äá[00:00&lt;00:00,‚Äá177kB/s]"
      }
     },
     "bed07fa1c61d4099b02aeb490b07169d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1d9d1d7829648faa57a7f2276db2232": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_079528d6ee6042d59440d8c847d1c727",
       "max": 294364.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_555e2bdf55fc4c6c9a142acf890a2154",
       "tabbable": null,
       "tooltip": null,
       "value": 294364.0
      }
     },
     "ca587fb8e58b48d3baa66d97981a87cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_adb40c0ee9e54c4b898d1ee1662f1f9c",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_df1642f173c74b5b8a51be5e08d71139",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá703k/703k‚Äá[00:00&lt;00:00,‚Äá7.86MB/s]"
      }
     },
     "ca60907af5ed40699334f8fc5ea999f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca9ddac70b4a43d2b2ba0ae26ffff7e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cc9da93090374ca5be6893c80dc26184": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d5b8fd9d93346a188df86f512ca032f",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f6fecb521474494c897b42ce13fd87c8",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá892M/892M‚Äá[00:02&lt;00:00,‚Äá381MB/s]"
      }
     },
     "d6af9196e2564bea90f3249611f31908": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6d738bb591324537b4a4c878afb8269a",
       "max": 891558816.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2291b7da1984e7ea634a7cdf71e18c5",
       "tabbable": null,
       "tooltip": null,
       "value": 891558816.0
      }
     },
     "d81130e31dcb48c5bdb6f942be31146e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db2d74b5fb4a4c95bdee4b6a4601c3f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcf8e5d198764d2aa0b0b87be023810d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "df1642f173c74b5b8a51be5e08d71139": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e86173be8a8541469b93dd1678a05b08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9df952e6e1f4b68a26cc7a6006cf0ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6487a8f6374440d48ab80618a629369a",
        "IPY_MODEL_d6af9196e2564bea90f3249611f31908",
        "IPY_MODEL_cc9da93090374ca5be6893c80dc26184"
       ],
       "layout": "IPY_MODEL_ac325a848e7c47468882151a6954555a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f551f706d7df40b69ee5d2ef81f77769": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6fecb521474494c897b42ce13fd87c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fd3ce8fc8d634408ab88e952772a2334": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdf9e43a4f034487995302a9945b4f78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2fb4f3e5b83140fb9196a8c2bf66383b",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_84f8732cf0d644048bd1e33f3777cd8e",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá12.5k/12.5k‚Äá[00:00&lt;00:00,‚Äá1.57MB/s]"
      }
     },
     "ffb66cec76bc49a2bdf71b4e53302391": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f8d1761ae3b4480a2683b3e8a001e06",
       "max": 891641279.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_71dd63fda6fe487dbd32a215e61cceed",
       "tabbable": null,
       "tooltip": null,
       "value": 891641279.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
